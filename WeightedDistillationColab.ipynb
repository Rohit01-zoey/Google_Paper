{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBKtIwH996tK",
        "outputId": "f747bf71-0b70-4d3c-9446-6e3c5dbafe50"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-08 09:58:31.988754: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-08 09:58:32.213875: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-09-08 09:58:33.160808: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2023-09-08 09:58:33.160933: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
            "2023-09-08 09:58:33.160946: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-09-08 09:58:34.221794: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-08 09:58:35.307652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19632 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n"
          ]
        }
      ],
      "source": [
        "# Works on TPUs\n",
        "import tensorflow as tf\n",
        "\n",
        "# tpu_name = ''\n",
        "# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_name)\n",
        "\n",
        "# tf.config.experimental_connect_to_cluster(resolver)\n",
        "# tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "# strategy = tf.distribute.TPUStrategy(resolver)\n",
        "# Initialize GPU devices\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) == 0:\n",
        "  print(\"No GPU devices found. Using CPU.\")\n",
        "  strategy = tf.distribute.OneDeviceStrategy(device='/cpu:0')\n",
        "else:\n",
        "    for device in physical_devices:\n",
        "        tf.config.experimental.set_memory_growth(device, True)\n",
        "    strategy = tf.distribute.OneDeviceStrategy(device='/gpu:0')  # Adjust the device name as needed\n",
        "\n",
        "# Create a distribution strategy for GPUs\n",
        "strategy = tf.distribute.OneDeviceStrategy(device='/gpu:0')  # Adjust the device name as needed\n",
        "\n",
        "tf.random.set_seed(103847532)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwiCChDUzGrS"
      },
      "source": [
        "# Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tlArshXvkqEv"
      },
      "outputs": [],
      "source": [
        "\"\"\"A collection of Neural Net models to be used for experiments.\"\"\"\n",
        "\n",
        "from typing import Callable, Optional\n",
        "\n",
        "from absl import app\n",
        "\n",
        "\n",
        "def _get_mobilenet(depth_multiplier, num_classes, width_multiplier=1.0):\n",
        "\n",
        "  \"\"\"Loads mobilenet.\n",
        "\n",
        "  Args:\n",
        "    depth_multiplier: the depth_multiplier parameter for mobilenet\n",
        "    num_classes: the number of classes\n",
        "    width_multiplier: the width_multiplier for mobilenet\n",
        "\n",
        "  Returns:\n",
        "    Returns the mobilenet model.\n",
        "  \"\"\"\n",
        "  model = tf.keras.applications.mobilenet.MobileNet(\n",
        "      input_shape=(32, 32, 3),\n",
        "      alpha=width_multiplier,\n",
        "      depth_multiplier=depth_multiplier,\n",
        "      dropout=0.001,\n",
        "      include_top=True,\n",
        "      weights=None,\n",
        "      input_tensor=None,\n",
        "      pooling=None,\n",
        "      classes=num_classes,\n",
        "      classifier_activation='softmax')\n",
        "  return model\n",
        "\n",
        "\n",
        "# Implementation of ResNet models that can be found in\n",
        "# https://keras.io/zh/examples/cifar10_resnet/\n",
        "def _resnet_layer(inputs,\n",
        "                  num_filters=16,\n",
        "                  kernel_size=3,\n",
        "                  strides=1,\n",
        "                  activation='relu',\n",
        "                  batch_normalization=True,\n",
        "                  conv_first=True):\n",
        "  \"\"\"2D Convolution-Batch Normalization-Activation stack builder.\n",
        "\n",
        "  Args:\n",
        "    inputs: input tensor from input image or previous layer\n",
        "    num_filters: Conv2D number of filters\n",
        "    kernel_size: Conv2D square kernel dimensions\n",
        "    strides: Conv2D square stride dimensions\n",
        "    activation: activation name\n",
        "    batch_normalization: whether to include batch normalization\n",
        "    conv_first: conv-bn-activation (True) or bn-activation-conv (False)\n",
        "\n",
        "  Returns:\n",
        "   x: tensor as input to the next layer\n",
        "  \"\"\"\n",
        "\n",
        "  conv = tf.keras.layers.Conv2D(\n",
        "      num_filters,\n",
        "      kernel_size=kernel_size,\n",
        "      strides=strides,\n",
        "      padding='same',\n",
        "      kernel_initializer='he_normal',\n",
        "      kernel_regularizer=tf.keras.regularizers.l2(1e-4))\n",
        "  x = inputs\n",
        "  if conv_first:\n",
        "    x = conv(x)\n",
        "    if batch_normalization:\n",
        "      x = tf.keras.layers.BatchNormalization()(x)\n",
        "    if activation is not None:\n",
        "      x = tf.keras.layers.Activation(activation)(x)\n",
        "  else:\n",
        "    if batch_normalization:\n",
        "      x = tf.keras.layers.BatchNormalization()(x)\n",
        "    if activation is not None:\n",
        "      x = tf.keras.layers.Activation(activation)(x)\n",
        "    x = conv(x)\n",
        "  return x\n",
        "\n",
        "\n",
        "def _resnet_v2(\n",
        "    input_shape=(32, 32, 3), depth=29, num_classes=10, data_augmentation=False):\n",
        "\n",
        "  \"\"\"ResNet Version 2 Model builder.\n",
        "\n",
        "  Args:\n",
        "    input_shape: shape of input image tensor\n",
        "    depth: number of core convolutional layers\n",
        "    num_classes: number of classes\n",
        "    data_augmentation: A boolean variable that determines whether we use data\n",
        "      augmentation or not\n",
        "\n",
        "  Returns:\n",
        "    model (Model): Keras model instance\n",
        "  \"\"\"\n",
        "\n",
        "  if (depth - 2) % 9 != 0:\n",
        "    raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "\n",
        "  # Start model definition.\n",
        "  num_filters_in = 16\n",
        "  num_res_blocks = int((depth - 2) / 9)\n",
        "  inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "  # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "  if data_augmentation:\n",
        "    data_augmentation_module = tf.keras.Sequential([\n",
        "        tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "        tf.keras.layers.experimental.preprocessing.RandomTranslation(\n",
        "            3. / 32, 3. / 32),\n",
        "    ])\n",
        "    x = data_augmentation_module(inputs)\n",
        "    x = _resnet_layer(\n",
        "        inputs=x, num_filters=num_filters_in, conv_first=True)\n",
        "  else:\n",
        "    x = _resnet_layer(\n",
        "        inputs=inputs, num_filters=num_filters_in, conv_first=True)\n",
        "\n",
        "  # Instantiate the stack of residual units\n",
        "  for stage in range(3):\n",
        "    for res_block in range(num_res_blocks):\n",
        "      activation = 'relu'\n",
        "      batch_normalization = True\n",
        "      strides = 1\n",
        "      if stage == 0:\n",
        "        num_filters_out = num_filters_in * 4\n",
        "        if res_block == 0:  # first layer and first stage\n",
        "          activation = None\n",
        "          batch_normalization = False\n",
        "      else:\n",
        "        num_filters_out = num_filters_in * 2\n",
        "        if res_block == 0:  # first layer but not first stage\n",
        "          strides = 2  # downsample\n",
        "\n",
        "      # bottleneck residual unit\n",
        "      y = _resnet_layer(\n",
        "          inputs=x,\n",
        "          num_filters=num_filters_in,\n",
        "          kernel_size=1,\n",
        "          strides=strides,\n",
        "          activation=activation,\n",
        "          batch_normalization=batch_normalization,\n",
        "          conv_first=False)\n",
        "      y = _resnet_layer(inputs=y, num_filters=num_filters_in, conv_first=False)\n",
        "      y = _resnet_layer(\n",
        "          inputs=y,\n",
        "          num_filters=num_filters_out,\n",
        "          kernel_size=1,\n",
        "          conv_first=False)\n",
        "      if res_block == 0:\n",
        "        # linear projection residual shortcut connection to match\n",
        "        # changed dims\n",
        "        x = _resnet_layer(\n",
        "            inputs=x,\n",
        "            num_filters=num_filters_out,\n",
        "            kernel_size=1,\n",
        "            strides=strides,\n",
        "            activation=None,\n",
        "            batch_normalization=False)\n",
        "      x = tf.keras.layers.add([x, y])\n",
        "      print(num_filters_in, num_filters_out)\n",
        "    num_filters_in = num_filters_out\n",
        "\n",
        "  # Add classifier on top.\n",
        "  # v2 has BN-ReLU before Pooling\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  x = tf.keras.layers.AveragePooling2D(pool_size=8)(x)\n",
        "  y = tf.keras.layers.Flatten()(x)\n",
        "  outputs = tf.keras.layers.Dense(\n",
        "      num_classes, activation='softmax', kernel_initializer='he_normal')(\n",
        "          y)\n",
        "\n",
        "  # Instantiate model.\n",
        "  model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "  return model\n",
        "\n",
        "\n",
        "def load_model(model_architecture: str,\n",
        "               num_classes: int,\n",
        "               optimizer_name: str,\n",
        "               loss_function: Optional[Callable[\n",
        "                   ..., tf.Tensor]] = tf.keras.losses.CategoricalCrossentropy(),\n",
        "               learning_rate: Optional[float] = 0.001,\n",
        "               width_multiplier: Optional[float] = 1.0,\n",
        "               depth_multiplier: Optional[int] = 1,\n",
        "               resnet_depth: Optional[int] = 11) -> tf.keras.Model:\n",
        "\n",
        "  \"\"\"Loads a compiled model.\n",
        "\n",
        "  Args:\n",
        "    model_architecture: The name of the model architecture.\n",
        "    num_classes: The number of classes.\n",
        "    optimizer_name: The name of the optimizer we use.\n",
        "    loss_function: The loss function used in distillation.\n",
        "    learning_rate: The initial learning rate for our optimizer.\n",
        "    width_multiplier: The width_multiplier of the base_CNN/mobilenet model.\n",
        "    depth_multiplier: The depth_multiplier of the mobilenet model.\n",
        "    resnet_depth: The depth of the resnet network which must be of the form 9*d\n",
        "      + 2 for some integer d, e.g., 11, 20.\n",
        "  Returns:\n",
        "    A compiled model to be trained.\n",
        "  \"\"\"\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "  if model_architecture == 'mobilenet':\n",
        "    model = _get_mobilenet(\n",
        "        depth_multiplier=depth_multiplier,\n",
        "        num_classes=num_classes,\n",
        "        width_multiplier=width_multiplier)\n",
        "  elif model_architecture == 'resnet':\n",
        "    model = _resnet_v2(depth=resnet_depth, num_classes=num_classes)\n",
        "  else:\n",
        "    raise app.UsageError('Invalid argument to --model')\n",
        "\n",
        "  if optimizer_name == 'adam':\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "  elif optimizer_name == 'adagrad':\n",
        "    optimizer = tf.keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
        "  elif optimizer_name == 'SGD':\n",
        "    optimizer = tf.keras.optimizers.SGD(\n",
        "        learning_rate=learning_rate, momentum=0.2, nesterov=False)\n",
        "  else:\n",
        "    print('Default settings: Adam')\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "  model.compile(\n",
        "      loss=loss_function, optimizer=optimizer, metrics='categorical_accuracy')\n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16 64\n",
            "16 64\n",
            "64 128\n",
            "64 128\n",
            "128 256\n",
            "128 256\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 32, 32, 16)   448         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 32, 32, 16)  64          ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 32, 32, 16)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 32, 32, 16)   272         ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 32, 32, 64)   1088        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 32, 32, 64)   1088        ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 32, 32, 64)   0           ['conv2d_4[0][0]',               \n",
            "                                                                  'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 32, 32, 64)  256         ['add[0][0]']                    \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 32, 32, 64)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 32, 32, 16)   1040        ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 64)   1088        ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 32, 32, 64)   0           ['add[0][0]',                    \n",
            "                                                                  'conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 64)  256         ['add_1[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 32, 32, 64)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 64)   4160        ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 64)  256         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 64)   36928       ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  256         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 128)  8320        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 128)  8320        ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 16, 16, 128)  0           ['conv2d_11[0][0]',              \n",
            "                                                                  'conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 128)  512        ['add_2[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 128)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 64)   8256        ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 64)  256         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 64)   36928       ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 64)  256         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 128)  8320        ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 16, 16, 128)  0           ['add_2[0][0]',                  \n",
            "                                                                  'conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 128)  512        ['add_3[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 128)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 8, 8, 128)    16512       ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 8, 8, 128)   512         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 8, 8, 128)   512         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 8, 8, 256)    33024       ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 8, 8, 256)    33024       ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 8, 8, 256)    0           ['conv2d_18[0][0]',              \n",
            "                                                                  'conv2d_17[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 8, 8, 256)   1024        ['add_4[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 8, 8, 256)    0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 8, 8, 128)    32896       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 8, 8, 128)   512         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 8, 8, 128)   512         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 8, 8, 256)    33024       ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 8, 8, 256)    0           ['add_4[0][0]',                  \n",
            "                                                                  'conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 8, 8, 256)   1024        ['add_5[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 8, 8, 256)    0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 1, 1, 256)   0           ['activation_18[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 256)          0           ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 100)          25700       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 597,220\n",
            "Trainable params: 593,732\n",
            "Non-trainable params: 3,488\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = load_model(model_architecture='resnet', resnet_depth = 20, optimizer_name = 'adam', num_classes = 100)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMwnTVBV7uGY"
      },
      "source": [
        "# Data Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4qTmr89n3voa"
      },
      "outputs": [],
      "source": [
        "\"\"\"Contains some simple data structures for passing around dataset splits.\"\"\"\n",
        "\n",
        "import dataclasses\n",
        "import datetime as dt\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class LabeledExamples:\n",
        "  \"\"\"A LabeledExample dataclass to make passing dataset splits around easier.\n",
        "\n",
        "    Attributes\n",
        "      ----------\n",
        "      examples: tf.Tensor\n",
        "          A tensor containing the examples (x) of the data.\n",
        "      labels: tf.Tensor\n",
        "          A tensor containing the labels (y) of the data.\n",
        "      size: int\n",
        "          The number of examples.\n",
        "      num_classes: int\n",
        "          The number of different labels.\n",
        "      trainable: bool\n",
        "          If true this dataset split is ok to train on (e.g. should be set to\n",
        "          False for the test split).\n",
        "  \"\"\"\n",
        "\n",
        "  examples: tf.Tensor\n",
        "  labels: tf.Tensor\n",
        "  size: int\n",
        "  num_classes: int\n",
        "  trainable: bool\n",
        "\n",
        "  def shuffle(self, seed: Optional[int] = None):\n",
        "    \"\"\"Shuffles the order of the examples.\"\"\"\n",
        "\n",
        "    if seed is None:\n",
        "      rand_seed = int(dt.datetime.now().strftime('%f')[:-5])\n",
        "    else:\n",
        "      rand_seed = seed\n",
        "\n",
        "    shuffled_examples = np.random.RandomState(seed=rand_seed).permutation(\n",
        "        self.examples)\n",
        "    shuffled_labels = np.random.RandomState(seed=rand_seed).permutation(\n",
        "        self.labels)\n",
        "    self.examples = shuffled_examples\n",
        "    self.labels = shuffled_labels\n",
        "\n",
        "\n",
        "def split(data: LabeledExamples,\n",
        "          index: int) -> Tuple[LabeledExamples, LabeledExamples]:\n",
        "  \"\"\"Splits a Labeled Examples instance into two parts.\"\"\"\n",
        "\n",
        "  split_a_examples = data.examples[:-index]\n",
        "  spit_a_labels = data.labels[:-index]\n",
        "\n",
        "  split_a = LabeledExamples(\n",
        "      split_a_examples,\n",
        "      spit_a_labels,\n",
        "      size=len(split_a_examples),\n",
        "      num_classes=data.num_classes,\n",
        "      trainable=True)\n",
        "\n",
        "  split_b_examples = data.examples[-index:]\n",
        "  split_b_labels = data.labels[-index:]\n",
        "\n",
        "  split_b = LabeledExamples(\n",
        "      split_b_examples,\n",
        "      split_b_labels,\n",
        "      size=len(split_b_examples),\n",
        "      num_classes=data.num_classes,\n",
        "      trainable=True)\n",
        "  return split_a, split_b\n",
        "\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class DataSplit:\n",
        "  \"\"\"Class for the dataset splits used in unlabeled distillation.\n",
        "\n",
        "  Attributes\n",
        "    ----------\n",
        "    dataset_a: LabeledExamples\n",
        "        An instance of LabeledExamples containing the (small) set of labeled\n",
        "        training data used to train the teacher.\n",
        "    dataset_b: LabeledExamples\n",
        "        An instance of LabeledExamples containing the (large) set of training\n",
        "        data used to train the teacher.  The labels of these points should *not*\n",
        "        be used to train the student model.\n",
        "    test: LabeledExamples\n",
        "        An instance of LabeledExamples containing the test set for evaluating\n",
        "        the teacher and student models.\n",
        "    validtion: LabeledExamples, Optional\n",
        "        An instance of LabeledExamples containing the validation.\n",
        "\n",
        "  \"\"\"\n",
        "  dataset_a: LabeledExamples\n",
        "  dataset_b: LabeledExamples\n",
        "  test: LabeledExamples\n",
        "  validation: Optional[LabeledExamples] = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yDtvUA9A2tpC"
      },
      "outputs": [],
      "source": [
        "\"\"\"Methods for loading datasets.\"\"\"\n",
        "\n",
        "from typing import Optional\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "\n",
        "def _example_label_split(dataset):\n",
        "  x, y = zip(*dataset)\n",
        "  return tf.convert_to_tensor(x, dtype=tf.float32), tf.convert_to_tensor(y)\n",
        "\n",
        "\n",
        "def _normalize_x(x):\n",
        "  x /= 127.5\n",
        "  x -= 1.0\n",
        "  return x\n",
        "\n",
        "\n",
        "def _normalize_y(y, num_classes):\n",
        "  return tf.keras.utils.to_categorical(y, num_classes)\n",
        "\n",
        "\n",
        "def load_cifar_data(labeled_percentage: Optional[int] = 20,\n",
        "                    num_classes: Optional[int] = 10,\n",
        "                    binary: Optional[bool] = False) -> DataSplit:\n",
        "  \"\"\"Loads cifar10 or cifar100 dataset.\"\"\"\n",
        "\n",
        "  if num_classes == 10:\n",
        "    train1, train2, test = tfds.load(\n",
        "        'cifar10',\n",
        "        split=[\n",
        "            f'train[:{labeled_percentage}%]', f'train[{labeled_percentage}%:]',\n",
        "            'test'\n",
        "        ],\n",
        "        as_supervised=True)\n",
        "  else:\n",
        "    train1, train2, test = tfds.load(\n",
        "        'cifar100',\n",
        "        split=[\n",
        "            f'train[:{labeled_percentage}%]', f'train[{labeled_percentage}%:]',\n",
        "            'test'\n",
        "        ],\n",
        "        as_supervised=True)\n",
        "\n",
        "  x_train1, y_train1 = _example_label_split(train1)\n",
        "  x_train2, y_train2 = _example_label_split(train2)\n",
        "  x_test, y_test = _example_label_split(test)\n",
        "\n",
        "  if binary:\n",
        "    y_train1 = y_train1 % 2\n",
        "    y_train2 = y_train2 % 2\n",
        "    y_test = y_test % 2\n",
        "    num_classes = 2\n",
        "\n",
        "  x_train1 = _normalize_x(x_train1)\n",
        "  y_train1 = _normalize_y(y_train1, num_classes)\n",
        "\n",
        "  x_train2 = _normalize_x(x_train2)\n",
        "  y_train2 = _normalize_y(y_train2, num_classes)\n",
        "\n",
        "  x_test = _normalize_x(x_test)\n",
        "  y_test = _normalize_y(y_test, num_classes)\n",
        "\n",
        "  dataset_a = LabeledExamples(\n",
        "      examples=x_train1,\n",
        "      labels=y_train1,\n",
        "      size=len(x_train1),\n",
        "      num_classes=num_classes,\n",
        "      trainable=True)\n",
        "\n",
        "  dataset_b = LabeledExamples(\n",
        "      examples=x_train2,\n",
        "      labels=y_train2,\n",
        "      size=len(x_train2),\n",
        "      num_classes=num_classes,\n",
        "      trainable=True)\n",
        "\n",
        "  test = LabeledExamples(\n",
        "      examples=x_test,\n",
        "      labels=y_test,\n",
        "      size=len(x_test),\n",
        "      num_classes=num_classes,\n",
        "      trainable=False)\n",
        "\n",
        "  data_split = DataSplit(\n",
        "      dataset_a=dataset_a, dataset_b=dataset_b, validation=None, test=test)\n",
        "\n",
        "  return data_split\n",
        "\n",
        "\n",
        "def load_celeb_a_data(\n",
        "    labeled_percentage: int,\n",
        "    num_classes: Optional[int] = 2,\n",
        "    label_key: Optional[str] = 'Male',\n",
        "    group_key: Optional[str] = 'Young') -> DataSplit:\n",
        "  \"\"\"Loads celeb_a.\"\"\"\n",
        "\n",
        "  def _get_image_and_label(feat_dict):\n",
        "    return (feat_dict['image'], feat_dict['attributes'][label_key])\n",
        "\n",
        "  def _preprocess_input_dict(feat_dict):\n",
        "    # Separate out the image and target variable from the feature dictionary.\n",
        "    image = feat_dict['image']\n",
        "    label = feat_dict['attributes'][label_key]\n",
        "    group = feat_dict['attributes'][group_key]\n",
        "\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.image.resize(image, [32, 32])\n",
        "\n",
        "    label = tf.cast(label, tf.float32)\n",
        "    group = tf.cast(group, tf.float32)\n",
        "\n",
        "    feat_dict['image'] = image\n",
        "    feat_dict['attributes'][label_key] = label\n",
        "    feat_dict['attributes'][group_key] = group\n",
        "\n",
        "    return feat_dict\n",
        "\n",
        "  celeb_a_builder = tfds.builder('celeb_a')\n",
        "  celeb_a_builder.download_and_prepare()\n",
        "\n",
        "  train1, train2, test = celeb_a_builder.as_dataset(split=[\n",
        "      f'train[:{labeled_percentage}%]', f'train[{labeled_percentage}%:]', 'test'\n",
        "  ])\n",
        "\n",
        "  x_train1, y_train1 = _example_label_split(\n",
        "      train1.batch(1).map(_preprocess_input_dict).map(_get_image_and_label))\n",
        "  x_train2, y_train2 = _example_label_split(\n",
        "      train2.batch(1).map(_preprocess_input_dict).map(_get_image_and_label))\n",
        "  x_test, y_test = _example_label_split(\n",
        "      test.batch(1).map(_preprocess_input_dict).map(_get_image_and_label))\n",
        "\n",
        "  x_train1 = tf.squeeze(x_train1)\n",
        "  y_train1 = tf.squeeze(y_train1)\n",
        "\n",
        "  x_train2 = tf.squeeze(x_train2)\n",
        "  y_train2 = tf.squeeze(y_train2)\n",
        "\n",
        "  x_test = tf.squeeze(x_test)\n",
        "  y_test = tf.squeeze(y_test)\n",
        "\n",
        "  x_train1 = _normalize_x(x_train1)\n",
        "  y_train1 = _normalize_y(y_train1, num_classes)\n",
        "\n",
        "  x_train2 = _normalize_x(x_train2)\n",
        "  y_train2 = _normalize_y(y_train2, num_classes)\n",
        "\n",
        "  x_test = _normalize_x(x_test)\n",
        "  y_test = _normalize_y(y_test, num_classes)\n",
        "\n",
        "  dataset_a = LabeledExamples(\n",
        "      examples=x_train1,\n",
        "      labels=y_train1,\n",
        "      size=len(x_train1),\n",
        "      num_classes=num_classes,\n",
        "      trainable=True)\n",
        "\n",
        "  dataset_b = LabeledExamples(\n",
        "      examples=x_train2,\n",
        "      labels=y_train2,\n",
        "      size=len(x_train2),\n",
        "      num_classes=num_classes,\n",
        "      trainable=True)\n",
        "\n",
        "  test = LabeledExamples(\n",
        "      examples=x_test,\n",
        "      labels=y_test,\n",
        "      size=len(x_test),\n",
        "      num_classes=num_classes,\n",
        "      trainable=False)\n",
        "\n",
        "  data_split = DataSplit(\n",
        "      dataset_a=dataset_a, dataset_b=dataset_b, validation=None, test=test)\n",
        "\n",
        "  return data_split\n",
        "\n",
        "\n",
        "def load_data(dataset_name: str,\n",
        "              labeled_percentage: int) -> DataSplit:\n",
        "  \"\"\"Loads either cifar10, cifar100, or celeb_a.\"\"\"\n",
        "\n",
        "  if dataset_name == 'cifar10':\n",
        "    num_classes = 10\n",
        "    return load_cifar_data(\n",
        "        labeled_percentage=labeled_percentage, num_classes=num_classes)\n",
        "  elif dataset_name == 'cifar10bin':\n",
        "    num_classes = 10\n",
        "    return load_cifar_data(\n",
        "        labeled_percentage=labeled_percentage,\n",
        "        num_classes=num_classes,\n",
        "        binary=True)\n",
        "  elif dataset_name == 'cifar100':\n",
        "    num_classes = 100\n",
        "    return load_cifar_data(\n",
        "        labeled_percentage=labeled_percentage, num_classes=num_classes)\n",
        "  elif dataset_name == 'celeb_a':\n",
        "    num_classes = 2\n",
        "    return load_celeb_a_data(\n",
        "        labeled_percentage=labeled_percentage, num_classes=num_classes)\n",
        "  else:\n",
        "    raise NameError('Wrong dataset name.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ9CyD2Z7_Fh"
      },
      "source": [
        "# Training Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "n0BRIb4B4VWQ"
      },
      "outputs": [],
      "source": [
        "\"\"\"A function that trains models with or without data augmentation.\"\"\"\n",
        "\n",
        "from typing import Optional\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def _train_model(\n",
        "    model: tf.keras.Model,\n",
        "    train_x: tf.Tensor,\n",
        "    train_y: tf.Tensor,\n",
        "    test_x: tf.Tensor,\n",
        "    test_y: tf.Tensor,\n",
        "    data_augmentation: Optional[bool] = False,\n",
        "    weights: Optional[tf.Tensor] = None,\n",
        "    epochs: Optional[int] = 200,\n",
        "    with_lr_scheduler: Optional[bool] = True,\n",
        "    batch_size: Optional[int] = 128,\n",
        "    epochs_offset: Optional[int] = 0) -> tf.keras.callbacks.History:\n",
        "  \"\"\"Trains a model.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    train_x: A dataset containing the data to train on.\n",
        "    train_y: A dataset containing the labels of the data to train on.\n",
        "    test_x: A dataset containing the data to test on.\n",
        "    test_y: A dataset containing the labels of the data to test on.\n",
        "    data_augmentation: True if data augmentation is used and False otherwise.\n",
        "    weights: The weight sample-weights to be used.\n",
        "    epochs: The number of epochs to train for.\n",
        "    with_lr_scheduler: Whether we use a schedule for the learning-rate or not.\n",
        "    batch_size: The batch size used for training.\n",
        "    epochs_offset: How many epochs we assume we have performed so far.\n",
        "\n",
        "  Returns:\n",
        "      history: History of trained model.\n",
        "\n",
        "  Raises:\n",
        "    NotImplementedError: if online data augmention is used with weights or if\n",
        "    an augmentation method other than None, 'offline', or 'online' is provided.\n",
        "    To use weights with online data augmentation, weights should be passed as\n",
        "    an extra advice label and a corresponding loss with advice should be used,\n",
        "    see the loss functions defined in loss_functions.py.\n",
        "  \"\"\"\n",
        "\n",
        "  def lr_schedule(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch + epochs_offset > 180:\n",
        "      lr *= 0.5e-3\n",
        "    elif epoch + epochs_offset > 160:\n",
        "      lr *= 1e-3\n",
        "    elif epoch + epochs_offset > 120:\n",
        "      lr *= 1e-2\n",
        "    elif epoch + epochs_offset > 80:\n",
        "      lr *= 1e-1\n",
        "    return lr\n",
        "\n",
        "  if with_lr_scheduler:\n",
        "    lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
        "    callbacks = [lr_scheduler]\n",
        "\n",
        "  with_weights = False\n",
        "  if weights is not None:\n",
        "    with_weights = True\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (train_x, train_y, weights))\n",
        "  else:\n",
        "    with_weights = False\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (train_x, train_y))\n",
        "\n",
        "  def prepare(ds, shuffle=False, augment=False, with_weights=False):\n",
        "    autotune = tf.data.AUTOTUNE\n",
        "\n",
        "    data_augmentation_layer = tf.keras.Sequential([\n",
        "        tf.keras.layers.RandomFlip('horizontal'),\n",
        "        tf.keras.layers.RandomTranslation(\n",
        "            height_factor=0.1,\n",
        "            width_factor=0.1,\n",
        "            fill_mode='nearest',\n",
        "            interpolation='bilinear',\n",
        "            seed=None,\n",
        "            fill_value=0.0)\n",
        "    ])\n",
        "\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(len(train_x), reshuffle_each_iteration=True)\n",
        "\n",
        "    # Use data augmentation only on the training set.\n",
        "    if augment:\n",
        "      if with_weights:\n",
        "        ds = ds.map(\n",
        "            lambda x, y, w: (data_augmentation_layer(x, training=True), y, w),\n",
        "            num_parallel_calls=autotune)\n",
        "      else:\n",
        "        ds = ds.map(\n",
        "            lambda x, y: (data_augmentation_layer(x, training=True), y),\n",
        "            num_parallel_calls=autotune)\n",
        "\n",
        "    # Batch the dataset. The drop_remainder is needed to avoid uneven batches.\n",
        "    ds = ds.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "    # Use buffered prefetching on all datasets.\n",
        "    ds = ds.prefetch(buffer_size=autotune)\n",
        "\n",
        "    return ds\n",
        "\n",
        "  train_dataset = prepare(\n",
        "      train_dataset,\n",
        "      shuffle=True,\n",
        "      augment=data_augmentation,\n",
        "      with_weights=with_weights)\n",
        "\n",
        "  history = model.fit(\n",
        "      train_dataset,\n",
        "      validation_data=(test_x, test_y),\n",
        "      epochs=epochs,\n",
        "      verbose=1,\n",
        "      workers=4,\n",
        "      callbacks=callbacks)\n",
        "\n",
        "  return history\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model: tf.keras.Model,\n",
        "    train_x: tf.Tensor,\n",
        "    train_y: tf.Tensor,\n",
        "    test_x: tf.Tensor,\n",
        "    test_y: tf.Tensor,\n",
        "    data_augmentation: Optional[str] = None,\n",
        "    weights: Optional[tf.Tensor] = None,\n",
        "    epochs: Optional[int] = 200,\n",
        "    with_lr_scheduler: Optional[bool] = True,\n",
        "    batch_size: Optional[int] = 128,\n",
        "    epochs_offset: Optional[int] = 0) -> tf.keras.callbacks.History:\n",
        "  \"\"\"Trains a model.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    train_x: A dataset containing the data to train on.\n",
        "    train_y: A dataset containing the labels of the data to train on.\n",
        "    test_x: A dataset containing the data to test on.\n",
        "    test_y: A dataset containing the labels of the data to test on.\n",
        "    data_augmentation: Can be either 'no', 'offline', 'online'.\n",
        "    weights: The weight sample-weights to be used.\n",
        "    epochs: The number of epochs to train for.\n",
        "    with_lr_scheduler: Whether we use a schedule for the learning-rate or not.\n",
        "    batch_size: The batch size used for training.\n",
        "    epochs_offset: How many epochs we assume we have performed so far.\n",
        "\n",
        "  Returns:\n",
        "      history: History of trained model.\n",
        "  \"\"\"\n",
        "\n",
        "  if data_augmentation != 'online':\n",
        "\n",
        "    if data_augmentation == 'no' or not data_augmentation:\n",
        "      use_data_augmentation = False\n",
        "    else:\n",
        "      use_data_augmentation = True\n",
        "\n",
        "    return _train_model(\n",
        "        model=model,\n",
        "        train_x=train_x,\n",
        "        train_y=train_y,\n",
        "        test_x=test_x,\n",
        "        test_y=test_y,\n",
        "        epochs=epochs,\n",
        "        data_augmentation=use_data_augmentation,\n",
        "        weights=weights,\n",
        "        with_lr_scheduler=with_lr_scheduler,\n",
        "        batch_size=batch_size,\n",
        "        epochs_offset=epochs_offset)\n",
        "\n",
        "  elif data_augmentation == 'online':\n",
        "    results = []\n",
        "\n",
        "    for i in range(1, epochs+1):\n",
        "\n",
        "      print(f'Epoch {i}/{epochs}')\n",
        "\n",
        "      history_tmp = _train_model(\n",
        "          model=model,\n",
        "          train_x=train_x,\n",
        "          train_y=train_y,\n",
        "          test_x=test_x,\n",
        "          test_y=test_y,\n",
        "          epochs=1,\n",
        "          data_augmentation=True,\n",
        "          weights=weights,\n",
        "          with_lr_scheduler=with_lr_scheduler,\n",
        "          batch_size=batch_size,\n",
        "          epochs_offset=i)\n",
        "\n",
        "      results.append(history_tmp)\n",
        "\n",
        "    history = results[0]\n",
        "\n",
        "    for hist in results[1:]:\n",
        "      for key in hist.history.keys():\n",
        "        history.history[key] += hist.history[key]\n",
        "    return history\n",
        "\n",
        "  else:\n",
        "    raise NotImplementedError()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3quluVIF76CT"
      },
      "source": [
        "# Experiment Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WBdL4N7G6JC3"
      },
      "outputs": [],
      "source": [
        "# Dataset used for training.\n",
        "_DATASET =  'cifar100'\n",
        "# Whether the teacher outputs soft-labels or hard-labels.\n",
        "_WITH_SOFT_LABELS = True\n",
        "# Whether we pretrain the student model.\n",
        "_WITH_PRETRAINING = True\n",
        "# The model architecture we are using for the teacher.\n",
        "_TEACHER_MODEL = 'resnet'\n",
        "# The data augmentation method we are using for the teacher.\n",
        "_TEACHER_DATA_AUGMENTATION =  'online'\n",
        "# The data augmentation method we are using for pretraining the student.\n",
        "_STUDENT_PRETRAINING_DATA_AUGMENTATION = 'online'\n",
        "# Data augmentation method we are using for training the student during\n",
        "_STUDENT_DISTILLATION_DATA_AUGMENTATION =  'online'\n",
        "# Student model architecture.\n",
        "_STUDENT_MODEL =  'resnet'\n",
        "# Teacher mobilenet depth multiplier.\n",
        "_TEACHER_MOBILENET_DEPTH_MULTIPLIER = 2\n",
        "# Student mobilenet depth multiplier.\n",
        "_STUDENT_MOBILENET_DEPTH_MULTIPLIER = 1\n",
        "# Teacher resnet depth.\n",
        "_TEACHER_RESNET_DEPTH = 110\n",
        "# Student resnet depth.\n",
        "_STUDENT_RESNET_DEPTH = 56\n",
        "# Student training epochs.\n",
        "_STUDENT_EPOCHS = 100\n",
        "# Teacher training epochs.\n",
        "_TEACHER_EPOCHS = 200\n",
        "# Student pretraining epochs.\n",
        "_PRETRAINING_EPOCHS = 200\n",
        "# Student optimizer.\n",
        "_STUDENT_OPTIMIZER = 'adam'\n",
        "# Teacher optimizer.\n",
        "_TEACHER_OPTIMIZER = 'adam'\n",
        "# Size of validation dataset.\n",
        "_VALIDATION_DATASET_SIZE = 512\n",
        "# Size of labeled dataset (percentage of labeled examples).\n",
        "_SIZE_OF_DATASET_A = 25\n",
        "# Whether to soft-label the labeled dataset A.\n",
        "_SOFT_LABEL_DATASET_A = False\n",
        "# Number of experiment trials.\n",
        "_NUM_TRIALS =  3\n",
        "# Whether to randomize the dataset in each trial.\n",
        "_RANDOMIZE_DATASET = True\n",
        "# Whether to train on validation data.\n",
        "_TRAIN_ON_VALIDATION = True\n",
        "# The batch size to be used.\n",
        "_BATCH_SIZE = 128\n",
        "# The random seed to be used.\n",
        "_SEED = 753410\n",
        "# The path to load/save models.\n",
        "_CNS_PATH = '/cns/jv-d/home/kontonis/colab/'\n",
        "\n",
        "\n",
        "# The filenames of the pretrained student model.\n",
        "student_load_temp_filename = 'pretrained_weights.h5'\n",
        "student_save_temp_filename = 'pretrained_weights.h5'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHVF28nf0ZLY"
      },
      "source": [
        "# Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "e019cf23b028471ba4bbdd7562059fb1",
            "1b6b6bd2bbc349578bc477be08e8dbfd",
            "670822cafcf64dcebfb8ed5d0b5f6b80",
            "dad908eb1a5e453886aae4072421cef7",
            "bbba9b14a5e3419f93ec24b63ae83ac3",
            "0b3b5c2ae94f4a819f88e1cee9f5a33c",
            "1dcc162118e24304aec8d5bbda552b14",
            "2758760fa84943d297ff75f2f4a1f11b",
            "14f2501b6a764a34ab0be67d832bc304",
            "4c97d001bebf432f975c3c64fc3a61c5",
            "ee90192a07a84b61a2702054138189c2",
            "1ed735d10be546a3bc2cc66068ea999c",
            "02e462c5e91e469a8146c500989c19df",
            "1428d7468b8b460597e89f415a3c5dbd",
            "b30f448657a04c7abaada388d3b656aa",
            "82a347fbd16d4c32971306b8d6b2b57a",
            "c58d1e6316a24750bdf4ba51098f7280",
            "e747346d06d449aaadfefb36d902a576",
            "4448ea8d263746ce8db8e3d66bfad446",
            "c87185ea3abb41689d6b23c50d57eed2",
            "01509b6f21de43f48343d2df137fa434",
            "30f0c55344814ed08dcf841d39b42b45",
            "cf3cd11bdbef467593013786ae70a08a",
            "983191d266f14c41b015890a9f53b903",
            "5f2bf455d9e041cdac6b8519997c03fb",
            "166dc17a38e8447288cba6ce147c51e0",
            "d8ebb04555ce40728eeecd4951a798bf",
            "cb473a9b00424987a4e36d9d044b0a96",
            "39e3cd47bdb245a4a7bd94eb5ab0c4df",
            "06e56a5f67004e76bb5bf78086aa7003",
            "7ae8b96e5082416c8b8f3613f80e80ff",
            "934e160518314e03b2d675618cb699cf",
            "d9a4e5660b8c4a67ad50cbdbd0c419fc",
            "ef60724b291e4e81abfa35d5444d9ae7",
            "b2d1c265c0f340978e79a1e20e4ec4f1",
            "90eee6032ea54cf189fa725751c4baa6",
            "33fb288614544851a9bd1e586f07f1b5",
            "9468c4c8ec5647d991126ed5c227d355",
            "6f6e896a8d4441cf9dcd953ae60fca40",
            "c0545872c3de4561ac4bef7ed402f89d",
            "29e4f83090ef471f849ae595f906f480",
            "f1ec1877fd234ec3b85baad00987ed3c",
            "4aa9619da1284b6baeb704212c750aa1",
            "d5a4f6e8f4284d26a949cb3fe19caf6b",
            "10eff5b4c3964489af536c7d634fe9fc",
            "ade307cbc41c4d25abf1f154d4658cb9",
            "d23796d20af0492f81105ab8a358117c",
            "ee3b23415db646ae92917cd03344b01f",
            "01fdb47da20048959040309cb36dd181",
            "b22299f613e34e328a47f968493235c9",
            "5da76f426a98463da3ff4c80740647a7",
            "fc4db6cb065347769502ce5180001db3",
            "90f2a31b38d347d185625063e1f7f933",
            "d730206c2ec248c7b9dd24a591e1e578",
            "f239894a44c14a1abd0a21109167537d",
            "101c50425c25436ea142886a0bdfbb9a",
            "90412bde42e5466881d26982937b17e8",
            "c40d07cf2d074291a42b4cc176f89cce",
            "2661835ce6334e6c9fd3e1426d37700e",
            "dbf29b11c23e4610a6e340636d90f159",
            "b8f91dd0a4654b63849fe61c9e940d53",
            "806932478b564e7f8c905c5600637815",
            "b37ee5210bc9441fbb9617dff6889b1f",
            "390d198cedcf4bc896f36f914679737a",
            "132d9720f49246eca68a2c2d0e722b58",
            "779ac98dd484436ea7b3825235ddf6e2",
            "83169747f618462a9bbd29138f50e38c",
            "3139735376164a03b93833ed8f5345bd",
            "88ae664f204f484bbab5e635fb2e5a85",
            "7ec328eb316e460085b6c29897dbb1bc",
            "69a3ede4ec9a4f11b236033320ec13b4",
            "85a2069f167f498fb897a976246e9dcd",
            "f139b7728dcc4696b1882b767fb6d0c1",
            "c1b0bf12a7c6463698328f72755a3447",
            "aaf32eef522e44ccb35a804929bb2d2f",
            "6f35e7c451124d6285e5afdb21e26823",
            "d2e97d0c4f184760b254bec2a97ed5f1",
            "305dd26f0d5e429f9614c3fcb17d3002",
            "cd825562f093402d95854387ec6b6063",
            "48c4bdcae65a4f71979157529bf45a5c",
            "53cf49b0f7cf4941a875a4966703c2c9",
            "7303a767e82d498fb1da120e9f76d25f",
            "4f2b801a0594441fb1a4afadeefd719d",
            "63b11c2932b844b485071b76c548e9d2",
            "1faee804aa4d4fad8c1d713fc2d1a882",
            "ecb53fbd438e4a4f9259b49f23ed493a",
            "cd23a566c5b84e8685c9a86431b2ed72",
            "53cb7da6a615452c9ee6430842f97ce8"
          ]
        },
        "id": "Fn9Z6_bgDgFx",
        "outputId": "e9e84c88-e44d-4d39-c73e-ce96d779487f"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "data_split = load_data(\n",
        "    dataset_name=_DATASET, labeled_percentage=_SIZE_OF_DATASET_A)\n",
        "\n",
        "# Number of classes should be equal for all three splits (dataset_a,\n",
        "# dataset_b, test) so we set it using the labeled split, dataset_a.\n",
        "num_classes = data_split.dataset_a.num_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hwUpBI-kfqH"
      },
      "source": [
        "\n",
        "# Train/Load the Teacher Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPjarREQjEsl",
        "outputId": "fbdecb9d-baaf-4499-b41e-28298ff5ed91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 07:47:14.617809: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:1771\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 464s 1s/step - loss: 6.0996 - categorical_accuracy: 0.0780 - val_loss: 6.2722 - val_categorical_accuracy: 0.0472 - lr: 0.0010\n",
            "Epoch 2/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 07:55:34.799150: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:1809\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 74s 760ms/step - loss: 5.2968 - categorical_accuracy: 0.1299 - val_loss: 5.3481 - val_categorical_accuracy: 0.0977 - lr: 0.0010\n",
            "Epoch 3/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 07:56:51.684849: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:1847\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 89s 915ms/step - loss: 4.8012 - categorical_accuracy: 0.1693 - val_loss: 5.0594 - val_categorical_accuracy: 0.1122 - lr: 0.0010\n",
            "Epoch 4/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 07:58:23.255312: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:1885\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 71s 730ms/step - loss: 4.4539 - categorical_accuracy: 0.1985 - val_loss: 4.5852 - val_categorical_accuracy: 0.1716 - lr: 0.0010\n",
            "Epoch 5/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 07:59:37.608613: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:1923\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 91s 934ms/step - loss: 4.1597 - categorical_accuracy: 0.2324 - val_loss: 4.3109 - val_categorical_accuracy: 0.1924 - lr: 0.0010\n",
            "Epoch 6/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:02:03.640373: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:1961\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 70s 721ms/step - loss: 3.9453 - categorical_accuracy: 0.2512 - val_loss: 4.4507 - val_categorical_accuracy: 0.1657 - lr: 0.0010\n",
            "Epoch 7/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:03:29.399650: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:1999\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 72s 739ms/step - loss: 3.7430 - categorical_accuracy: 0.2793 - val_loss: 4.2703 - val_categorical_accuracy: 0.1837 - lr: 0.0010\n",
            "Epoch 8/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:04:45.045776: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2037\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 90s 927ms/step - loss: 3.5475 - categorical_accuracy: 0.3107 - val_loss: 4.1222 - val_categorical_accuracy: 0.1960 - lr: 0.0010\n",
            "Epoch 9/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:07:10.040730: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2075\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 89s 916ms/step - loss: 3.3906 - categorical_accuracy: 0.3294 - val_loss: 3.9403 - val_categorical_accuracy: 0.2319 - lr: 0.0010\n",
            "Epoch 10/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:08:42.646130: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2113\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 90s 924ms/step - loss: 3.2463 - categorical_accuracy: 0.3569 - val_loss: 3.8444 - val_categorical_accuracy: 0.2411 - lr: 0.0010\n",
            "Epoch 11/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:10:15.957473: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2151\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 89s 918ms/step - loss: 3.2281 - categorical_accuracy: 0.3525 - val_loss: 3.6582 - val_categorical_accuracy: 0.2749 - lr: 0.0010\n",
            "Epoch 12/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:11:48.509651: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2189\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 75s 765ms/step - loss: 3.0341 - categorical_accuracy: 0.3966 - val_loss: 3.6697 - val_categorical_accuracy: 0.2814 - lr: 0.0010\n",
            "Epoch 13/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:13:14.081458: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2227\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 74s 760ms/step - loss: 3.0101 - categorical_accuracy: 0.3943 - val_loss: 3.5245 - val_categorical_accuracy: 0.2948 - lr: 0.0010\n",
            "Epoch 14/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:14:31.780265: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2265\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 70s 723ms/step - loss: 2.8990 - categorical_accuracy: 0.4170 - val_loss: 3.5245 - val_categorical_accuracy: 0.2874 - lr: 0.0010\n",
            "Epoch 15/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:15:46.183644: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2303\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 72s 739ms/step - loss: 2.7524 - categorical_accuracy: 0.4501 - val_loss: 3.4297 - val_categorical_accuracy: 0.3139 - lr: 0.0010\n",
            "Epoch 16/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:17:01.877807: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2341\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 86s 887ms/step - loss: 2.6868 - categorical_accuracy: 0.4626 - val_loss: 3.7262 - val_categorical_accuracy: 0.2910 - lr: 0.0010\n",
            "Epoch 17/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:19:28.031262: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2379\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 90s 925ms/step - loss: 2.5718 - categorical_accuracy: 0.4854 - val_loss: 3.6625 - val_categorical_accuracy: 0.2890 - lr: 0.0010\n",
            "Epoch 18/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:21:53.328160: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2417\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 88s 910ms/step - loss: 2.5077 - categorical_accuracy: 0.4999 - val_loss: 3.8187 - val_categorical_accuracy: 0.2939 - lr: 0.0010\n",
            "Epoch 19/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:23:24.759484: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2455\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 47s 484ms/step - loss: 2.5922 - categorical_accuracy: 0.4776 - val_loss: 3.2503 - val_categorical_accuracy: 0.3559 - lr: 0.0010\n",
            "Epoch 20/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:24:13.835611: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2493\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 231ms/step - loss: 2.3909 - categorical_accuracy: 0.5306 - val_loss: 3.3398 - val_categorical_accuracy: 0.3485 - lr: 0.0010\n",
            "Epoch 21/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:24:37.134220: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2531\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 226ms/step - loss: 2.3011 - categorical_accuracy: 0.5474 - val_loss: 3.5734 - val_categorical_accuracy: 0.3241 - lr: 0.0010\n",
            "Epoch 22/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:24:59.776991: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2569\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 234ms/step - loss: 2.4180 - categorical_accuracy: 0.5141 - val_loss: 3.4941 - val_categorical_accuracy: 0.3375 - lr: 0.0010\n",
            "Epoch 23/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:25:23.190940: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2607\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 221ms/step - loss: 2.3131 - categorical_accuracy: 0.5417 - val_loss: 3.4238 - val_categorical_accuracy: 0.3490 - lr: 0.0010\n",
            "Epoch 24/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:25:45.350668: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2645\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 233ms/step - loss: 2.2075 - categorical_accuracy: 0.5702 - val_loss: 3.2125 - val_categorical_accuracy: 0.3739 - lr: 0.0010\n",
            "Epoch 25/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:26:08.685594: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2683\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 225ms/step - loss: 2.1876 - categorical_accuracy: 0.5708 - val_loss: 3.4405 - val_categorical_accuracy: 0.3619 - lr: 0.0010\n",
            "Epoch 26/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:26:31.314428: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2721\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 227ms/step - loss: 2.1151 - categorical_accuracy: 0.5909 - val_loss: 3.0196 - val_categorical_accuracy: 0.4086 - lr: 0.0010\n",
            "Epoch 27/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:26:54.086805: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2759\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 230ms/step - loss: 2.0063 - categorical_accuracy: 0.6143 - val_loss: 3.3354 - val_categorical_accuracy: 0.3693 - lr: 0.0010\n",
            "Epoch 28/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:27:17.127778: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2797\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 2.1208 - categorical_accuracy: 0.5853 - val_loss: 3.1849 - val_categorical_accuracy: 0.3927 - lr: 0.0010\n",
            "Epoch 29/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:27:39.348958: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2835\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 219ms/step - loss: 1.9649 - categorical_accuracy: 0.6262 - val_loss: 3.1337 - val_categorical_accuracy: 0.4060 - lr: 0.0010\n",
            "Epoch 30/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:28:01.210365: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2873\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 233ms/step - loss: 1.8607 - categorical_accuracy: 0.6604 - val_loss: 3.3768 - val_categorical_accuracy: 0.3812 - lr: 0.0010\n",
            "Epoch 31/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:28:24.496330: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2911\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 223ms/step - loss: 2.0078 - categorical_accuracy: 0.6186 - val_loss: 3.3992 - val_categorical_accuracy: 0.3792 - lr: 0.0010\n",
            "Epoch 32/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:28:46.712317: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2949\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 232ms/step - loss: 1.8534 - categorical_accuracy: 0.6572 - val_loss: 3.1397 - val_categorical_accuracy: 0.4132 - lr: 0.0010\n",
            "Epoch 33/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:29:09.847688: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:2987\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 1.8017 - categorical_accuracy: 0.6761 - val_loss: 3.2345 - val_categorical_accuracy: 0.3911 - lr: 0.0010\n",
            "Epoch 34/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:29:32.132976: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3025\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 224ms/step - loss: 1.8187 - categorical_accuracy: 0.6658 - val_loss: 3.3766 - val_categorical_accuracy: 0.3864 - lr: 0.0010\n",
            "Epoch 35/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:29:54.583082: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3063\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 231ms/step - loss: 1.7117 - categorical_accuracy: 0.7038 - val_loss: 3.4854 - val_categorical_accuracy: 0.3853 - lr: 0.0010\n",
            "Epoch 36/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:30:17.943832: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3101\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 225ms/step - loss: 1.7363 - categorical_accuracy: 0.6940 - val_loss: 3.1087 - val_categorical_accuracy: 0.4272 - lr: 0.0010\n",
            "Epoch 37/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:30:40.461683: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3139\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 232ms/step - loss: 1.6674 - categorical_accuracy: 0.7132 - val_loss: 3.1727 - val_categorical_accuracy: 0.4154 - lr: 0.0010\n",
            "Epoch 38/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:31:03.691191: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3177\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 224ms/step - loss: 1.6654 - categorical_accuracy: 0.7125 - val_loss: 3.2621 - val_categorical_accuracy: 0.4074 - lr: 0.0010\n",
            "Epoch 39/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:31:26.405372: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3215\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 224ms/step - loss: 1.5996 - categorical_accuracy: 0.7340 - val_loss: 3.5674 - val_categorical_accuracy: 0.3929 - lr: 0.0010\n",
            "Epoch 40/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:31:48.891720: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3253\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 231ms/step - loss: 1.5961 - categorical_accuracy: 0.7339 - val_loss: 3.7029 - val_categorical_accuracy: 0.3890 - lr: 0.0010\n",
            "Epoch 41/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:32:11.978207: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3291\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 223ms/step - loss: 1.5148 - categorical_accuracy: 0.7579 - val_loss: 3.3549 - val_categorical_accuracy: 0.4152 - lr: 0.0010\n",
            "Epoch 42/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:32:34.392238: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3329\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 1.4225 - categorical_accuracy: 0.7876 - val_loss: 3.3937 - val_categorical_accuracy: 0.4243 - lr: 0.0010\n",
            "Epoch 43/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:32:56.665543: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3367\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 231ms/step - loss: 1.5981 - categorical_accuracy: 0.7291 - val_loss: 3.3741 - val_categorical_accuracy: 0.4147 - lr: 0.0010\n",
            "Epoch 44/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:33:19.942852: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3405\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 233ms/step - loss: 1.4135 - categorical_accuracy: 0.7890 - val_loss: 3.4388 - val_categorical_accuracy: 0.4043 - lr: 0.0010\n",
            "Epoch 45/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:33:43.298491: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3443\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 232ms/step - loss: 1.4937 - categorical_accuracy: 0.7614 - val_loss: 3.6867 - val_categorical_accuracy: 0.4028 - lr: 0.0010\n",
            "Epoch 46/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:34:06.475998: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3481\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 223ms/step - loss: 1.4184 - categorical_accuracy: 0.7862 - val_loss: 3.4099 - val_categorical_accuracy: 0.4221 - lr: 0.0010\n",
            "Epoch 47/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:34:28.837128: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3519\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 224ms/step - loss: 1.3397 - categorical_accuracy: 0.8131 - val_loss: 3.2637 - val_categorical_accuracy: 0.4376 - lr: 0.0010\n",
            "Epoch 48/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:34:51.234961: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3557\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 232ms/step - loss: 1.4115 - categorical_accuracy: 0.7888 - val_loss: 3.4637 - val_categorical_accuracy: 0.4311 - lr: 0.0010\n",
            "Epoch 49/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:35:14.598097: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3595\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 221ms/step - loss: 1.3055 - categorical_accuracy: 0.8218 - val_loss: 3.2748 - val_categorical_accuracy: 0.4311 - lr: 0.0010\n",
            "Epoch 50/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:35:36.989388: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3633\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 221ms/step - loss: 1.3311 - categorical_accuracy: 0.8127 - val_loss: 3.6863 - val_categorical_accuracy: 0.4187 - lr: 0.0010\n",
            "Epoch 51/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:35:59.159086: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3671\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 233ms/step - loss: 1.2955 - categorical_accuracy: 0.8242 - val_loss: 3.8674 - val_categorical_accuracy: 0.3767 - lr: 0.0010\n",
            "Epoch 52/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:36:22.488943: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3709\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 1.2071 - categorical_accuracy: 0.8563 - val_loss: 3.4435 - val_categorical_accuracy: 0.4253 - lr: 0.0010\n",
            "Epoch 53/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:36:44.730140: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3747\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 238ms/step - loss: 1.1521 - categorical_accuracy: 0.8697 - val_loss: 3.4980 - val_categorical_accuracy: 0.4478 - lr: 0.0010\n",
            "Epoch 54/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:37:08.591392: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3785\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 226ms/step - loss: 1.1511 - categorical_accuracy: 0.8692 - val_loss: 3.3326 - val_categorical_accuracy: 0.4453 - lr: 0.0010\n",
            "Epoch 55/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:37:31.197251: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3823\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 224ms/step - loss: 1.3595 - categorical_accuracy: 0.8018 - val_loss: 3.8511 - val_categorical_accuracy: 0.3997 - lr: 0.0010\n",
            "Epoch 56/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:37:53.586186: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3861\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 233ms/step - loss: 1.1814 - categorical_accuracy: 0.8636 - val_loss: 3.3964 - val_categorical_accuracy: 0.4446 - lr: 0.0010\n",
            "Epoch 57/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:38:16.881997: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3899\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 224ms/step - loss: 1.0800 - categorical_accuracy: 0.8923 - val_loss: 3.6274 - val_categorical_accuracy: 0.4349 - lr: 0.0010\n",
            "Epoch 58/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:38:39.330747: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3937\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 225ms/step - loss: 1.2804 - categorical_accuracy: 0.8260 - val_loss: 4.1785 - val_categorical_accuracy: 0.3947 - lr: 0.0010\n",
            "Epoch 59/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:39:02.105028: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:3975\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 229ms/step - loss: 1.2280 - categorical_accuracy: 0.8438 - val_loss: 4.1224 - val_categorical_accuracy: 0.3915 - lr: 0.0010\n",
            "Epoch 60/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:39:25.280254: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4013\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 224ms/step - loss: 1.1440 - categorical_accuracy: 0.8723 - val_loss: 3.7325 - val_categorical_accuracy: 0.4276 - lr: 0.0010\n",
            "Epoch 61/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:39:47.804450: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4051\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 233ms/step - loss: 1.0716 - categorical_accuracy: 0.8959 - val_loss: 3.6315 - val_categorical_accuracy: 0.4388 - lr: 0.0010\n",
            "Epoch 62/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:40:11.145235: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4089\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 234ms/step - loss: 1.0276 - categorical_accuracy: 0.9067 - val_loss: 3.5931 - val_categorical_accuracy: 0.4485 - lr: 0.0010\n",
            "Epoch 63/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:40:34.516609: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4127\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 226ms/step - loss: 1.0221 - categorical_accuracy: 0.9108 - val_loss: 3.5483 - val_categorical_accuracy: 0.4428 - lr: 0.0010\n",
            "Epoch 64/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:40:57.158552: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4165\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 233ms/step - loss: 1.0126 - categorical_accuracy: 0.9100 - val_loss: 3.8588 - val_categorical_accuracy: 0.4249 - lr: 0.0010\n",
            "Epoch 65/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:41:20.532262: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4203\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 1.2798 - categorical_accuracy: 0.8231 - val_loss: 5.0209 - val_categorical_accuracy: 0.3400 - lr: 0.0010\n",
            "Epoch 66/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:41:42.749431: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4241\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 231ms/step - loss: 1.1912 - categorical_accuracy: 0.8566 - val_loss: 3.9630 - val_categorical_accuracy: 0.4116 - lr: 0.0010\n",
            "Epoch 67/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:42:05.851188: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4279\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 224ms/step - loss: 1.0852 - categorical_accuracy: 0.8885 - val_loss: 3.6113 - val_categorical_accuracy: 0.4429 - lr: 0.0010\n",
            "Epoch 68/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:42:28.314090: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4317\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 1.0610 - categorical_accuracy: 0.8963 - val_loss: 3.6338 - val_categorical_accuracy: 0.4494 - lr: 0.0010\n",
            "Epoch 69/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:42:50.568406: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4355\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 231ms/step - loss: 1.0810 - categorical_accuracy: 0.8910 - val_loss: 4.1374 - val_categorical_accuracy: 0.4192 - lr: 0.0010\n",
            "Epoch 70/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:43:13.628140: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4393\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 225ms/step - loss: 1.0404 - categorical_accuracy: 0.8996 - val_loss: 3.7544 - val_categorical_accuracy: 0.4424 - lr: 0.0010\n",
            "Epoch 71/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:43:36.158298: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4431\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 1.0403 - categorical_accuracy: 0.9026 - val_loss: 3.7981 - val_categorical_accuracy: 0.4253 - lr: 0.0010\n",
            "Epoch 72/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:43:58.464697: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4469\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 25s 253ms/step - loss: 1.0187 - categorical_accuracy: 0.9059 - val_loss: 3.9172 - val_categorical_accuracy: 0.4189 - lr: 0.0010\n",
            "Epoch 73/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:44:23.926023: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4507\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 223ms/step - loss: 1.0215 - categorical_accuracy: 0.9029 - val_loss: 3.5344 - val_categorical_accuracy: 0.4681 - lr: 0.0010\n",
            "Epoch 74/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:44:46.485726: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4545\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 230ms/step - loss: 1.0770 - categorical_accuracy: 0.8841 - val_loss: 3.9170 - val_categorical_accuracy: 0.4065 - lr: 0.0010\n",
            "Epoch 75/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:45:09.684837: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4583\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 223ms/step - loss: 1.0519 - categorical_accuracy: 0.8971 - val_loss: 3.6965 - val_categorical_accuracy: 0.4487 - lr: 0.0010\n",
            "Epoch 76/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:45:32.138999: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4621\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 225ms/step - loss: 1.0339 - categorical_accuracy: 0.8999 - val_loss: 4.1026 - val_categorical_accuracy: 0.4225 - lr: 0.0010\n",
            "Epoch 77/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:45:54.722345: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4659\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 231ms/step - loss: 1.0156 - categorical_accuracy: 0.9067 - val_loss: 3.9723 - val_categorical_accuracy: 0.4280 - lr: 0.0010\n",
            "Epoch 78/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:46:17.991042: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4697\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 221ms/step - loss: 0.9594 - categorical_accuracy: 0.9258 - val_loss: 3.6388 - val_categorical_accuracy: 0.4675 - lr: 0.0010\n",
            "Epoch 79/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:46:40.196792: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4735\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 225ms/step - loss: 0.9854 - categorical_accuracy: 0.9127 - val_loss: 3.7841 - val_categorical_accuracy: 0.4425 - lr: 0.0010\n",
            "Epoch 80/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:47:02.803852: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4773\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 224ms/step - loss: 0.9935 - categorical_accuracy: 0.9100 - val_loss: 3.6803 - val_categorical_accuracy: 0.4541 - lr: 0.0010\n",
            "Epoch 81/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:47:25.462441: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4811\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 225ms/step - loss: 0.8431 - categorical_accuracy: 0.9634 - val_loss: 2.9912 - val_categorical_accuracy: 0.5356 - lr: 1.0000e-04\n",
            "Epoch 82/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:47:48.001670: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4849\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 229ms/step - loss: 0.7682 - categorical_accuracy: 0.9879 - val_loss: 2.9497 - val_categorical_accuracy: 0.5416 - lr: 1.0000e-04\n",
            "Epoch 83/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:48:10.932201: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4887\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 224ms/step - loss: 0.7513 - categorical_accuracy: 0.9921 - val_loss: 3.0057 - val_categorical_accuracy: 0.5396 - lr: 1.0000e-04\n",
            "Epoch 84/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:48:33.449236: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4925\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 0.7439 - categorical_accuracy: 0.9940 - val_loss: 2.9675 - val_categorical_accuracy: 0.5432 - lr: 1.0000e-04\n",
            "Epoch 85/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:48:55.658157: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:4963\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 231ms/step - loss: 0.7376 - categorical_accuracy: 0.9938 - val_loss: 2.9889 - val_categorical_accuracy: 0.5438 - lr: 1.0000e-04\n",
            "Epoch 86/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:49:18.688066: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5001\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 0.7274 - categorical_accuracy: 0.9961 - val_loss: 3.0059 - val_categorical_accuracy: 0.5422 - lr: 1.0000e-04\n",
            "Epoch 87/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:49:41.009768: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5039\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 229ms/step - loss: 0.7192 - categorical_accuracy: 0.9972 - val_loss: 2.9869 - val_categorical_accuracy: 0.5456 - lr: 1.0000e-04\n",
            "Epoch 88/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:50:22.692036: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5077\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 223ms/step - loss: 0.7124 - categorical_accuracy: 0.9973 - val_loss: 2.9877 - val_categorical_accuracy: 0.5447 - lr: 1.0000e-04\n",
            "Epoch 89/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:50:45.082293: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5115\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 233ms/step - loss: 0.7057 - categorical_accuracy: 0.9980 - val_loss: 3.0024 - val_categorical_accuracy: 0.5453 - lr: 1.0000e-04\n",
            "Epoch 90/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:51:08.379294: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5153\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 0.7009 - categorical_accuracy: 0.9980 - val_loss: 3.0194 - val_categorical_accuracy: 0.5472 - lr: 1.0000e-04\n",
            "Epoch 91/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:51:30.642841: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5191\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 222ms/step - loss: 0.6992 - categorical_accuracy: 0.9973 - val_loss: 3.0382 - val_categorical_accuracy: 0.5426 - lr: 1.0000e-04\n",
            "Epoch 92/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:51:52.912860: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5229\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 233ms/step - loss: 0.6919 - categorical_accuracy: 0.9976 - val_loss: 3.0259 - val_categorical_accuracy: 0.5440 - lr: 1.0000e-04\n",
            "Epoch 93/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:52:16.165109: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5267\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 224ms/step - loss: 0.6859 - categorical_accuracy: 0.9979 - val_loss: 3.0303 - val_categorical_accuracy: 0.5437 - lr: 1.0000e-04\n",
            "Epoch 94/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:52:38.548085: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5305\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 0.6794 - categorical_accuracy: 0.9981 - val_loss: 3.0372 - val_categorical_accuracy: 0.5456 - lr: 1.0000e-04\n",
            "Epoch 95/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:53:00.830641: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5343\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 229ms/step - loss: 0.6748 - categorical_accuracy: 0.9989 - val_loss: 3.0381 - val_categorical_accuracy: 0.5453 - lr: 1.0000e-04\n",
            "Epoch 96/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:53:23.828941: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5381\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 0.6681 - categorical_accuracy: 0.9990 - val_loss: 3.0535 - val_categorical_accuracy: 0.5462 - lr: 1.0000e-04\n",
            "Epoch 97/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:53:46.095108: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5419\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 232ms/step - loss: 0.6618 - categorical_accuracy: 0.9990 - val_loss: 3.0486 - val_categorical_accuracy: 0.5464 - lr: 1.0000e-04\n",
            "Epoch 98/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:54:09.231045: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5457\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 223ms/step - loss: 0.6577 - categorical_accuracy: 0.9990 - val_loss: 3.0315 - val_categorical_accuracy: 0.5472 - lr: 1.0000e-04\n",
            "Epoch 99/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:54:31.556753: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5495\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 224ms/step - loss: 0.6520 - categorical_accuracy: 0.9981 - val_loss: 3.0291 - val_categorical_accuracy: 0.5477 - lr: 1.0000e-04\n",
            "Epoch 100/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:54:53.905497: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5533\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 229ms/step - loss: 0.6459 - categorical_accuracy: 0.9990 - val_loss: 3.0391 - val_categorical_accuracy: 0.5463 - lr: 1.0000e-04\n",
            "Epoch 101/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:55:16.880768: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5571\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 225ms/step - loss: 0.6391 - categorical_accuracy: 0.9996 - val_loss: 3.0723 - val_categorical_accuracy: 0.5464 - lr: 1.0000e-04\n",
            "Epoch 102/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:55:39.487650: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5609\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 223ms/step - loss: 0.6347 - categorical_accuracy: 0.9987 - val_loss: 3.0322 - val_categorical_accuracy: 0.5479 - lr: 1.0000e-04\n",
            "Epoch 103/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:56:01.937145: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5647\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 237ms/step - loss: 0.6270 - categorical_accuracy: 0.9993 - val_loss: 3.0285 - val_categorical_accuracy: 0.5477 - lr: 1.0000e-04\n",
            "Epoch 104/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:56:26.228965: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5685\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 221ms/step - loss: 0.6227 - categorical_accuracy: 0.9991 - val_loss: 3.0483 - val_categorical_accuracy: 0.5477 - lr: 1.0000e-04\n",
            "Epoch 105/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:56:48.373861: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5723\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 231ms/step - loss: 0.6151 - categorical_accuracy: 0.9995 - val_loss: 3.0690 - val_categorical_accuracy: 0.5444 - lr: 1.0000e-04\n",
            "Epoch 106/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:57:11.457048: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5761\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 0.6088 - categorical_accuracy: 0.9994 - val_loss: 3.0604 - val_categorical_accuracy: 0.5467 - lr: 1.0000e-04\n",
            "Epoch 107/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:57:33.674538: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5799\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 226ms/step - loss: 0.6049 - categorical_accuracy: 0.9990 - val_loss: 3.0556 - val_categorical_accuracy: 0.5449 - lr: 1.0000e-04\n",
            "Epoch 108/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:57:56.247077: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5837\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 230ms/step - loss: 0.5970 - categorical_accuracy: 0.9986 - val_loss: 3.1130 - val_categorical_accuracy: 0.5441 - lr: 1.0000e-04\n",
            "Epoch 109/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:58:19.227969: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5875\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 224ms/step - loss: 0.5908 - categorical_accuracy: 0.9990 - val_loss: 3.0501 - val_categorical_accuracy: 0.5464 - lr: 1.0000e-04\n",
            "Epoch 110/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:58:41.682550: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5913\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 24s 244ms/step - loss: 0.5835 - categorical_accuracy: 0.9992 - val_loss: 3.0567 - val_categorical_accuracy: 0.5472 - lr: 1.0000e-04\n",
            "Epoch 111/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:59:06.028920: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5951\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 222ms/step - loss: 0.5801 - categorical_accuracy: 0.9986 - val_loss: 3.1057 - val_categorical_accuracy: 0.5437 - lr: 1.0000e-04\n",
            "Epoch 112/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:59:28.172487: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:5989\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 232ms/step - loss: 0.5737 - categorical_accuracy: 0.9988 - val_loss: 3.0893 - val_categorical_accuracy: 0.5422 - lr: 1.0000e-04\n",
            "Epoch 113/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 08:59:51.254662: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6027\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 232ms/step - loss: 0.5641 - categorical_accuracy: 0.9996 - val_loss: 3.0930 - val_categorical_accuracy: 0.5429 - lr: 1.0000e-04\n",
            "Epoch 114/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:00:14.351868: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6065\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 0.5593 - categorical_accuracy: 0.9990 - val_loss: 3.0752 - val_categorical_accuracy: 0.5446 - lr: 1.0000e-04\n",
            "Epoch 115/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:00:36.585231: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6103\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 24s 244ms/step - loss: 0.5520 - categorical_accuracy: 0.9994 - val_loss: 3.0722 - val_categorical_accuracy: 0.5418 - lr: 1.0000e-04\n",
            "Epoch 116/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:01:00.915716: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6141\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 234ms/step - loss: 0.5456 - categorical_accuracy: 0.9993 - val_loss: 3.0670 - val_categorical_accuracy: 0.5437 - lr: 1.0000e-04\n",
            "Epoch 117/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:01:24.342041: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6179\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 221ms/step - loss: 0.5405 - categorical_accuracy: 0.9989 - val_loss: 3.1184 - val_categorical_accuracy: 0.5437 - lr: 1.0000e-04\n",
            "Epoch 118/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:01:46.483299: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6217\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 231ms/step - loss: 0.5341 - categorical_accuracy: 0.9990 - val_loss: 3.0760 - val_categorical_accuracy: 0.5427 - lr: 1.0000e-04\n",
            "Epoch 119/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:02:09.595469: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6255\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 219ms/step - loss: 0.5262 - categorical_accuracy: 0.9997 - val_loss: 3.0998 - val_categorical_accuracy: 0.5393 - lr: 1.0000e-04\n",
            "Epoch 120/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:02:31.486118: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6293\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 222ms/step - loss: 0.5206 - categorical_accuracy: 0.9990 - val_loss: 3.1638 - val_categorical_accuracy: 0.5351 - lr: 1.0000e-04\n",
            "Epoch 121/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:02:53.685445: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6331\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 240ms/step - loss: 0.5181 - categorical_accuracy: 0.9988 - val_loss: 3.1188 - val_categorical_accuracy: 0.5413 - lr: 1.0000e-05\n",
            "Epoch 122/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:03:17.645486: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6369\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 221ms/step - loss: 0.5153 - categorical_accuracy: 0.9996 - val_loss: 3.1151 - val_categorical_accuracy: 0.5432 - lr: 1.0000e-05\n",
            "Epoch 123/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:03:39.762251: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6407\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 219ms/step - loss: 0.5136 - categorical_accuracy: 0.9995 - val_loss: 3.1049 - val_categorical_accuracy: 0.5431 - lr: 1.0000e-05\n",
            "Epoch 124/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:04:01.899388: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6445\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 230ms/step - loss: 0.5126 - categorical_accuracy: 0.9997 - val_loss: 3.0906 - val_categorical_accuracy: 0.5455 - lr: 1.0000e-05\n",
            "Epoch 125/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:04:25.112368: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6483\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 221ms/step - loss: 0.5124 - categorical_accuracy: 0.9992 - val_loss: 3.0866 - val_categorical_accuracy: 0.5451 - lr: 1.0000e-05\n",
            "Epoch 126/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:04:47.359807: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6521\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 233ms/step - loss: 0.5106 - categorical_accuracy: 0.9996 - val_loss: 3.0887 - val_categorical_accuracy: 0.5466 - lr: 1.0000e-05\n",
            "Epoch 127/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:05:10.807740: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6559\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 0.5100 - categorical_accuracy: 0.9995 - val_loss: 3.0830 - val_categorical_accuracy: 0.5455 - lr: 1.0000e-05\n",
            "Epoch 128/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:05:33.064679: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6597\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 220ms/step - loss: 0.5086 - categorical_accuracy: 0.9995 - val_loss: 3.0785 - val_categorical_accuracy: 0.5442 - lr: 1.0000e-05\n",
            "Epoch 129/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:05:55.030497: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6635\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 231ms/step - loss: 0.5075 - categorical_accuracy: 0.9998 - val_loss: 3.0837 - val_categorical_accuracy: 0.5446 - lr: 1.0000e-05\n",
            "Epoch 130/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:06:18.112790: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6673\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 225ms/step - loss: 0.5065 - categorical_accuracy: 0.9998 - val_loss: 3.0803 - val_categorical_accuracy: 0.5446 - lr: 1.0000e-05\n",
            "Epoch 131/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:06:40.638085: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6711\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 224ms/step - loss: 0.5060 - categorical_accuracy: 0.9998 - val_loss: 3.0857 - val_categorical_accuracy: 0.5447 - lr: 1.0000e-05\n",
            "Epoch 132/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:07:03.156283: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6749\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 223ms/step - loss: 0.5051 - categorical_accuracy: 0.9997 - val_loss: 3.0832 - val_categorical_accuracy: 0.5448 - lr: 1.0000e-05\n",
            "Epoch 133/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:07:25.735717: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6787\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 0.5037 - categorical_accuracy: 0.9999 - val_loss: 3.0830 - val_categorical_accuracy: 0.5445 - lr: 1.0000e-05\n",
            "Epoch 134/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:07:47.906670: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6825\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 231ms/step - loss: 0.5031 - categorical_accuracy: 0.9998 - val_loss: 3.0805 - val_categorical_accuracy: 0.5449 - lr: 1.0000e-05\n",
            "Epoch 135/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:08:10.998283: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6863\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 226ms/step - loss: 0.5023 - categorical_accuracy: 0.9998 - val_loss: 3.0815 - val_categorical_accuracy: 0.5454 - lr: 1.0000e-05\n",
            "Epoch 136/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:08:33.649925: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6901\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 220ms/step - loss: 0.5022 - categorical_accuracy: 0.9994 - val_loss: 3.0752 - val_categorical_accuracy: 0.5472 - lr: 1.0000e-05\n",
            "Epoch 137/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:08:55.672772: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6939\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 231ms/step - loss: 0.5008 - categorical_accuracy: 0.9995 - val_loss: 3.0799 - val_categorical_accuracy: 0.5474 - lr: 1.0000e-05\n",
            "Epoch 138/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:09:18.806048: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:6977\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 220ms/step - loss: 0.5002 - categorical_accuracy: 0.9997 - val_loss: 3.0846 - val_categorical_accuracy: 0.5471 - lr: 1.0000e-05\n",
            "Epoch 139/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:09:40.881619: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7015\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 234ms/step - loss: 0.4987 - categorical_accuracy: 1.0000 - val_loss: 3.0773 - val_categorical_accuracy: 0.5470 - lr: 1.0000e-05\n",
            "Epoch 140/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:10:04.331648: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7053\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 221ms/step - loss: 0.4978 - categorical_accuracy: 0.9998 - val_loss: 3.0815 - val_categorical_accuracy: 0.5471 - lr: 1.0000e-05\n",
            "Epoch 141/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:10:46.180333: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7091\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 231ms/step - loss: 0.4963 - categorical_accuracy: 0.9999 - val_loss: 3.0752 - val_categorical_accuracy: 0.5463 - lr: 1.0000e-05\n",
            "Epoch 142/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:11:09.197299: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7129\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 220ms/step - loss: 0.4954 - categorical_accuracy: 0.9999 - val_loss: 3.0756 - val_categorical_accuracy: 0.5456 - lr: 1.0000e-05\n",
            "Epoch 143/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:11:31.386043: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7167\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 225ms/step - loss: 0.4945 - categorical_accuracy: 1.0000 - val_loss: 3.0767 - val_categorical_accuracy: 0.5467 - lr: 1.0000e-05\n",
            "Epoch 144/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:11:53.922301: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7205\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 230ms/step - loss: 0.4935 - categorical_accuracy: 0.9998 - val_loss: 3.0792 - val_categorical_accuracy: 0.5453 - lr: 1.0000e-05\n",
            "Epoch 145/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:12:16.833802: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7243\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 222ms/step - loss: 0.4922 - categorical_accuracy: 0.9998 - val_loss: 3.0750 - val_categorical_accuracy: 0.5468 - lr: 1.0000e-05\n",
            "Epoch 146/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:12:39.042140: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7281\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 0.4914 - categorical_accuracy: 0.9999 - val_loss: 3.0724 - val_categorical_accuracy: 0.5485 - lr: 1.0000e-05\n",
            "Epoch 147/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:13:01.252997: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7319\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 228ms/step - loss: 0.4905 - categorical_accuracy: 0.9998 - val_loss: 3.0691 - val_categorical_accuracy: 0.5488 - lr: 1.0000e-05\n",
            "Epoch 148/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:13:24.471069: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7357\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 221ms/step - loss: 0.4892 - categorical_accuracy: 0.9999 - val_loss: 3.0755 - val_categorical_accuracy: 0.5472 - lr: 1.0000e-05\n",
            "Epoch 149/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:13:46.599576: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7395\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 233ms/step - loss: 0.4881 - categorical_accuracy: 0.9998 - val_loss: 3.0760 - val_categorical_accuracy: 0.5475 - lr: 1.0000e-05\n",
            "Epoch 150/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:14:09.889765: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7433\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 0.4867 - categorical_accuracy: 1.0000 - val_loss: 3.0703 - val_categorical_accuracy: 0.5490 - lr: 1.0000e-05\n",
            "Epoch 151/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:14:32.039448: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7471\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 220ms/step - loss: 0.4858 - categorical_accuracy: 0.9999 - val_loss: 3.0718 - val_categorical_accuracy: 0.5472 - lr: 1.0000e-05\n",
            "Epoch 152/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:14:54.073460: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7509\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 240ms/step - loss: 0.4848 - categorical_accuracy: 0.9999 - val_loss: 3.0698 - val_categorical_accuracy: 0.5474 - lr: 1.0000e-05\n",
            "Epoch 153/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:15:18.005026: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7547\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 219ms/step - loss: 0.4839 - categorical_accuracy: 0.9998 - val_loss: 3.0776 - val_categorical_accuracy: 0.5479 - lr: 1.0000e-05\n",
            "Epoch 154/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:15:39.880476: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7585\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 225ms/step - loss: 0.4823 - categorical_accuracy: 0.9999 - val_loss: 3.0779 - val_categorical_accuracy: 0.5487 - lr: 1.0000e-05\n",
            "Epoch 155/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:16:02.560219: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7623\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 227ms/step - loss: 0.4815 - categorical_accuracy: 0.9998 - val_loss: 3.0783 - val_categorical_accuracy: 0.5469 - lr: 1.0000e-05\n",
            "Epoch 156/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:16:25.540997: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7661\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 226ms/step - loss: 0.4799 - categorical_accuracy: 0.9999 - val_loss: 3.0722 - val_categorical_accuracy: 0.5476 - lr: 1.0000e-05\n",
            "Epoch 157/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:16:48.281319: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7699\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 229ms/step - loss: 0.4789 - categorical_accuracy: 0.9999 - val_loss: 3.0791 - val_categorical_accuracy: 0.5473 - lr: 1.0000e-05\n",
            "Epoch 158/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:17:11.381360: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7737\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 224ms/step - loss: 0.4779 - categorical_accuracy: 0.9998 - val_loss: 3.0704 - val_categorical_accuracy: 0.5467 - lr: 1.0000e-05\n",
            "Epoch 159/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:17:33.749974: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7775\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 219ms/step - loss: 0.4764 - categorical_accuracy: 0.9999 - val_loss: 3.0753 - val_categorical_accuracy: 0.5466 - lr: 1.0000e-05\n",
            "Epoch 160/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:17:55.721725: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7813\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 230ms/step - loss: 0.4752 - categorical_accuracy: 1.0000 - val_loss: 3.0826 - val_categorical_accuracy: 0.5470 - lr: 1.0000e-05\n",
            "Epoch 161/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:18:18.757388: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7851\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 223ms/step - loss: 0.4748 - categorical_accuracy: 0.9998 - val_loss: 3.0855 - val_categorical_accuracy: 0.5466 - lr: 1.0000e-06\n",
            "Epoch 162/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:18:41.072372: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7889\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 229ms/step - loss: 0.4745 - categorical_accuracy: 1.0000 - val_loss: 3.0837 - val_categorical_accuracy: 0.5457 - lr: 1.0000e-06\n",
            "Epoch 163/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:19:04.224260: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7927\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 232ms/step - loss: 0.4749 - categorical_accuracy: 0.9998 - val_loss: 3.0843 - val_categorical_accuracy: 0.5465 - lr: 1.0000e-06\n",
            "Epoch 164/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:19:27.587983: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:7965\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 223ms/step - loss: 0.4741 - categorical_accuracy: 0.9999 - val_loss: 3.0840 - val_categorical_accuracy: 0.5470 - lr: 1.0000e-06\n",
            "Epoch 165/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:19:50.056026: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8003\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 234ms/step - loss: 0.4741 - categorical_accuracy: 0.9999 - val_loss: 3.0825 - val_categorical_accuracy: 0.5469 - lr: 1.0000e-06\n",
            "Epoch 166/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:20:13.861088: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8041\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 226ms/step - loss: 0.4738 - categorical_accuracy: 1.0000 - val_loss: 3.0833 - val_categorical_accuracy: 0.5469 - lr: 1.0000e-06\n",
            "Epoch 167/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:20:36.943480: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8079\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 221ms/step - loss: 0.4743 - categorical_accuracy: 0.9999 - val_loss: 3.0840 - val_categorical_accuracy: 0.5478 - lr: 1.0000e-06\n",
            "Epoch 168/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:20:59.404654: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8117\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 233ms/step - loss: 0.4737 - categorical_accuracy: 0.9999 - val_loss: 3.0825 - val_categorical_accuracy: 0.5475 - lr: 1.0000e-06\n",
            "Epoch 169/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:21:22.888359: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8155\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 0.4734 - categorical_accuracy: 1.0000 - val_loss: 3.0827 - val_categorical_accuracy: 0.5476 - lr: 1.0000e-06\n",
            "Epoch 170/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:21:45.282941: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8193\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 231ms/step - loss: 0.4730 - categorical_accuracy: 0.9999 - val_loss: 3.0817 - val_categorical_accuracy: 0.5470 - lr: 1.0000e-06\n",
            "Epoch 171/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:22:08.534477: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8231\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 0.4738 - categorical_accuracy: 0.9998 - val_loss: 3.0830 - val_categorical_accuracy: 0.5474 - lr: 1.0000e-06\n",
            "Epoch 172/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:22:30.962549: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8269\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 223ms/step - loss: 0.4729 - categorical_accuracy: 1.0000 - val_loss: 3.0849 - val_categorical_accuracy: 0.5468 - lr: 1.0000e-06\n",
            "Epoch 173/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:22:53.456438: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8307\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 233ms/step - loss: 0.4733 - categorical_accuracy: 0.9999 - val_loss: 3.0846 - val_categorical_accuracy: 0.5468 - lr: 1.0000e-06\n",
            "Epoch 174/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:23:16.942937: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8345\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 226ms/step - loss: 0.4730 - categorical_accuracy: 0.9998 - val_loss: 3.0852 - val_categorical_accuracy: 0.5470 - lr: 1.0000e-06\n",
            "Epoch 175/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:23:39.636617: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8383\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 226ms/step - loss: 0.4730 - categorical_accuracy: 1.0000 - val_loss: 3.0856 - val_categorical_accuracy: 0.5459 - lr: 1.0000e-06\n",
            "Epoch 176/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:24:02.561770: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8421\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 227ms/step - loss: 0.4724 - categorical_accuracy: 0.9999 - val_loss: 3.0857 - val_categorical_accuracy: 0.5467 - lr: 1.0000e-06\n",
            "Epoch 177/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:24:25.721468: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8459\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 220ms/step - loss: 0.4723 - categorical_accuracy: 0.9998 - val_loss: 3.0840 - val_categorical_accuracy: 0.5468 - lr: 1.0000e-06\n",
            "Epoch 178/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:24:47.856111: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8497\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 231ms/step - loss: 0.4723 - categorical_accuracy: 1.0000 - val_loss: 3.0845 - val_categorical_accuracy: 0.5461 - lr: 1.0000e-06\n",
            "Epoch 179/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:25:11.024596: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8535\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 227ms/step - loss: 0.4721 - categorical_accuracy: 0.9999 - val_loss: 3.0816 - val_categorical_accuracy: 0.5467 - lr: 1.0000e-06\n",
            "Epoch 180/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:25:33.783578: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8573\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 0.4720 - categorical_accuracy: 0.9998 - val_loss: 3.0829 - val_categorical_accuracy: 0.5466 - lr: 1.0000e-06\n",
            "Epoch 181/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:25:56.054637: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8611\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 231ms/step - loss: 0.4721 - categorical_accuracy: 0.9998 - val_loss: 3.0834 - val_categorical_accuracy: 0.5471 - lr: 5.0000e-07\n",
            "Epoch 182/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:26:19.154314: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8649\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 220ms/step - loss: 0.4718 - categorical_accuracy: 0.9999 - val_loss: 3.0831 - val_categorical_accuracy: 0.5466 - lr: 5.0000e-07\n",
            "Epoch 183/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:26:41.253783: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8687\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 236ms/step - loss: 0.4718 - categorical_accuracy: 0.9998 - val_loss: 3.0836 - val_categorical_accuracy: 0.5468 - lr: 5.0000e-07\n",
            "Epoch 184/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:27:05.046077: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8725\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 221ms/step - loss: 0.4721 - categorical_accuracy: 0.9997 - val_loss: 3.0820 - val_categorical_accuracy: 0.5466 - lr: 5.0000e-07\n",
            "Epoch 185/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:27:27.239554: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8763\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 219ms/step - loss: 0.4715 - categorical_accuracy: 0.9999 - val_loss: 3.0813 - val_categorical_accuracy: 0.5462 - lr: 5.0000e-07\n",
            "Epoch 186/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:27:49.290748: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8801\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 232ms/step - loss: 0.4717 - categorical_accuracy: 0.9999 - val_loss: 3.0809 - val_categorical_accuracy: 0.5464 - lr: 5.0000e-07\n",
            "Epoch 187/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:28:12.528795: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8839\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 0.4717 - categorical_accuracy: 0.9999 - val_loss: 3.0826 - val_categorical_accuracy: 0.5464 - lr: 5.0000e-07\n",
            "Epoch 188/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:28:34.753161: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8877\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 226ms/step - loss: 0.4714 - categorical_accuracy: 1.0000 - val_loss: 3.0822 - val_categorical_accuracy: 0.5463 - lr: 5.0000e-07\n",
            "Epoch 189/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:28:57.452569: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8915\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 231ms/step - loss: 0.4716 - categorical_accuracy: 1.0000 - val_loss: 3.0822 - val_categorical_accuracy: 0.5465 - lr: 5.0000e-07\n",
            "Epoch 190/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:29:20.501831: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8953\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 222ms/step - loss: 0.4715 - categorical_accuracy: 0.9999 - val_loss: 3.0808 - val_categorical_accuracy: 0.5470 - lr: 5.0000e-07\n",
            "Epoch 191/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:29:42.800887: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:8991\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 228ms/step - loss: 0.4711 - categorical_accuracy: 0.9998 - val_loss: 3.0813 - val_categorical_accuracy: 0.5469 - lr: 5.0000e-07\n",
            "Epoch 192/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:30:05.652189: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9029\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 225ms/step - loss: 0.4711 - categorical_accuracy: 1.0000 - val_loss: 3.0828 - val_categorical_accuracy: 0.5470 - lr: 5.0000e-07\n",
            "Epoch 193/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:30:28.312868: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9067\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 220ms/step - loss: 0.4714 - categorical_accuracy: 0.9999 - val_loss: 3.0831 - val_categorical_accuracy: 0.5470 - lr: 5.0000e-07\n",
            "Epoch 194/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:30:50.540456: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9105\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 232ms/step - loss: 0.4715 - categorical_accuracy: 0.9999 - val_loss: 3.0816 - val_categorical_accuracy: 0.5471 - lr: 5.0000e-07\n",
            "Epoch 195/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:31:13.723307: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9143\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 223ms/step - loss: 0.4709 - categorical_accuracy: 1.0000 - val_loss: 3.0818 - val_categorical_accuracy: 0.5464 - lr: 5.0000e-07\n",
            "Epoch 196/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:31:36.056775: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9181\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 221ms/step - loss: 0.4708 - categorical_accuracy: 0.9999 - val_loss: 3.0823 - val_categorical_accuracy: 0.5465 - lr: 5.0000e-07\n",
            "Epoch 197/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:31:58.129127: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9219\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 23s 232ms/step - loss: 0.4710 - categorical_accuracy: 0.9999 - val_loss: 3.0820 - val_categorical_accuracy: 0.5466 - lr: 5.0000e-07\n",
            "Epoch 198/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:32:21.325869: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9257\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 221ms/step - loss: 0.4708 - categorical_accuracy: 1.0000 - val_loss: 3.0814 - val_categorical_accuracy: 0.5468 - lr: 5.0000e-07\n",
            "Epoch 199/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:32:43.496075: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9295\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 22s 231ms/step - loss: 0.4708 - categorical_accuracy: 0.9999 - val_loss: 3.0821 - val_categorical_accuracy: 0.5462 - lr: 5.0000e-07\n",
            "Epoch 200/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:33:06.539515: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9333\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 21s 221ms/step - loss: 0.4705 - categorical_accuracy: 0.9999 - val_loss: 3.0818 - val_categorical_accuracy: 0.5464 - lr: 5.0000e-07\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# from google3.pyglib import gfile\n",
        "\n",
        "# Training the teacher\n",
        "teacher_params = {\n",
        "    'dataset': _DATASET,\n",
        "    'epochs': _TEACHER_EPOCHS,\n",
        "    'optimizer': _TEACHER_OPTIMIZER,\n",
        "    'labeled_percentage': _SIZE_OF_DATASET_A,\n",
        "    'architecture': _TEACHER_MODEL,\n",
        "    'data_augmentation': _TEACHER_DATA_AUGMENTATION\n",
        "    }\n",
        "\n",
        "if _TEACHER_MODEL == 'mobilenet':\n",
        "  teacher_params['depth'] = _TEACHER_MOBILENET_DEPTH_MULTIPLIER\n",
        "elif _TEACHER_MODEL == 'resnet':\n",
        "  teacher_params['depth'] = _TEACHER_RESNET_DEPTH\n",
        "\n",
        "teacher_filename = 'TEACHER' + str(teacher_params)\n",
        "\n",
        "teacher_filepath = os.path.join(_CNS_PATH, teacher_filename)\n",
        "\n",
        "\n",
        "teacher_load_temp_filename = 'temp_teacher_load.h5'\n",
        "teacher_save_temp_filename = 'temp_teacher_save.h5'\n",
        "\n",
        "# Training the teacher\n",
        "with strategy.scope():\n",
        "  teacher_model = load_model(\n",
        "        _TEACHER_MODEL,\n",
        "        num_classes,\n",
        "        _TEACHER_OPTIMIZER,\n",
        "        width_multiplier=1.0,\n",
        "        depth_multiplier=_TEACHER_MOBILENET_DEPTH_MULTIPLIER,\n",
        "        resnet_depth=_TEACHER_RESNET_DEPTH)\n",
        "\n",
        "# if gfile.Exists(teacher_filepath):\n",
        "#   gfile.Copy(teacher_filepath, teacher_load_temp_filename, overwrite=True)\n",
        "#   with strategy.scope():\n",
        "#     teacher_model.load_weights(teacher_load_temp_filename)\n",
        "# else:\n",
        "_ = train_model(\n",
        "      teacher_model,\n",
        "      data_split.dataset_a.examples,\n",
        "      data_split.dataset_a.labels,\n",
        "      data_split.test.examples,\n",
        "      data_split.test.labels,\n",
        "      data_augmentation=_TEACHER_DATA_AUGMENTATION,\n",
        "      epochs=_TEACHER_EPOCHS)\n",
        "\n",
        "  # # If the provided CNS path is not empty try to save the teacher model.\n",
        "  # if _CNS_PATH:\n",
        "  #   with strategy.scope():\n",
        "  #     teacher_model.save_weights(teacher_save_temp_filename)\n",
        "  #   gfile.Copy(teacher_save_temp_filename, teacher_filepath, overwrite=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "t57Im5BNojtX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 9s 28ms/step - loss: 3.0818 - categorical_accuracy: 0.5464\n",
            "The teacher's accuracy is: 54.64000105857849\n"
          ]
        }
      ],
      "source": [
        "score = teacher_model.evaluate(data_split.test.examples,\n",
        "                                data_split.test.labels)\n",
        "\n",
        "if isinstance(score, (list, tuple, np.ndarray)):\n",
        "  teacher_accuracy = score[1] * 100.0\n",
        "print(\"The teacher's accuracy is:\", teacher_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # saving the teacher model with 0.15 labeled data\n",
        "# tf.saved_model.save(teacher_model, f\"/home/hp/Google_Paper/results/cifar100/{_SIZE_OF_DATASET_A}/ResNet110\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaGtmGokI2u9"
      },
      "source": [
        "# Pretrain/Load the Student Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lic0dqXJpFOP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:33:38.859641: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9392\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17/97 [====>.........................] - ETA: 6s - loss: 5.6215 - categorical_accuracy: 0.0299"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 51s 144ms/step - loss: 5.2106 - categorical_accuracy: 0.0731 - val_loss: 5.2490 - val_categorical_accuracy: 0.0531 - lr: 0.0010\n",
            "Epoch 2/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:34:30.896317: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9430\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 4.6837 - categorical_accuracy: 0.1214 - val_loss: 4.9075 - val_categorical_accuracy: 0.0832 - lr: 0.0010\n",
            "Epoch 3/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:34:44.246724: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9468\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 4.3601 - categorical_accuracy: 0.1600 - val_loss: 4.5821 - val_categorical_accuracy: 0.1196 - lr: 0.0010\n",
            "Epoch 4/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:34:57.604461: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9506\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 143ms/step - loss: 4.1149 - categorical_accuracy: 0.1846 - val_loss: 4.2069 - val_categorical_accuracy: 0.1659 - lr: 0.0010\n",
            "Epoch 5/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:35:12.104996: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9544\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 136ms/step - loss: 3.8784 - categorical_accuracy: 0.2190 - val_loss: 4.5544 - val_categorical_accuracy: 0.1315 - lr: 0.0010\n",
            "Epoch 6/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:35:26.079942: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9582\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 3.6805 - categorical_accuracy: 0.2503 - val_loss: 3.9087 - val_categorical_accuracy: 0.2049 - lr: 0.0010\n",
            "Epoch 7/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:35:39.330163: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9620\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 3.5049 - categorical_accuracy: 0.2722 - val_loss: 4.3314 - val_categorical_accuracy: 0.1633 - lr: 0.0010\n",
            "Epoch 8/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:35:52.808019: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9658\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 137ms/step - loss: 3.3433 - categorical_accuracy: 0.2970 - val_loss: 3.7606 - val_categorical_accuracy: 0.2216 - lr: 0.0010\n",
            "Epoch 9/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:36:06.720269: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9696\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 3.1941 - categorical_accuracy: 0.3236 - val_loss: 3.9038 - val_categorical_accuracy: 0.2087 - lr: 0.0010\n",
            "Epoch 10/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:36:20.163987: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9734\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 3.0796 - categorical_accuracy: 0.3504 - val_loss: 3.6324 - val_categorical_accuracy: 0.2455 - lr: 0.0010\n",
            "Epoch 11/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:36:33.336155: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9772\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 2.9784 - categorical_accuracy: 0.3628 - val_loss: 3.6587 - val_categorical_accuracy: 0.2386 - lr: 0.0010\n",
            "Epoch 12/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:36:46.756144: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9810\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 3.0068 - categorical_accuracy: 0.3607 - val_loss: 3.3845 - val_categorical_accuracy: 0.2884 - lr: 0.0010\n",
            "Epoch 13/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:37:00.142816: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9848\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 15s 158ms/step - loss: 2.7865 - categorical_accuracy: 0.4047 - val_loss: 3.4280 - val_categorical_accuracy: 0.2921 - lr: 0.0010\n",
            "Epoch 14/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:37:16.095894: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9886\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 2.6954 - categorical_accuracy: 0.4257 - val_loss: 3.5575 - val_categorical_accuracy: 0.2781 - lr: 0.0010\n",
            "Epoch 15/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:37:29.496770: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9924\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 2.6011 - categorical_accuracy: 0.4422 - val_loss: 3.5807 - val_categorical_accuracy: 0.2851 - lr: 0.0010\n",
            "Epoch 16/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:37:42.870114: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\027TensorSliceDataset:9962\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 2.7098 - categorical_accuracy: 0.4185 - val_loss: 3.2357 - val_categorical_accuracy: 0.3260 - lr: 0.0010\n",
            "Epoch 17/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:37:56.258577: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10000\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 136ms/step - loss: 2.4784 - categorical_accuracy: 0.4779 - val_loss: 3.1167 - val_categorical_accuracy: 0.3552 - lr: 0.0010\n",
            "Epoch 18/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:38:10.152970: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10038\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 2.5271 - categorical_accuracy: 0.4612 - val_loss: 3.4460 - val_categorical_accuracy: 0.3136 - lr: 0.0010\n",
            "Epoch 19/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:38:23.575064: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10076\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 2.3486 - categorical_accuracy: 0.5053 - val_loss: 3.2239 - val_categorical_accuracy: 0.3387 - lr: 0.0010\n",
            "Epoch 20/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:38:36.828150: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10114\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 134ms/step - loss: 2.4050 - categorical_accuracy: 0.4895 - val_loss: 3.4255 - val_categorical_accuracy: 0.3014 - lr: 0.0010\n",
            "Epoch 21/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:38:50.485546: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10152\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 140ms/step - loss: 2.2389 - categorical_accuracy: 0.5288 - val_loss: 3.4898 - val_categorical_accuracy: 0.3153 - lr: 0.0010\n",
            "Epoch 22/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:39:04.808674: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10190\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 2.1418 - categorical_accuracy: 0.5540 - val_loss: 3.3783 - val_categorical_accuracy: 0.3132 - lr: 0.0010\n",
            "Epoch 23/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:39:18.319937: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10228\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 2.0851 - categorical_accuracy: 0.5643 - val_loss: 3.7273 - val_categorical_accuracy: 0.3093 - lr: 0.0010\n",
            "Epoch 24/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:39:31.674880: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10266\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 2.2613 - categorical_accuracy: 0.5234 - val_loss: 2.9668 - val_categorical_accuracy: 0.3976 - lr: 0.0010\n",
            "Epoch 25/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:39:44.991420: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10304\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 1.9891 - categorical_accuracy: 0.5950 - val_loss: 3.2535 - val_categorical_accuracy: 0.3472 - lr: 0.0010\n",
            "Epoch 26/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:39:58.252315: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10342\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 143ms/step - loss: 2.1399 - categorical_accuracy: 0.5516 - val_loss: 3.2816 - val_categorical_accuracy: 0.3586 - lr: 0.0010\n",
            "Epoch 27/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:40:12.755244: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10380\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 1.9100 - categorical_accuracy: 0.6142 - val_loss: 3.0879 - val_categorical_accuracy: 0.3833 - lr: 0.0010\n",
            "Epoch 28/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:40:26.349223: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10418\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 133ms/step - loss: 1.8382 - categorical_accuracy: 0.6289 - val_loss: 3.1237 - val_categorical_accuracy: 0.3831 - lr: 0.0010\n",
            "Epoch 29/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:40:40.147980: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10456\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 1.7655 - categorical_accuracy: 0.6514 - val_loss: 3.1152 - val_categorical_accuracy: 0.3737 - lr: 0.0010\n",
            "Epoch 30/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:40:53.534993: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10494\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 140ms/step - loss: 1.7129 - categorical_accuracy: 0.6583 - val_loss: 3.5806 - val_categorical_accuracy: 0.3275 - lr: 0.0010\n",
            "Epoch 31/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:41:07.758484: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10532\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 2.0109 - categorical_accuracy: 0.5859 - val_loss: 3.3275 - val_categorical_accuracy: 0.3699 - lr: 0.0010\n",
            "Epoch 32/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:41:21.266227: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10570\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 1.6763 - categorical_accuracy: 0.6765 - val_loss: 3.0633 - val_categorical_accuracy: 0.3987 - lr: 0.0010\n",
            "Epoch 33/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:41:34.742041: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10608\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 1.5789 - categorical_accuracy: 0.6991 - val_loss: 3.0699 - val_categorical_accuracy: 0.3977 - lr: 0.0010\n",
            "Epoch 34/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:41:48.060660: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10646\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 1.8802 - categorical_accuracy: 0.6172 - val_loss: 3.6661 - val_categorical_accuracy: 0.3519 - lr: 0.0010\n",
            "Epoch 35/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:42:01.315748: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10684\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 143ms/step - loss: 1.5512 - categorical_accuracy: 0.7118 - val_loss: 3.1642 - val_categorical_accuracy: 0.3864 - lr: 0.0010\n",
            "Epoch 36/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:42:15.810690: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10722\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 1.7406 - categorical_accuracy: 0.6517 - val_loss: 3.3917 - val_categorical_accuracy: 0.3725 - lr: 0.0010\n",
            "Epoch 37/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:42:29.276974: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10760\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 1.4874 - categorical_accuracy: 0.7322 - val_loss: 3.0581 - val_categorical_accuracy: 0.4051 - lr: 0.0010\n",
            "Epoch 38/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:42:42.727368: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10798\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 1.3975 - categorical_accuracy: 0.7593 - val_loss: 3.2218 - val_categorical_accuracy: 0.3945 - lr: 0.0010\n",
            "Epoch 39/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:42:56.196582: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10836\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 139ms/step - loss: 1.3536 - categorical_accuracy: 0.7688 - val_loss: 3.1695 - val_categorical_accuracy: 0.3999 - lr: 0.0010\n",
            "Epoch 40/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:43:10.396755: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10874\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 1.3347 - categorical_accuracy: 0.7752 - val_loss: 3.6629 - val_categorical_accuracy: 0.3853 - lr: 0.0010\n",
            "Epoch 41/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:43:23.597602: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10912\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 1.6981 - categorical_accuracy: 0.6654 - val_loss: 3.5026 - val_categorical_accuracy: 0.3897 - lr: 0.0010\n",
            "Epoch 42/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:43:37.137348: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10950\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 133ms/step - loss: 1.2988 - categorical_accuracy: 0.7887 - val_loss: 3.1879 - val_categorical_accuracy: 0.4132 - lr: 0.0010\n",
            "Epoch 43/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:43:50.907024: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:10988\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 138ms/step - loss: 1.2147 - categorical_accuracy: 0.8188 - val_loss: 3.2172 - val_categorical_accuracy: 0.4196 - lr: 0.0010\n",
            "Epoch 44/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:44:05.213780: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11026\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 1.1966 - categorical_accuracy: 0.8195 - val_loss: 3.4418 - val_categorical_accuracy: 0.3885 - lr: 0.0010\n",
            "Epoch 45/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:44:18.576852: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11064\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 1.6273 - categorical_accuracy: 0.6855 - val_loss: 3.8005 - val_categorical_accuracy: 0.3662 - lr: 0.0010\n",
            "Epoch 46/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:44:32.086158: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11102\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 1.2158 - categorical_accuracy: 0.8195 - val_loss: 3.3126 - val_categorical_accuracy: 0.4149 - lr: 0.0010\n",
            "Epoch 47/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:44:45.407277: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11140\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 1.0930 - categorical_accuracy: 0.8527 - val_loss: 3.3146 - val_categorical_accuracy: 0.4067 - lr: 0.0010\n",
            "Epoch 48/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:44:58.763102: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11178\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 139ms/step - loss: 1.0823 - categorical_accuracy: 0.8568 - val_loss: 3.6637 - val_categorical_accuracy: 0.3953 - lr: 0.0010\n",
            "Epoch 49/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:45:13.001726: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11216\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 1.0393 - categorical_accuracy: 0.8719 - val_loss: 3.7661 - val_categorical_accuracy: 0.3991 - lr: 0.0010\n",
            "Epoch 50/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:45:26.430597: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11254\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 133ms/step - loss: 1.5603 - categorical_accuracy: 0.7056 - val_loss: 3.5952 - val_categorical_accuracy: 0.4091 - lr: 0.0010\n",
            "Epoch 51/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:45:40.013889: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11292\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 1.1118 - categorical_accuracy: 0.8487 - val_loss: 3.3360 - val_categorical_accuracy: 0.4365 - lr: 0.0010\n",
            "Epoch 52/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:45:53.382337: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11330\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 139ms/step - loss: 0.9947 - categorical_accuracy: 0.8883 - val_loss: 3.2961 - val_categorical_accuracy: 0.4352 - lr: 0.0010\n",
            "Epoch 53/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:46:07.660559: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11368\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 0.9689 - categorical_accuracy: 0.8924 - val_loss: 3.5545 - val_categorical_accuracy: 0.3950 - lr: 0.0010\n",
            "Epoch 54/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:46:21.112230: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11406\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 1.4549 - categorical_accuracy: 0.7369 - val_loss: 4.0728 - val_categorical_accuracy: 0.3756 - lr: 0.0010\n",
            "Epoch 55/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:46:34.624100: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11444\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 1.0529 - categorical_accuracy: 0.8714 - val_loss: 3.9457 - val_categorical_accuracy: 0.3926 - lr: 0.0010\n",
            "Epoch 56/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:46:47.874840: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11482\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 1.2886 - categorical_accuracy: 0.7875 - val_loss: 3.9828 - val_categorical_accuracy: 0.3836 - lr: 0.0010\n",
            "Epoch 57/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:47:01.370016: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11520\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 146ms/step - loss: 1.2069 - categorical_accuracy: 0.8146 - val_loss: 3.6696 - val_categorical_accuracy: 0.4129 - lr: 0.0010\n",
            "Epoch 58/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:47:16.601561: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11558\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 1.1182 - categorical_accuracy: 0.8468 - val_loss: 3.5238 - val_categorical_accuracy: 0.4299 - lr: 0.0010\n",
            "Epoch 59/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:47:30.055579: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11596\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 1.0435 - categorical_accuracy: 0.8690 - val_loss: 3.6026 - val_categorical_accuracy: 0.4132 - lr: 0.0010\n",
            "Epoch 60/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:47:43.414250: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11634\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 1.1003 - categorical_accuracy: 0.8491 - val_loss: 3.4916 - val_categorical_accuracy: 0.4115 - lr: 0.0010\n",
            "Epoch 61/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:47:56.663368: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11672\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 141ms/step - loss: 1.0624 - categorical_accuracy: 0.8611 - val_loss: 3.4975 - val_categorical_accuracy: 0.4216 - lr: 0.0010\n",
            "Epoch 62/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:48:10.994930: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11710\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 1.0075 - categorical_accuracy: 0.8793 - val_loss: 3.4829 - val_categorical_accuracy: 0.4365 - lr: 0.0010\n",
            "Epoch 63/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:48:24.427364: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11748\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.9247 - categorical_accuracy: 0.9083 - val_loss: 3.6802 - val_categorical_accuracy: 0.4364 - lr: 0.0010\n",
            "Epoch 64/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:48:37.767203: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11786\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 133ms/step - loss: 0.9033 - categorical_accuracy: 0.9134 - val_loss: 3.9343 - val_categorical_accuracy: 0.4135 - lr: 0.0010\n",
            "Epoch 65/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:48:51.292000: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11824\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 143ms/step - loss: 1.1297 - categorical_accuracy: 0.8363 - val_loss: 3.8497 - val_categorical_accuracy: 0.4114 - lr: 0.0010\n",
            "Epoch 66/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:49:05.861382: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11862\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 0.9727 - categorical_accuracy: 0.8943 - val_loss: 3.6110 - val_categorical_accuracy: 0.4283 - lr: 0.0010\n",
            "Epoch 67/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:49:19.292558: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11900\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 1.0447 - categorical_accuracy: 0.8666 - val_loss: 3.8514 - val_categorical_accuracy: 0.4216 - lr: 0.0010\n",
            "Epoch 68/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:49:32.581147: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11938\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 0.9957 - categorical_accuracy: 0.8818 - val_loss: 3.8876 - val_categorical_accuracy: 0.4098 - lr: 0.0010\n",
            "Epoch 69/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:49:46.124691: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:11976\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 12s 128ms/step - loss: 0.9364 - categorical_accuracy: 0.9050 - val_loss: 3.4630 - val_categorical_accuracy: 0.4481 - lr: 0.0010\n",
            "Epoch 70/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:49:59.299183: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12014\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 139ms/step - loss: 0.8735 - categorical_accuracy: 0.9220 - val_loss: 3.7172 - val_categorical_accuracy: 0.4278 - lr: 0.0010\n",
            "Epoch 71/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:50:13.521408: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12052\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 0.8432 - categorical_accuracy: 0.9328 - val_loss: 3.6300 - val_categorical_accuracy: 0.4331 - lr: 0.0010\n",
            "Epoch 72/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:50:26.754891: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12090\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 0.8467 - categorical_accuracy: 0.9280 - val_loss: 3.7801 - val_categorical_accuracy: 0.4348 - lr: 0.0010\n",
            "Epoch 73/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:50:40.215305: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12128\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.8523 - categorical_accuracy: 0.9285 - val_loss: 3.9162 - val_categorical_accuracy: 0.4272 - lr: 0.0010\n",
            "Epoch 74/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:50:53.471170: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12166\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 140ms/step - loss: 0.8618 - categorical_accuracy: 0.9216 - val_loss: 3.9116 - val_categorical_accuracy: 0.4206 - lr: 0.0010\n",
            "Epoch 75/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:51:07.698575: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12204\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 133ms/step - loss: 1.1700 - categorical_accuracy: 0.8222 - val_loss: 5.0745 - val_categorical_accuracy: 0.3473 - lr: 0.0010\n",
            "Epoch 76/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:51:21.318580: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12242\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.9403 - categorical_accuracy: 0.8991 - val_loss: 3.7555 - val_categorical_accuracy: 0.4388 - lr: 0.0010\n",
            "Epoch 77/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:51:34.674753: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12280\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.8108 - categorical_accuracy: 0.9437 - val_loss: 3.7382 - val_categorical_accuracy: 0.4328 - lr: 0.0010\n",
            "Epoch 78/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:51:48.007862: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12318\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 12s 128ms/step - loss: 0.7756 - categorical_accuracy: 0.9534 - val_loss: 3.5939 - val_categorical_accuracy: 0.4411 - lr: 0.0010\n",
            "Epoch 79/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:52:01.279359: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12356\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 140ms/step - loss: 0.7679 - categorical_accuracy: 0.9533 - val_loss: 3.7545 - val_categorical_accuracy: 0.4527 - lr: 0.0010\n",
            "Epoch 80/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:52:16.043229: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12394\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 0.7890 - categorical_accuracy: 0.9410 - val_loss: 4.1914 - val_categorical_accuracy: 0.4058 - lr: 0.0010\n",
            "Epoch 81/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:52:29.795786: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12432\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 0.6987 - categorical_accuracy: 0.9750 - val_loss: 3.2224 - val_categorical_accuracy: 0.5053 - lr: 1.0000e-04\n",
            "Epoch 82/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:52:43.001744: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12470\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 0.7417 - categorical_accuracy: 0.9599 - val_loss: 3.1861 - val_categorical_accuracy: 0.5090 - lr: 1.0000e-04\n",
            "Epoch 83/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:52:56.399502: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12508\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 142ms/step - loss: 0.6326 - categorical_accuracy: 0.9952 - val_loss: 3.1626 - val_categorical_accuracy: 0.5173 - lr: 1.0000e-04\n",
            "Epoch 84/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:53:10.855891: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12546\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.6226 - categorical_accuracy: 0.9967 - val_loss: 3.1590 - val_categorical_accuracy: 0.5188 - lr: 1.0000e-04\n",
            "Epoch 85/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:53:24.383634: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12584\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 0.6811 - categorical_accuracy: 0.9800 - val_loss: 3.1756 - val_categorical_accuracy: 0.5154 - lr: 1.0000e-04\n",
            "Epoch 86/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:53:37.544219: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12622\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.6640 - categorical_accuracy: 0.9851 - val_loss: 3.2068 - val_categorical_accuracy: 0.5158 - lr: 1.0000e-04\n",
            "Epoch 87/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:53:50.863315: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12660\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 144ms/step - loss: 0.6527 - categorical_accuracy: 0.9894 - val_loss: 3.2043 - val_categorical_accuracy: 0.5122 - lr: 1.0000e-04\n",
            "Epoch 88/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:54:05.586513: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12698\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 0.6075 - categorical_accuracy: 0.9981 - val_loss: 3.1803 - val_categorical_accuracy: 0.5187 - lr: 1.0000e-04\n",
            "Epoch 89/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:54:18.848182: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12736\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 133ms/step - loss: 0.6392 - categorical_accuracy: 0.9910 - val_loss: 3.2170 - val_categorical_accuracy: 0.5139 - lr: 1.0000e-04\n",
            "Epoch 90/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:54:32.420148: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12774\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.6005 - categorical_accuracy: 0.9982 - val_loss: 3.2179 - val_categorical_accuracy: 0.5159 - lr: 1.0000e-04\n",
            "Epoch 91/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:54:45.663148: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12812\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 142ms/step - loss: 0.6293 - categorical_accuracy: 0.9918 - val_loss: 3.2103 - val_categorical_accuracy: 0.5162 - lr: 1.0000e-04\n",
            "Epoch 92/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:55:00.140307: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12850\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 144ms/step - loss: 0.5943 - categorical_accuracy: 0.9990 - val_loss: 3.2131 - val_categorical_accuracy: 0.5190 - lr: 1.0000e-04\n",
            "Epoch 93/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:55:14.946522: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12888\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 133ms/step - loss: 0.5917 - categorical_accuracy: 0.9986 - val_loss: 3.2067 - val_categorical_accuracy: 0.5175 - lr: 1.0000e-04\n",
            "Epoch 94/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:55:28.799241: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12926\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 138ms/step - loss: 0.5861 - categorical_accuracy: 0.9994 - val_loss: 3.2052 - val_categorical_accuracy: 0.5197 - lr: 1.0000e-04\n",
            "Epoch 95/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:55:43.123980: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:12964\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 0.6138 - categorical_accuracy: 0.9928 - val_loss: 3.2131 - val_categorical_accuracy: 0.5131 - lr: 1.0000e-04\n",
            "Epoch 96/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:55:56.833253: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13002\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 140ms/step - loss: 0.5818 - categorical_accuracy: 0.9993 - val_loss: 3.2209 - val_categorical_accuracy: 0.5169 - lr: 1.0000e-04\n",
            "Epoch 97/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:56:11.260897: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13040\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 0.6049 - categorical_accuracy: 0.9942 - val_loss: 3.2900 - val_categorical_accuracy: 0.5153 - lr: 1.0000e-04\n",
            "Epoch 98/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:56:24.804493: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13078\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.5984 - categorical_accuracy: 0.9955 - val_loss: 3.2636 - val_categorical_accuracy: 0.5157 - lr: 1.0000e-04\n",
            "Epoch 99/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:56:38.257103: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13116\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.5935 - categorical_accuracy: 0.9957 - val_loss: 3.2383 - val_categorical_accuracy: 0.5172 - lr: 1.0000e-04\n",
            "Epoch 100/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:56:51.679402: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13154\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 142ms/step - loss: 0.5913 - categorical_accuracy: 0.9952 - val_loss: 3.3027 - val_categorical_accuracy: 0.5136 - lr: 1.0000e-04\n",
            "Epoch 101/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:57:06.185736: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13192\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 133ms/step - loss: 0.5838 - categorical_accuracy: 0.9959 - val_loss: 3.3032 - val_categorical_accuracy: 0.5144 - lr: 1.0000e-04\n",
            "Epoch 102/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:57:19.869980: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13230\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 134ms/step - loss: 0.5651 - categorical_accuracy: 0.9990 - val_loss: 3.2848 - val_categorical_accuracy: 0.5170 - lr: 1.0000e-04\n",
            "Epoch 103/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:57:33.761446: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13268\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 12s 128ms/step - loss: 0.5759 - categorical_accuracy: 0.9973 - val_loss: 3.2747 - val_categorical_accuracy: 0.5165 - lr: 1.0000e-04\n",
            "Epoch 104/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:57:47.034590: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13306\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 0.5583 - categorical_accuracy: 0.9992 - val_loss: 3.2811 - val_categorical_accuracy: 0.5189 - lr: 1.0000e-04\n",
            "Epoch 105/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:58:00.355073: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13344\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 141ms/step - loss: 0.5676 - categorical_accuracy: 0.9977 - val_loss: 3.2837 - val_categorical_accuracy: 0.5152 - lr: 1.0000e-04\n",
            "Epoch 106/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:58:14.761648: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13382\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.5644 - categorical_accuracy: 0.9973 - val_loss: 3.3187 - val_categorical_accuracy: 0.5177 - lr: 1.0000e-04\n",
            "Epoch 107/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:58:28.245653: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13420\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 133ms/step - loss: 0.5594 - categorical_accuracy: 0.9977 - val_loss: 3.3166 - val_categorical_accuracy: 0.5139 - lr: 1.0000e-04\n",
            "Epoch 108/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:58:41.839918: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13458\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 0.5544 - categorical_accuracy: 0.9980 - val_loss: 3.3301 - val_categorical_accuracy: 0.5152 - lr: 1.0000e-04\n",
            "Epoch 109/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:58:55.410735: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13496\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 15s 153ms/step - loss: 0.5520 - categorical_accuracy: 0.9976 - val_loss: 3.3208 - val_categorical_accuracy: 0.5136 - lr: 1.0000e-04\n",
            "Epoch 110/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:59:11.012362: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13534\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 0.5451 - categorical_accuracy: 0.9989 - val_loss: 3.3284 - val_categorical_accuracy: 0.5148 - lr: 1.0000e-04\n",
            "Epoch 111/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:59:24.245604: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13572\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.5344 - categorical_accuracy: 0.9987 - val_loss: 3.3515 - val_categorical_accuracy: 0.5167 - lr: 1.0000e-04\n",
            "Epoch 112/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:59:37.754682: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13610\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 0.5291 - categorical_accuracy: 0.9994 - val_loss: 3.3087 - val_categorical_accuracy: 0.5191 - lr: 1.0000e-04\n",
            "Epoch 113/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 09:59:50.965634: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13648\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 140ms/step - loss: 0.5249 - categorical_accuracy: 0.9997 - val_loss: 3.2724 - val_categorical_accuracy: 0.5198 - lr: 1.0000e-04\n",
            "Epoch 114/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:00:05.326045: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13686\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.5215 - categorical_accuracy: 0.9992 - val_loss: 3.3047 - val_categorical_accuracy: 0.5163 - lr: 1.0000e-04\n",
            "Epoch 115/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:00:18.751994: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13724\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.5323 - categorical_accuracy: 0.9969 - val_loss: 3.2923 - val_categorical_accuracy: 0.5143 - lr: 1.0000e-04\n",
            "Epoch 116/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:00:32.117015: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13762\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 136ms/step - loss: 0.5260 - categorical_accuracy: 0.9981 - val_loss: 3.3906 - val_categorical_accuracy: 0.5111 - lr: 1.0000e-04\n",
            "Epoch 117/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:00:46.242439: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13800\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.5123 - categorical_accuracy: 0.9992 - val_loss: 3.3626 - val_categorical_accuracy: 0.5138 - lr: 1.0000e-04\n",
            "Epoch 118/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:00:59.780420: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13838\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 138ms/step - loss: 0.5182 - categorical_accuracy: 0.9978 - val_loss: 3.3626 - val_categorical_accuracy: 0.5099 - lr: 1.0000e-04\n",
            "Epoch 119/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:01:13.939629: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13876\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.5130 - categorical_accuracy: 0.9980 - val_loss: 3.3575 - val_categorical_accuracy: 0.5118 - lr: 1.0000e-04\n",
            "Epoch 120/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:01:27.302661: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13914\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.4998 - categorical_accuracy: 0.9997 - val_loss: 3.3217 - val_categorical_accuracy: 0.5172 - lr: 1.0000e-04\n",
            "Epoch 121/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:01:40.624160: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13952\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4975 - categorical_accuracy: 0.9991 - val_loss: 3.3217 - val_categorical_accuracy: 0.5183 - lr: 1.0000e-05\n",
            "Epoch 122/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:01:54.070247: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:13990\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 138ms/step - loss: 0.4957 - categorical_accuracy: 0.9996 - val_loss: 3.3241 - val_categorical_accuracy: 0.5184 - lr: 1.0000e-05\n",
            "Epoch 123/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:02:08.176230: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14028\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 0.5027 - categorical_accuracy: 0.9990 - val_loss: 3.3381 - val_categorical_accuracy: 0.5184 - lr: 1.0000e-05\n",
            "Epoch 124/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:02:21.714819: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14066\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.5013 - categorical_accuracy: 0.9986 - val_loss: 3.3425 - val_categorical_accuracy: 0.5167 - lr: 1.0000e-05\n",
            "Epoch 125/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:02:35.118193: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14104\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 0.4940 - categorical_accuracy: 0.9998 - val_loss: 3.3264 - val_categorical_accuracy: 0.5184 - lr: 1.0000e-05\n",
            "Epoch 126/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:02:48.580566: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14142\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 0.4932 - categorical_accuracy: 0.9997 - val_loss: 3.3263 - val_categorical_accuracy: 0.5195 - lr: 1.0000e-05\n",
            "Epoch 127/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:03:02.143099: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14180\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 134ms/step - loss: 0.4989 - categorical_accuracy: 0.9987 - val_loss: 3.3376 - val_categorical_accuracy: 0.5195 - lr: 1.0000e-05\n",
            "Epoch 128/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:03:16.215128: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14218\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4980 - categorical_accuracy: 0.9993 - val_loss: 3.3438 - val_categorical_accuracy: 0.5191 - lr: 1.0000e-05\n",
            "Epoch 129/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:03:29.566162: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14256\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 0.4916 - categorical_accuracy: 0.9998 - val_loss: 3.3298 - val_categorical_accuracy: 0.5200 - lr: 1.0000e-05\n",
            "Epoch 130/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:03:42.792558: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14294\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.4911 - categorical_accuracy: 1.0000 - val_loss: 3.3252 - val_categorical_accuracy: 0.5212 - lr: 1.0000e-05\n",
            "Epoch 131/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:03:56.151528: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14332\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 146ms/step - loss: 0.4907 - categorical_accuracy: 0.9998 - val_loss: 3.3271 - val_categorical_accuracy: 0.5206 - lr: 1.0000e-05\n",
            "Epoch 132/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:04:11.018064: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14370\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4902 - categorical_accuracy: 0.9997 - val_loss: 3.3228 - val_categorical_accuracy: 0.5206 - lr: 1.0000e-05\n",
            "Epoch 133/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:04:24.627653: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14408\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4959 - categorical_accuracy: 0.9988 - val_loss: 3.3333 - val_categorical_accuracy: 0.5199 - lr: 1.0000e-05\n",
            "Epoch 134/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:04:38.039069: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14446\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.4888 - categorical_accuracy: 0.9998 - val_loss: 3.3262 - val_categorical_accuracy: 0.5190 - lr: 1.0000e-05\n",
            "Epoch 135/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:04:51.439217: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14484\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 140ms/step - loss: 0.4948 - categorical_accuracy: 0.9989 - val_loss: 3.3268 - val_categorical_accuracy: 0.5199 - lr: 1.0000e-05\n",
            "Epoch 136/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:05:05.785987: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14522\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4935 - categorical_accuracy: 0.9990 - val_loss: 3.3322 - val_categorical_accuracy: 0.5207 - lr: 1.0000e-05\n",
            "Epoch 137/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:05:19.242355: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14560\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 0.4875 - categorical_accuracy: 0.9998 - val_loss: 3.3241 - val_categorical_accuracy: 0.5206 - lr: 1.0000e-05\n",
            "Epoch 138/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:05:32.741206: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14598\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.4928 - categorical_accuracy: 0.9990 - val_loss: 3.3319 - val_categorical_accuracy: 0.5201 - lr: 1.0000e-05\n",
            "Epoch 139/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:05:46.040167: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14636\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 0.4919 - categorical_accuracy: 0.9991 - val_loss: 3.3427 - val_categorical_accuracy: 0.5190 - lr: 1.0000e-05\n",
            "Epoch 140/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:05:59.491831: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14674\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 140ms/step - loss: 0.4903 - categorical_accuracy: 0.9994 - val_loss: 3.3371 - val_categorical_accuracy: 0.5202 - lr: 1.0000e-05\n",
            "Epoch 141/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:06:13.689746: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14712\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4855 - categorical_accuracy: 0.9997 - val_loss: 3.3181 - val_categorical_accuracy: 0.5212 - lr: 1.0000e-05\n",
            "Epoch 142/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:06:27.125724: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14750\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.4851 - categorical_accuracy: 0.9994 - val_loss: 3.3131 - val_categorical_accuracy: 0.5200 - lr: 1.0000e-05\n",
            "Epoch 143/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:06:40.530445: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14788\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 12s 128ms/step - loss: 0.4836 - categorical_accuracy: 0.9999 - val_loss: 3.3139 - val_categorical_accuracy: 0.5211 - lr: 1.0000e-05\n",
            "Epoch 144/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:06:53.607801: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14826\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 141ms/step - loss: 0.4832 - categorical_accuracy: 0.9997 - val_loss: 3.3205 - val_categorical_accuracy: 0.5212 - lr: 1.0000e-05\n",
            "Epoch 145/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:07:07.953996: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14864\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4827 - categorical_accuracy: 0.9998 - val_loss: 3.3195 - val_categorical_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 146/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:07:21.342857: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14902\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 136ms/step - loss: 0.4815 - categorical_accuracy: 0.9999 - val_loss: 3.3257 - val_categorical_accuracy: 0.5210 - lr: 1.0000e-05\n",
            "Epoch 147/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:07:35.234716: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14940\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.4859 - categorical_accuracy: 0.9994 - val_loss: 3.3320 - val_categorical_accuracy: 0.5210 - lr: 1.0000e-05\n",
            "Epoch 148/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:07:48.566627: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:14978\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 134ms/step - loss: 0.4851 - categorical_accuracy: 0.9996 - val_loss: 3.3347 - val_categorical_accuracy: 0.5215 - lr: 1.0000e-05\n",
            "Epoch 149/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:08:02.427960: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15016\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 133ms/step - loss: 0.4846 - categorical_accuracy: 0.9994 - val_loss: 3.3394 - val_categorical_accuracy: 0.5207 - lr: 1.0000e-05\n",
            "Epoch 150/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:08:16.253435: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15054\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4792 - categorical_accuracy: 0.9996 - val_loss: 3.3287 - val_categorical_accuracy: 0.5214 - lr: 1.0000e-05\n",
            "Epoch 151/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:08:29.692034: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15092\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4786 - categorical_accuracy: 0.9998 - val_loss: 3.3265 - val_categorical_accuracy: 0.5207 - lr: 1.0000e-05\n",
            "Epoch 152/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:08:43.132477: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15130\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.4779 - categorical_accuracy: 0.9998 - val_loss: 3.3230 - val_categorical_accuracy: 0.5203 - lr: 1.0000e-05\n",
            "Epoch 153/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:08:56.430718: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15168\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 142ms/step - loss: 0.4773 - categorical_accuracy: 0.9997 - val_loss: 3.3254 - val_categorical_accuracy: 0.5208 - lr: 1.0000e-05\n",
            "Epoch 154/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:09:11.025961: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15206\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4767 - categorical_accuracy: 0.9997 - val_loss: 3.3272 - val_categorical_accuracy: 0.5207 - lr: 1.0000e-05\n",
            "Epoch 155/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:09:24.703518: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15244\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4803 - categorical_accuracy: 0.9998 - val_loss: 3.3340 - val_categorical_accuracy: 0.5187 - lr: 1.0000e-05\n",
            "Epoch 156/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:09:38.173976: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15282\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 0.4793 - categorical_accuracy: 0.9995 - val_loss: 3.3343 - val_categorical_accuracy: 0.5202 - lr: 1.0000e-05\n",
            "Epoch 157/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:09:51.347886: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15320\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 139ms/step - loss: 0.4743 - categorical_accuracy: 0.9998 - val_loss: 3.3287 - val_categorical_accuracy: 0.5211 - lr: 1.0000e-05\n",
            "Epoch 158/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:10:05.515419: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15358\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 133ms/step - loss: 0.4737 - categorical_accuracy: 0.9998 - val_loss: 3.3289 - val_categorical_accuracy: 0.5201 - lr: 1.0000e-05\n",
            "Epoch 159/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:10:19.219509: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15396\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 0.4785 - categorical_accuracy: 0.9994 - val_loss: 3.3436 - val_categorical_accuracy: 0.5208 - lr: 1.0000e-05\n",
            "Epoch 160/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:10:32.513159: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15434\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 133ms/step - loss: 0.4772 - categorical_accuracy: 0.9996 - val_loss: 3.3443 - val_categorical_accuracy: 0.5203 - lr: 1.0000e-05\n",
            "Epoch 161/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:10:46.137572: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15472\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 0.4718 - categorical_accuracy: 0.9999 - val_loss: 3.3400 - val_categorical_accuracy: 0.5196 - lr: 1.0000e-06\n",
            "Epoch 162/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:10:59.607161: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15510\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 142ms/step - loss: 0.4763 - categorical_accuracy: 0.9994 - val_loss: 3.3491 - val_categorical_accuracy: 0.5192 - lr: 1.0000e-06\n",
            "Epoch 163/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:11:14.115637: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15548\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4761 - categorical_accuracy: 0.9994 - val_loss: 3.3495 - val_categorical_accuracy: 0.5200 - lr: 1.0000e-06\n",
            "Epoch 164/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:11:27.537480: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15586\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4758 - categorical_accuracy: 0.9996 - val_loss: 3.3518 - val_categorical_accuracy: 0.5199 - lr: 1.0000e-06\n",
            "Epoch 165/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:11:41.001517: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15624\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4763 - categorical_accuracy: 0.9997 - val_loss: 3.3494 - val_categorical_accuracy: 0.5200 - lr: 1.0000e-06\n",
            "Epoch 166/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:11:54.429214: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15662\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 137ms/step - loss: 0.4718 - categorical_accuracy: 0.9996 - val_loss: 3.3400 - val_categorical_accuracy: 0.5204 - lr: 1.0000e-06\n",
            "Epoch 167/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:12:08.457427: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15700\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4712 - categorical_accuracy: 1.0000 - val_loss: 3.3371 - val_categorical_accuracy: 0.5191 - lr: 1.0000e-06\n",
            "Epoch 168/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:12:21.848434: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15738\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 133ms/step - loss: 0.4713 - categorical_accuracy: 0.9998 - val_loss: 3.3347 - val_categorical_accuracy: 0.5200 - lr: 1.0000e-06\n",
            "Epoch 169/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:12:35.504049: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15776\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.4758 - categorical_accuracy: 0.9993 - val_loss: 3.3443 - val_categorical_accuracy: 0.5202 - lr: 1.0000e-06\n",
            "Epoch 170/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:12:49.065938: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15814\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 133ms/step - loss: 0.4751 - categorical_accuracy: 0.9999 - val_loss: 3.3496 - val_categorical_accuracy: 0.5192 - lr: 1.0000e-06\n",
            "Epoch 171/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:13:02.798254: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15852\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 137ms/step - loss: 0.4754 - categorical_accuracy: 0.9996 - val_loss: 3.3525 - val_categorical_accuracy: 0.5193 - lr: 1.0000e-06\n",
            "Epoch 172/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:13:16.971561: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15890\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4708 - categorical_accuracy: 0.9998 - val_loss: 3.3410 - val_categorical_accuracy: 0.5196 - lr: 1.0000e-06\n",
            "Epoch 173/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:13:30.382218: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15928\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 0.4752 - categorical_accuracy: 0.9998 - val_loss: 3.3465 - val_categorical_accuracy: 0.5199 - lr: 1.0000e-06\n",
            "Epoch 174/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:13:43.917066: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:15966\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4748 - categorical_accuracy: 0.9997 - val_loss: 3.3512 - val_categorical_accuracy: 0.5200 - lr: 1.0000e-06\n",
            "Epoch 175/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:13:57.288302: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16004\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 14s 139ms/step - loss: 0.4708 - categorical_accuracy: 0.9998 - val_loss: 3.3419 - val_categorical_accuracy: 0.5203 - lr: 1.0000e-06\n",
            "Epoch 176/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:14:11.478226: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16042\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 136ms/step - loss: 0.4744 - categorical_accuracy: 0.9995 - val_loss: 3.3443 - val_categorical_accuracy: 0.5195 - lr: 1.0000e-06\n",
            "Epoch 177/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:14:25.285419: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16080\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 0.4751 - categorical_accuracy: 0.9994 - val_loss: 3.3489 - val_categorical_accuracy: 0.5193 - lr: 1.0000e-06\n",
            "Epoch 178/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:14:38.872048: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16118\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 0.4746 - categorical_accuracy: 0.9994 - val_loss: 3.3517 - val_categorical_accuracy: 0.5187 - lr: 1.0000e-06\n",
            "Epoch 179/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:14:52.144930: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16156\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 138ms/step - loss: 0.4746 - categorical_accuracy: 0.9998 - val_loss: 3.3516 - val_categorical_accuracy: 0.5188 - lr: 1.0000e-06\n",
            "Epoch 180/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:15:06.196199: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16194\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 129ms/step - loss: 0.4754 - categorical_accuracy: 0.9994 - val_loss: 3.3512 - val_categorical_accuracy: 0.5199 - lr: 1.0000e-06\n",
            "Epoch 181/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:15:19.372139: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16232\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4703 - categorical_accuracy: 0.9998 - val_loss: 3.3400 - val_categorical_accuracy: 0.5198 - lr: 5.0000e-07\n",
            "Epoch 182/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:15:32.797178: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16270\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4704 - categorical_accuracy: 0.9999 - val_loss: 3.3360 - val_categorical_accuracy: 0.5198 - lr: 5.0000e-07\n",
            "Epoch 183/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:15:46.333810: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16308\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 136ms/step - loss: 0.4744 - categorical_accuracy: 0.9994 - val_loss: 3.3454 - val_categorical_accuracy: 0.5194 - lr: 5.0000e-07\n",
            "Epoch 184/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:16:00.246499: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16346\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 139ms/step - loss: 0.4743 - categorical_accuracy: 0.9997 - val_loss: 3.3516 - val_categorical_accuracy: 0.5195 - lr: 5.0000e-07\n",
            "Epoch 185/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:16:14.356891: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16384\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4702 - categorical_accuracy: 0.9998 - val_loss: 3.3423 - val_categorical_accuracy: 0.5195 - lr: 5.0000e-07\n",
            "Epoch 186/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:16:27.782687: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16422\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4706 - categorical_accuracy: 0.9998 - val_loss: 3.3382 - val_categorical_accuracy: 0.5194 - lr: 5.0000e-07\n",
            "Epoch 187/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:16:41.229698: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16460\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4745 - categorical_accuracy: 0.9997 - val_loss: 3.3480 - val_categorical_accuracy: 0.5191 - lr: 5.0000e-07\n",
            "Epoch 188/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:16:54.571658: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16498\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 138ms/step - loss: 0.4742 - categorical_accuracy: 0.9997 - val_loss: 3.3494 - val_categorical_accuracy: 0.5191 - lr: 5.0000e-07\n",
            "Epoch 189/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:17:08.687052: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16536\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4746 - categorical_accuracy: 0.9990 - val_loss: 3.3496 - val_categorical_accuracy: 0.5185 - lr: 5.0000e-07\n",
            "Epoch 190/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:17:22.209024: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16574\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4739 - categorical_accuracy: 0.9994 - val_loss: 3.3532 - val_categorical_accuracy: 0.5198 - lr: 5.0000e-07\n",
            "Epoch 191/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:17:35.772342: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16612\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 134ms/step - loss: 0.4746 - categorical_accuracy: 0.9997 - val_loss: 3.3511 - val_categorical_accuracy: 0.5195 - lr: 5.0000e-07\n",
            "Epoch 192/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:17:49.721440: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16650\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 135ms/step - loss: 0.4740 - categorical_accuracy: 0.9998 - val_loss: 3.3500 - val_categorical_accuracy: 0.5199 - lr: 5.0000e-07\n",
            "Epoch 193/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:18:03.602591: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16688\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 136ms/step - loss: 0.4740 - categorical_accuracy: 0.9998 - val_loss: 3.3510 - val_categorical_accuracy: 0.5196 - lr: 5.0000e-07\n",
            "Epoch 194/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:18:17.549310: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16726\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.4735 - categorical_accuracy: 0.9997 - val_loss: 3.3511 - val_categorical_accuracy: 0.5195 - lr: 5.0000e-07\n",
            "Epoch 195/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:18:30.888173: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16764\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 132ms/step - loss: 0.4701 - categorical_accuracy: 0.9998 - val_loss: 3.3417 - val_categorical_accuracy: 0.5193 - lr: 5.0000e-07\n",
            "Epoch 196/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:18:44.355724: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16802\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 130ms/step - loss: 0.4699 - categorical_accuracy: 0.9998 - val_loss: 3.3377 - val_categorical_accuracy: 0.5193 - lr: 5.0000e-07\n",
            "Epoch 197/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:18:57.588570: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16840\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 137ms/step - loss: 0.4742 - categorical_accuracy: 0.9997 - val_loss: 3.3456 - val_categorical_accuracy: 0.5194 - lr: 5.0000e-07\n",
            "Epoch 198/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:19:11.669558: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16878\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 133ms/step - loss: 0.4733 - categorical_accuracy: 0.9998 - val_loss: 3.3492 - val_categorical_accuracy: 0.5200 - lr: 5.0000e-07\n",
            "Epoch 199/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:19:25.331291: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16916\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4732 - categorical_accuracy: 0.9998 - val_loss: 3.3488 - val_categorical_accuracy: 0.5193 - lr: 5.0000e-07\n",
            "Epoch 200/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:19:38.844848: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 12500\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:16954\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97/97 [==============================] - 13s 131ms/step - loss: 0.4699 - categorical_accuracy: 0.9998 - val_loss: 3.3389 - val_categorical_accuracy: 0.5200 - lr: 5.0000e-07\n",
            "313/313 [==============================] - 6s 17ms/step - loss: 3.3389 - categorical_accuracy: 0.5200\n",
            "pretrained model test-accuracy: 51.99999809265137\n"
          ]
        }
      ],
      "source": [
        "if _SOFT_LABEL_DATASET_A:\n",
        "  # If true then extend dataset_a with its examples soft-labeled by teacher.\n",
        "  teacher_predictions = teacher_model.predict(data_split.dataset_a.examples)\n",
        "  data_split.dataset_a.examples = tf.concat(\n",
        "      (data_split.dataset_a.examples, data_split.dataset_a.examples), axis=0)\n",
        "  data_split.dataset_a.labels = tf.concat(\n",
        "      (data_split.dataset_a.labels, teacher_predictions), axis=0)\n",
        "\n",
        "student_params = {\n",
        "    'dataset': _DATASET,\n",
        "    'epochs': _PRETRAINING_EPOCHS,\n",
        "    'optimizer': _STUDENT_OPTIMIZER,\n",
        "    'labeled_percentage': _SIZE_OF_DATASET_A,\n",
        "    'architecture': _STUDENT_MODEL,\n",
        "    'data_augmentation': _STUDENT_PRETRAINING_DATA_AUGMENTATION\n",
        "    }\n",
        "\n",
        "if _STUDENT_MODEL == 'mobilenet':\n",
        "  student_params['depth'] = _STUDENT_MOBILENET_DEPTH_MULTIPLIER\n",
        "elif _STUDENT_MODEL == 'resnet':\n",
        "  student_params['depth'] = _STUDENT_RESNET_DEPTH\n",
        "\n",
        "student_filename = 'STUDENT' + str(student_params)\n",
        "\n",
        "student_filepath = os.path.join(_CNS_PATH, student_filename)\n",
        "\n",
        "student_load_temp_filename = 'pretrained_weights.h5'\n",
        "student_save_temp_filename = 'pretrained_weights.h5'\n",
        "\n",
        "with strategy.scope():\n",
        "  model_pretrained = load_model(\n",
        "      _STUDENT_MODEL,\n",
        "      num_classes,\n",
        "      _STUDENT_OPTIMIZER,\n",
        "      width_multiplier=1.0,\n",
        "      depth_multiplier=_STUDENT_MOBILENET_DEPTH_MULTIPLIER,\n",
        "      resnet_depth=_STUDENT_RESNET_DEPTH)\n",
        "\n",
        "# if gfile.Exists(student_filepath):\n",
        "#   gfile.Copy(student_filepath, student_load_temp_filename, overwrite=True)\n",
        "#   with strategy.scope():\n",
        "#     model_pretrained.load_weights(student_load_temp_filename)\n",
        "# else:\n",
        "train_model(\n",
        "    model_pretrained,\n",
        "    data_split.dataset_a.examples,\n",
        "    data_split.dataset_a.labels,\n",
        "    data_split.test.examples,\n",
        "    data_split.test.labels,\n",
        "    data_augmentation=_STUDENT_PRETRAINING_DATA_AUGMENTATION,\n",
        "    epochs=_PRETRAINING_EPOCHS)\n",
        "\n",
        "with strategy.scope():\n",
        "  model_pretrained.save_weights(student_save_temp_filename)\n",
        "\n",
        "  # If path is not empty then save pretrained student model.\n",
        "  # if _CNS_PATH:\n",
        "  #   gfile.Copy(student_save_temp_filename, student_filepath, overwrite=True)\n",
        "\n",
        "scores = model_pretrained.evaluate(\n",
        "    data_split.test.examples, data_split.test.labels, verbose=1)\n",
        "print('pretrained model test-accuracy:', scores[1] * 100.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-sNmGYSPWIZ"
      },
      "source": [
        "# Estimate Teacher's Accuracy (Isotonic Regression)\n",
        "\n",
        "Use either (normalized) entropy or (normalized) margin to estimate teacher's model accuracy.  We assume that the probability that a label from the teacher\n",
        "is correct is monotone with respect to the margin and enforce this monotonicity\n",
        "in our regression problem via Isotonic Regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "uC03_ES3PTMr",
        "outputId": "dcf3bb39-ee51-4487-dc45-0cec18e9aa76"
      },
      "outputs": [],
      "source": [
        "import dataclasses\n",
        "from typing import Callable, Optional\n",
        "\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class Advice:\n",
        "  \"\"\"Class for advice used in distillation.\n",
        "\n",
        "  Attributes\n",
        "    ----------\n",
        "    train: tf.Tensor\n",
        "        A tensor containing the advice for the training data.\n",
        "    validation: tf.Tensor\n",
        "        A tensor containing the advice for the validation data.\n",
        "    pretraining: tf.Tensor\n",
        "        A tensor containing the advice for the pretraining data.\n",
        "    test: tf.Tensor\n",
        "        A tensor containing the advice for the test data.\n",
        "  \"\"\"\n",
        "  train: Optional[tf.Tensor] = None\n",
        "  validation: Optional[tf.Tensor] = None\n",
        "  pretraining: Optional[tf.Tensor] = None\n",
        "  test: Optional[tf.Tensor] = None\n",
        "\n",
        "\n",
        "def margin(x: tf.Tensor,\n",
        "           with_logits: Optional[bool] = False,\n",
        "           normalize: Optional[bool] = False) -> tf.Tensor:\n",
        "  \"\"\"Computes the margin of a probability/logit tensor.\"\"\"\n",
        "\n",
        "  if with_logits:\n",
        "    class_probabilities = tf.nn.softmax(x, axis=None, name=None)\n",
        "  else:\n",
        "    class_probabilities = x\n",
        "  a, _ = tf.math.top_k(class_probabilities, k=2)\n",
        "  marg = (tf.gather(a, [0], axis=1) - tf.gather(a, [1], axis=1))\n",
        "\n",
        "  if normalize:\n",
        "    marg = marg/tf.math.reduce_mean(marg)\n",
        "\n",
        "  return marg\n",
        "\n",
        "\n",
        "def entropy(x: tf.Tensor,\n",
        "            with_logits: Optional[bool] = False,\n",
        "            normalize: Optional[bool] = False) -> tf.Tensor:\n",
        "  \"\"\"Computes the entropy of a probability/logit tensor.\"\"\"\n",
        "\n",
        "  if with_logits:\n",
        "    class_probabilities = tf.nn.softmax(x, axis=None, name=None)\n",
        "  else:\n",
        "    class_probabilities = x\n",
        "\n",
        "  ent = tf.keras.losses.categorical_crossentropy(class_probabilities,\n",
        "                                                 class_probabilities)\n",
        "  if normalize:\n",
        "    ent = ent/tf.math.reduce_mean(ent)\n",
        "\n",
        "  return ent\n",
        "\n",
        "\n",
        "def disagreement(q: tf.Tensor, p: tf.Tensor) -> tf.Tensor:\n",
        "  \"\"\"Returns a tensor with ones at the positions where p and q are different.\"\"\"\n",
        "\n",
        "  top_1_disagreement = tf.math.equal(tf.argmax(q, 1), tf.argmax(p, 1))\n",
        "  return tf.cast(top_1_disagreement, tf.float32)\n",
        "\n",
        "\n",
        "def _add_default_advice(data_split: DataSplit,\n",
        "                        train_advice: tf.Tensor) -> Advice:\n",
        "  \"\"\"Adds the default advice for pretraining, validation, and test data.\"\"\"\n",
        "\n",
        "  pretraining = data_split.dataset_a\n",
        "  validation = data_split.validation\n",
        "  test = data_split.test\n",
        "\n",
        "  validation_advice = None\n",
        "  pretraining_advice = None\n",
        "\n",
        "  if validation is not None:\n",
        "    validation_advice = tf.ones(validation.size),\n",
        "    validation_advice = tf.reshape(validation_advice, [-1])\n",
        "  if pretraining is not None:\n",
        "    pretraining_advice = tf.ones(pretraining.size),\n",
        "    pretraining_advice = tf.reshape(pretraining_advice, [-1])\n",
        "\n",
        "  test_advice = tf.zeros(test.size)\n",
        "  test_advice = tf.reshape(test_advice, [-1])\n",
        "\n",
        "  advice_data = Advice(\n",
        "      train=train_advice,\n",
        "      validation=validation_advice,\n",
        "      pretraining=pretraining_advice,\n",
        "      test=test_advice)\n",
        "\n",
        "  return advice_data\n",
        "\n",
        "\n",
        "def vanilla_advice(data_split: DataSplit) -> Advice:\n",
        "  \"\"\"A function that creates advice for vanilla distillation (used for testing).\n",
        "\n",
        "  Args:\n",
        "    data_split: Instance of datasets.UnlabeledDistillationData containing the\n",
        "      training, validation, and test data.\n",
        "\n",
        "  Returns:\n",
        "    Instance of Advice containing advice vectors.\n",
        "  \"\"\"\n",
        "\n",
        "  train = data_split.dataset_b\n",
        "  main_advice = tf.ones(train.size)\n",
        "\n",
        "  return _add_default_advice(data_split, main_advice)\n",
        "\n",
        "\n",
        "def teacher_accuracy_advice_isotonic(\n",
        "    teacher: tf.keras.Model,\n",
        "    confidence: Callable[[tf.Tensor], tf.Tensor],\n",
        "    data_split: DataSplit) -> Advice:\n",
        "  \"\"\"Creates teacher-accuracy advice for the training dataset (dataset_b).\n",
        "\n",
        "  It uses a confidence measure (e.g., margin, entropy) for the teacher\n",
        "  prediction over a validation dataset and isotonic regression to learn\n",
        "  the mapping from confidence to accuracy.\n",
        "\n",
        "  Args:\n",
        "    teacher: Instance of tf.keras.Model: the teacher model.\n",
        "    confidence: A function that maps soft labels to confidence.\n",
        "    data_split: Instance of DataSplit containing the\n",
        "      training, validation, and test data.\n",
        "\n",
        "  Returns:\n",
        "    Instance of Advice containing advice vectors.\n",
        "  \"\"\"\n",
        "\n",
        "  train = data_split.dataset_b\n",
        "  validation = data_split.validation\n",
        "\n",
        "  # These are the lower bound/upper bounds used in isotonic regression.\n",
        "  # All values predicted should be in the range [min_threshold, max_threshold].\n",
        "  # Since the outputs correspond to the probability that the teacher model is\n",
        "  # correct the range [0.5, 1.] is reasonable.\n",
        "  min_threshold = .5\n",
        "  max_threshold = 1.\n",
        "\n",
        "  # Compute teacher predictions on the validation examples.\n",
        "  teacher_predictions_validation = teacher.predict(validation.examples)\n",
        "\n",
        "  # Compute the teacher margins on the validation examples.\n",
        "  covariate = tf.reshape(confidence(teacher_predictions_validation), (-1, 1))\n",
        "\n",
        "  # Compute the (pointwise) accuracy of the teacher on the validation data.\n",
        "  response = disagreement(teacher_predictions_validation, validation.labels)\n",
        "\n",
        "  # Create a isotonic regressor that maps teacher_margins to teacher_accuracies.\n",
        "  covariate = tf.reshape(covariate, -1)\n",
        "  response = tf.reshape(response, -1)\n",
        "  iso = IsotonicRegression(\n",
        "      y_min=min_threshold, y_max=max_threshold, out_of_bounds='clip')\n",
        "  iso.fit(covariate, response)\n",
        "\n",
        "  # Compute the teacher soft labels on the training dataset.\n",
        "  teacher_predictions_training = teacher.predict(train.examples)\n",
        "\n",
        "  # Compute the teacher confidence on the training dataset.\n",
        "  teacher_confidence = tf.reshape(confidence(teacher_predictions_training), -1)\n",
        "\n",
        "  # Use the knn to predict the accuracy of the teacher on the training examples.\n",
        "  main_advice = iso.predict(teacher_confidence)\n",
        "\n",
        "  return _add_default_advice(data_split, main_advice)\n",
        "\n",
        "\n",
        "def teacher_accuracy_advice_from_entropy(\n",
        "    teacher: tf.keras.Model,\n",
        "    data_split: DataSplit,\n",
        "    normalize: Optional[bool] = False) -> Advice:\n",
        "  \"\"\"Creates teacher-accuracy advice for the training dataset (dataset_b).\n",
        "\n",
        "  Uses entropy as an uncertainty measure for the teacher and isotonic regression\n",
        "  on the validation dataset.\n",
        "\n",
        "  Args:\n",
        "    teacher: Instance of tf.keras.Model: the teacher model.\n",
        "    data_split: Instance of DataSplit containing the\n",
        "      training, validation, and test data.\n",
        "    normalize: True if the entropy should be normalized by the average entropy\n",
        "    over the dataset.\n",
        "\n",
        "  Returns:\n",
        "    Instance of Advice containing advice vectors.\n",
        "  \"\"\"\n",
        "\n",
        "  conf = lambda x: entropy(x, with_logits=False, normalize=normalize)\n",
        "\n",
        "  return teacher_accuracy_advice_isotonic(teacher, conf, data_split)\n",
        "\n",
        "\n",
        "def teacher_accuracy_advice_from_margin(\n",
        "    teacher: tf.keras.Model,\n",
        "    data_split: DataSplit,\n",
        "    normalize: Optional[bool] = False) -> Advice:\n",
        "  \"\"\"Creates teacher-accuracy advice for the training dataset (dataset_b).\n",
        "\n",
        "  Uses margin as an uncertainty measure for the teacher and isotonic regression\n",
        "  on the validation dataset.\n",
        "\n",
        "  Args:\n",
        "    teacher: Instance of tf.keras.Model: the teacher model.\n",
        "    data_split: Instance of DataSplit containing the\n",
        "      training, validation, and test data.\n",
        "    normalize: True if margin should be normalized by the average margin over\n",
        "    the dataset.\n",
        "\n",
        "  Returns:\n",
        "    Instance of Advice containing advice vectors.\n",
        "  \"\"\"\n",
        "\n",
        "  conf = lambda x: margin(x, with_logits=False, normalize=normalize)\n",
        "\n",
        "  return teacher_accuracy_advice_isotonic(teacher, conf, data_split)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaD7DKb-T4HQ"
      },
      "source": [
        "# Distillation Function\n",
        "\n",
        "This is a simple wrapper function that takes the student model and the predictions of the teacher and trains the student.  It can take both advice\n",
        "and weights to be used in distillation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4ru3NlfFTz-T"
      },
      "outputs": [],
      "source": [
        "# from typing import TypedDict\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "# A simple dict for the various training parameters of the distill() function,\n",
        "class TrainingParameters(TypedDict):\n",
        "  with_soft_labels: Optional[bool]\n",
        "  epochs: Optional[int]\n",
        "  batch_size: Optional[int]\n",
        "  data_augmentation: Optional[str]\n",
        "\n",
        "def distill(model: tf.keras.Model,\n",
        "             teacher_predictions: tf.Tensor,\n",
        "             data_split: DataSplit,\n",
        "             params: TrainingParameters,\n",
        "             advice_data: Optional[Advice] = None,\n",
        "             weight_data: Optional[Advice] = None) ->...:\n",
        "  \"\"\"A function that implements Distillation.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    teacher_predictions: Instance of tf.Tensor containing teacher's predictions.\n",
        "    data_split: Instance of DataSplit.\n",
        "    params: Instance of TrainingParameters typed dict that contains the\n",
        "      following parameters:\n",
        "      epochs - The number of training epochs.\n",
        "      batch_size - The batch size used for training.\n",
        "      with_soft_labels - If true use the soft-labels provided by the teacher.\n",
        "      data_augmentation - One of None, 'offline', 'online'.\n",
        "    advice_data: Instance of Advice to be used to as advice feature.\n",
        "    weight_data: Instance of Advice to be used as weights for the training data.\n",
        "\n",
        "  Returns:\n",
        "    The achieved accuracy, the test-accuracy trajectory.\n",
        "  \"\"\"\n",
        "\n",
        "  pretraining = data_split.dataset_a\n",
        "  train = data_split.dataset_b\n",
        "  validation = data_split.validation\n",
        "  test = data_split.test\n",
        "\n",
        "  # Default values for the parameters of the params dict.\n",
        "  default_batch_size = 128\n",
        "  default_epochs = 90\n",
        "  default_with_soft_labels = True\n",
        "  default_data_augmentation = None\n",
        "\n",
        "  if params is not None:\n",
        "    batch_size = params.get('batch_size', default_batch_size)\n",
        "    epochs = params.get('epochs', default_epochs)\n",
        "    with_soft_labels = params.get('with_soft_labels', default_with_soft_labels)\n",
        "    data_augmentation = params.get('data_augmentation',\n",
        "                                   default_data_augmentation)\n",
        "\n",
        "  # We are doing soft-distillation by default.\n",
        "  if with_soft_labels:\n",
        "    targets = teacher_predictions\n",
        "  else:\n",
        "    arg_max_indices = tf.argmax(teacher_predictions, -1)\n",
        "    targets = tf.keras.utils.to_categorical(arg_max_indices,\n",
        "                                            len(teacher_predictions[0]))\n",
        "\n",
        "  train_data = train.examples\n",
        "  train_labels = tf.reshape(targets, tf.shape(train.labels))\n",
        "\n",
        "  test_data = test.examples\n",
        "  test_labels = test.labels\n",
        "\n",
        "  # Include pretraining data in the training dataset\n",
        "  if pretraining is not None and pretraining.trainable:\n",
        "    train_data = tf.concat((pretraining.examples, train_data), axis=0)\n",
        "    train_labels = tf.concat((pretraining.labels, train_labels), axis=0)\n",
        "\n",
        "  # Include validation data in the training dataset\n",
        "  if validation is not None and validation.trainable:\n",
        "    train_data = tf.concat((train_data, validation.examples), axis=0)\n",
        "    train_labels = tf.concat((train_labels, validation.labels), axis=0)\n",
        "\n",
        "  # Fill advice for validation and pretraining with default values.\n",
        "  if advice_data is not None:\n",
        "\n",
        "    full_advice = advice_data.train\n",
        "\n",
        "    if pretraining is not None and pretraining.trainable:\n",
        "      full_advice = tf.concat((advice_data.pretraining, full_advice), axis=0)\n",
        "\n",
        "    if validation is not None and validation.trainable:\n",
        "      full_advice = tf.concat((full_advice, advice_data.validation), axis=0)\n",
        "\n",
        "    if len(tf.shape(full_advice)) == 1:\n",
        "      print(\"reshape\")\n",
        "      train_advice = tf.reshape(full_advice, shape=(-1, 1))\n",
        "    else:\n",
        "      train_advice = full_advice\n",
        "\n",
        "    train_labels = tf.concat((train_labels, train_advice), axis=1)\n",
        "\n",
        "    # We need dummy test advice in order for test data to be consistent\n",
        "    # with the training data (we should always use zero for this).\n",
        "\n",
        "    if len(tf.shape(advice_data.test)) == 1:\n",
        "      test_advice = tf.reshape(advice_data.test, shape=(-1, 1))\n",
        "    else:\n",
        "      test_advice = advice_data.test\n",
        "    test_labels = tf.concat((test.labels, test_advice), axis=1)\n",
        "\n",
        "  # Use no weights by default.\n",
        "  weights = None\n",
        "  if weight_data is not None:\n",
        "\n",
        "    full_weights = weight_data.train\n",
        "\n",
        "    if pretraining is not None and pretraining.trainable:\n",
        "      full_weights = tf.concat((weight_data.pretraining, full_weights), axis=0)\n",
        "\n",
        "    if validation is not None and validation.trainable:\n",
        "      full_weights = tf.concat((full_weights, weight_data.validation), axis=0)\n",
        "\n",
        "    weights = tf.reshape(full_weights, [-1])\n",
        "\n",
        "  score = model.evaluate(test.examples, test_labels)\n",
        "  if isinstance(score, (list, tuple, np.ndarray)):\n",
        "    score = score[1]\n",
        "\n",
        "  history = train_model(\n",
        "      model,\n",
        "      train_data,\n",
        "      train_labels,\n",
        "      test_data,\n",
        "      test_labels,\n",
        "      data_augmentation=data_augmentation,\n",
        "      weights=weights,\n",
        "      epochs=epochs,\n",
        "      batch_size=batch_size)\n",
        "\n",
        "  trajectory = np.array(history.history['val_categorical_accuracy'])\n",
        "  trajectory = np.insert(trajectory, 0, score)\n",
        "  trajectory *= 100.0\n",
        "  result = np.max(trajectory)\n",
        "\n",
        "  return (result, trajectory)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcAbd8Woyngd"
      },
      "source": [
        "# Randomize dataset B and create validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "RtjaN3i7yk2Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 636/1156 [===============>..............] - ETA: 11s"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1156/1156 [==============================] - 29s 22ms/step\n"
          ]
        }
      ],
      "source": [
        "# Create a small validation dataset.\n",
        "if _RANDOMIZE_DATASET:\n",
        "  data_split.dataset_b.shuffle(_SEED)\n",
        "\n",
        "# Round the size of validation to be multiple of batch_size\n",
        "rounded_validation_dataset_size = _BATCH_SIZE * round(\n",
        "    _VALIDATION_DATASET_SIZE / _BATCH_SIZE)\n",
        "\n",
        "train, validation = split(data_split.dataset_b, rounded_validation_dataset_size)\n",
        "\n",
        "train.trainable = True\n",
        "\n",
        "# We will train the student model on the validation dataset.\n",
        "validation.trainable = _TRAIN_ON_VALIDATION\n",
        "\n",
        "# Update the data_split datasets with the new training and validation data.\n",
        "data_split.dataset_b = train\n",
        "data_split.validation = validation\n",
        "\n",
        "# Predict the Labels on the unlabeled dataset using the teacher model\n",
        "teacher_predictions = teacher_model.predict(data_split.dataset_b.examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mpL7QT9U2TL"
      },
      "source": [
        "# Vanilla Student Mixing Loss\n",
        "\n",
        "The student mixing decorator gets a loss function and returns the student-label-mixing loss.  We use it primarily with the categorical cross-entropy loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "s33X1SAaUH7_"
      },
      "outputs": [],
      "source": [
        "def advice_mix(loss: Callable[[tf.Tensor, tf.Tensor], tf.Tensor]\n",
        "               ) -> Callable[[tf.Tensor, tf.Tensor], tf.Tensor]:\n",
        "  \"\"\"A decorator that returns a student label mixing loss function.\n",
        "\n",
        "  Args:\n",
        "      loss: A loss function that takes two tensors as arguments, e.g., the\n",
        "        tf.keras.losses.CategoricalCrossentropy().\n",
        "\n",
        "  Returns:\n",
        "    A loss that takes tensors with advice and computes the student mixing loss.\n",
        "  \"\"\"\n",
        "\n",
        "  def _loss(y_true, y_pred):\n",
        "\n",
        "    # Split y_true into the advice (last column of y_true) and labels.\n",
        "    advice = tf.stop_gradient(y_true[:, -1:])\n",
        "    label = tf.stop_gradient(y_true[:, :-1])\n",
        "\n",
        "    # Mix the student label (y_pred) using the advice.\n",
        "    y_mixed = y_pred * advice + (1. - y_pred) * (1 - advice)\n",
        "\n",
        "    # Return the loss of the teacher label and the mixed student label.\n",
        "    return loss(label, y_mixed)\n",
        "\n",
        "  return _loss\n",
        "\n",
        "\n",
        "def mixed_cce(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
        "  \"\"\"Computes the cross entropy loss using the advice to perform student mixing.\n",
        "\n",
        "  Args:\n",
        "    y_true: tf.Tensor with num_classes + 1 columns where the first num_classes\n",
        "      columns contain the true label and the last column corresponds to the\n",
        "      advice.\n",
        "    y_pred: tf.Tensor with num_classes columns that contains the predicted\n",
        "      probabilities for each class.\n",
        "\n",
        "  Returns:\n",
        "    The student mixed cross entropy between y_true[:,:-1] and y_pred defined as:\n",
        "    ce(teacher_pred, advice student_pred + (1-advice) (1-student_pred))\n",
        "  \"\"\"\n",
        "\n",
        "  # We have to use tf.keras.losses.Reduction.NONE when we are using\n",
        "  # tf.distribute.Strategy.\n",
        "  # (see https://www.tensorflow.org/tutorials/distribute/custom_training).\n",
        "  loss = advice_mix(\n",
        "      tf.keras.losses.CategoricalCrossentropy(\n",
        "          reduction=tf.keras.losses.Reduction.NONE))\n",
        "\n",
        "  return tf.math.reduce_mean(loss(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8i5CbmRJthk"
      },
      "source": [
        "# Top-k Student Label Mixing loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QfAYKFn5vDKU"
      },
      "outputs": [],
      "source": [
        "import tensorflow_probability as tfp\n",
        "def soft_top_k(x, k, temp):\n",
        "  perm = tfp.math.soft_sorting_matrix(x, temp)[:,:k]\n",
        "  return tf.reduce_sum(perm, axis=1)\n",
        "\n",
        "\n",
        "def advice_mix_soft_top_k(k, temperature):\n",
        "  \"\"\"A decorator that returns a top_k student label mixing loss decorator.\n",
        "\n",
        "  Args:\n",
        "      k: the top_k elements of the student to be used.\n",
        "      temperature: the smoothing temperature of the top_k operator.\n",
        "\n",
        "  Returns:\n",
        "    A top_k student label mixing loss decorator.\n",
        "    loss.\n",
        "  \"\"\"\n",
        "\n",
        "  def _advice_mix_soft_top_k(loss):\n",
        "\n",
        "    def _loss(y_true, y_pred):\n",
        "\n",
        "      # Split y_true into the advice (last column of y_true) and labels.\n",
        "      advice = tf.stop_gradient(y_true[:, -1:])\n",
        "      label = tf.stop_gradient(y_true[:, :-1])\n",
        "\n",
        "      # boost = tf.stop_gradient(soft_top_k(y_pred, k, temperature))\n",
        "      boost = soft_top_k(y_pred, k, temperature)\n",
        "\n",
        "      missing = tf.stop_gradient((1. - boost) * (1. - y_pred))\n",
        "      y_mixed = y_pred * advice + (1.-advice) * (boost * (1.-y_pred) + missing)\n",
        "\n",
        "      # Return the loss of the teacher label and the mixed student label.\n",
        "      return loss(label, y_mixed)\n",
        "\n",
        "    return _loss\n",
        "\n",
        "  return _advice_mix_soft_top_k\n",
        "\n",
        "\n",
        "\n",
        "def mixed_cce_top_k(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
        "  \"\"\"Computes the cross entropy loss using the advice to perform student mixing.\n",
        "\n",
        "  Args:\n",
        "    y_true: tf.Tensor with num_classes + 1 columns where the first num_classes\n",
        "      columns contain the true label and the last column corresponds to the\n",
        "      advice.\n",
        "    y_pred: tf.Tensor with num_classes columns that contains the predicted\n",
        "      probabilities for each class.\n",
        "\n",
        "  Returns:\n",
        "    The student mixed cross entropy between y_true[:,:-1] and y_pred defined as:\n",
        "    ce(teacher_pred, advice student_pred + (1-advice) (1-student_pred))\n",
        "  \"\"\"\n",
        "\n",
        "  # We have to use tf.keras.losses.Reduction.NONE when we are using\n",
        "  # tf.distribute.Strategy.\n",
        "  # (see https://www.tensorflow.org/tutorials/distribute/custom_training).\n",
        "  mixing_operator = advice_mix_soft_top_k(20, 100.0)\n",
        "  loss = mixing_operator(tf.keras.losses.CategoricalCrossentropy(\n",
        "    reduction=tf.keras.losses.Reduction.NONE))\n",
        "\n",
        "  return tf.math.reduce_mean(loss(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "3UA3yO-BRo4C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 21ms/step\n",
            "1156/1156 [==============================] - 26s 22ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0.5       , 0.69230769, 0.69230769, ..., 0.6       , 0.5       ,\n",
              "       0.5       ])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compute the advice data using margin.\n",
        "advice_data = teacher_accuracy_advice_from_margin(teacher_model, data_split)\n",
        "advice_data.train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ekj0H0X0WJuc"
      },
      "outputs": [],
      "source": [
        "# Define the training parameters for the distill() funcion.\n",
        "training_params = {\n",
        "    'epochs': _STUDENT_EPOCHS,\n",
        "    'with_soft_labels': _WITH_SOFT_LABELS,\n",
        "    'batch_size': _BATCH_SIZE,\n",
        "    'data_augmentation': _STUDENT_DISTILLATION_DATA_AUGMENTATION\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "gdM-_SVxZ_wR"
      },
      "outputs": [],
      "source": [
        "# Load a fresh student model with the studentl-label-mixing cross-entropy loss.\n",
        "with strategy.scope():\n",
        "  student = load_model(\n",
        "      _STUDENT_MODEL,\n",
        "      num_classes=num_classes,\n",
        "      optimizer_name=_STUDENT_OPTIMIZER,\n",
        "      loss_function=mixed_cce_top_k,\n",
        "      width_multiplier=1,\n",
        "      depth_multiplier=_STUDENT_MOBILENET_DEPTH_MULTIPLIER,\n",
        "      resnet_depth=_STUDENT_RESNET_DEPTH)\n",
        "\n",
        "  student.load_weights('pretrained_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bm0Nie77WwMy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reshape\n",
            "313/313 [==============================] - 8s 15ms/step - loss: 7.8124 - categorical_accuracy: 0.5200\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:21:09.651508: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17095\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 73s 94ms/step - loss: 3.4881 - categorical_accuracy: 0.4748 - val_loss: 6.9210 - val_categorical_accuracy: 0.4124 - lr: 0.0010\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:22:24.248556: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17133\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 3.4286 - categorical_accuracy: 0.5071 - val_loss: 6.7149 - val_categorical_accuracy: 0.3710 - lr: 0.0010\n",
            "Epoch 3/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:23:01.611942: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17171\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 3.5221 - categorical_accuracy: 0.4808 - val_loss: 6.7191 - val_categorical_accuracy: 0.4110 - lr: 0.0010\n",
            "Epoch 4/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:23:40.043614: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17209\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 95ms/step - loss: 3.4342 - categorical_accuracy: 0.5089 - val_loss: 6.7540 - val_categorical_accuracy: 0.4103 - lr: 0.0010\n",
            "Epoch 5/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:24:18.758529: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17247\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 91ms/step - loss: 3.4882 - categorical_accuracy: 0.4949 - val_loss: 6.8121 - val_categorical_accuracy: 0.4307 - lr: 0.0010\n",
            "Epoch 6/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:24:55.685435: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17285\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 3.4379 - categorical_accuracy: 0.5121 - val_loss: 6.9098 - val_categorical_accuracy: 0.4205 - lr: 0.0010\n",
            "Epoch 7/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:25:33.878604: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17323\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 93ms/step - loss: 3.4203 - categorical_accuracy: 0.5184 - val_loss: 6.9304 - val_categorical_accuracy: 0.4408 - lr: 0.0010\n",
            "Epoch 8/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:26:11.936065: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17361\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 3.4024 - categorical_accuracy: 0.5247 - val_loss: 7.0118 - val_categorical_accuracy: 0.4624 - lr: 0.0010\n",
            "Epoch 9/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:26:48.996357: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17399\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 3.3983 - categorical_accuracy: 0.5262 - val_loss: 6.9283 - val_categorical_accuracy: 0.4563 - lr: 0.0010\n",
            "Epoch 10/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:27:27.123100: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17437\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 38s 97ms/step - loss: 3.3845 - categorical_accuracy: 0.5304 - val_loss: 6.9273 - val_categorical_accuracy: 0.4622 - lr: 0.0010\n",
            "Epoch 11/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:28:06.620416: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17475\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 91ms/step - loss: 3.4421 - categorical_accuracy: 0.5094 - val_loss: 6.8562 - val_categorical_accuracy: 0.4631 - lr: 0.0010\n",
            "Epoch 12/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:28:43.693493: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17513\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 3.3947 - categorical_accuracy: 0.5272 - val_loss: 6.8336 - val_categorical_accuracy: 0.4389 - lr: 0.0010\n",
            "Epoch 13/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:29:21.754792: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17551\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 3.3713 - categorical_accuracy: 0.5309 - val_loss: 6.7114 - val_categorical_accuracy: 0.4085 - lr: 0.0010\n",
            "Epoch 14/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:29:58.930254: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17589\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 3.3613 - categorical_accuracy: 0.5372 - val_loss: 6.8396 - val_categorical_accuracy: 0.4409 - lr: 0.0010\n",
            "Epoch 15/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:30:37.113537: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17627\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 93ms/step - loss: 3.3444 - categorical_accuracy: 0.5422 - val_loss: 6.9316 - val_categorical_accuracy: 0.4187 - lr: 0.0010\n",
            "Epoch 16/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:31:14.971975: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17665\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 3.3421 - categorical_accuracy: 0.5428 - val_loss: 7.0320 - val_categorical_accuracy: 0.4609 - lr: 0.0010\n",
            "Epoch 17/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:31:51.971598: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17703\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 93ms/step - loss: 3.4033 - categorical_accuracy: 0.5199 - val_loss: 6.9717 - val_categorical_accuracy: 0.4545 - lr: 0.0010\n",
            "Epoch 18/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:32:29.980818: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17741\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 95ms/step - loss: 3.3526 - categorical_accuracy: 0.5423 - val_loss: 6.8494 - val_categorical_accuracy: 0.4305 - lr: 0.0010\n",
            "Epoch 19/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:33:09.147822: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17779\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 3.3422 - categorical_accuracy: 0.5398 - val_loss: 6.8470 - val_categorical_accuracy: 0.4516 - lr: 0.0010\n",
            "Epoch 20/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:33:46.164242: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17817\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 3.3484 - categorical_accuracy: 0.5396 - val_loss: 7.0951 - val_categorical_accuracy: 0.4511 - lr: 0.0010\n",
            "Epoch 21/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:34:24.272269: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17855\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 3.3188 - categorical_accuracy: 0.5500 - val_loss: 7.2606 - val_categorical_accuracy: 0.4968 - lr: 0.0010\n",
            "Epoch 22/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:35:01.166065: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17893\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 3.3385 - categorical_accuracy: 0.5419 - val_loss: 7.1646 - val_categorical_accuracy: 0.4560 - lr: 0.0010\n",
            "Epoch 23/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:35:39.416938: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17931\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 3.3001 - categorical_accuracy: 0.5564 - val_loss: 7.1494 - val_categorical_accuracy: 0.4713 - lr: 0.0010\n",
            "Epoch 24/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:36:17.214692: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:17969\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 3.3324 - categorical_accuracy: 0.5428 - val_loss: 7.0041 - val_categorical_accuracy: 0.4803 - lr: 0.0010\n",
            "Epoch 25/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:36:54.512392: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18007\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 95ms/step - loss: 3.2980 - categorical_accuracy: 0.5547 - val_loss: 7.1232 - val_categorical_accuracy: 0.4668 - lr: 0.0010\n",
            "Epoch 26/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:37:33.170614: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18045\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 95ms/step - loss: 3.3206 - categorical_accuracy: 0.5480 - val_loss: 7.2294 - val_categorical_accuracy: 0.4915 - lr: 0.0010\n",
            "Epoch 27/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:38:11.612707: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18083\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 38s 96ms/step - loss: 3.2797 - categorical_accuracy: 0.5617 - val_loss: 6.8965 - val_categorical_accuracy: 0.4385 - lr: 0.0010\n",
            "Epoch 28/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:38:51.186105: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18121\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 56s 142ms/step - loss: 3.2990 - categorical_accuracy: 0.5537 - val_loss: 7.3872 - val_categorical_accuracy: 0.4716 - lr: 0.0010\n",
            "Epoch 29/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:39:48.626277: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18159\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 115s 293ms/step - loss: 3.2848 - categorical_accuracy: 0.5588 - val_loss: 6.9750 - val_categorical_accuracy: 0.4519 - lr: 0.0010\n",
            "Epoch 30/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:42:15.194264: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18197\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 129s 330ms/step - loss: 3.2975 - categorical_accuracy: 0.5531 - val_loss: 7.1011 - val_categorical_accuracy: 0.4789 - lr: 0.0010\n",
            "Epoch 31/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:44:44.685184: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18235\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 125s 317ms/step - loss: 3.2790 - categorical_accuracy: 0.5617 - val_loss: 7.1114 - val_categorical_accuracy: 0.4562 - lr: 0.0010\n",
            "Epoch 32/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:47:12.825313: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18273\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 119s 303ms/step - loss: 3.2785 - categorical_accuracy: 0.5591 - val_loss: 7.3970 - val_categorical_accuracy: 0.4916 - lr: 0.0010\n",
            "Epoch 33/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:49:17.079755: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18311\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 118s 302ms/step - loss: 3.2552 - categorical_accuracy: 0.5686 - val_loss: 7.2173 - val_categorical_accuracy: 0.4663 - lr: 0.0010\n",
            "Epoch 34/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:51:44.871947: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18349\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 117s 296ms/step - loss: 3.2432 - categorical_accuracy: 0.5730 - val_loss: 7.2656 - val_categorical_accuracy: 0.5011 - lr: 0.0010\n",
            "Epoch 35/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:53:48.407264: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18387\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 125s 318ms/step - loss: 3.2329 - categorical_accuracy: 0.5793 - val_loss: 7.3232 - val_categorical_accuracy: 0.5019 - lr: 0.0010\n",
            "Epoch 36/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:56:00.408218: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18425\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 125s 318ms/step - loss: 3.2369 - categorical_accuracy: 0.5750 - val_loss: 7.3111 - val_categorical_accuracy: 0.4782 - lr: 0.0010\n",
            "Epoch 37/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 10:58:15.208984: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18463\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 124s 317ms/step - loss: 3.2310 - categorical_accuracy: 0.5770 - val_loss: 7.3687 - val_categorical_accuracy: 0.4769 - lr: 0.0010\n",
            "Epoch 38/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:00:26.171091: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18501\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 114s 291ms/step - loss: 3.2188 - categorical_accuracy: 0.5826 - val_loss: 7.3997 - val_categorical_accuracy: 0.4846 - lr: 0.0010\n",
            "Epoch 39/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:02:54.932966: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18539\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 116s 296ms/step - loss: 3.3070 - categorical_accuracy: 0.5466 - val_loss: 7.1724 - val_categorical_accuracy: 0.4702 - lr: 0.0010\n",
            "Epoch 40/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:05:24.447111: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18577\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 118s 299ms/step - loss: 3.2229 - categorical_accuracy: 0.5818 - val_loss: 7.1292 - val_categorical_accuracy: 0.4706 - lr: 0.0010\n",
            "Epoch 41/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:07:27.518448: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18615\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 123s 315ms/step - loss: 3.2679 - categorical_accuracy: 0.5590 - val_loss: 7.2553 - val_categorical_accuracy: 0.4778 - lr: 0.0010\n",
            "Epoch 42/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:09:56.774414: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18653\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 131s 331ms/step - loss: 3.2148 - categorical_accuracy: 0.5852 - val_loss: 7.3437 - val_categorical_accuracy: 0.4601 - lr: 0.0010\n",
            "Epoch 43/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:12:26.460809: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18691\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 132s 337ms/step - loss: 3.2066 - categorical_accuracy: 0.5838 - val_loss: 7.4149 - val_categorical_accuracy: 0.4669 - lr: 0.0010\n",
            "Epoch 44/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:14:56.524759: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18729\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 126s 321ms/step - loss: 3.2577 - categorical_accuracy: 0.5594 - val_loss: 7.3152 - val_categorical_accuracy: 0.4833 - lr: 0.0010\n",
            "Epoch 45/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:17:08.935873: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18767\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 133s 338ms/step - loss: 3.2064 - categorical_accuracy: 0.5855 - val_loss: 7.4168 - val_categorical_accuracy: 0.4839 - lr: 0.0010\n",
            "Epoch 46/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:19:38.582457: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18805\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 131s 333ms/step - loss: 3.2447 - categorical_accuracy: 0.5654 - val_loss: 7.1882 - val_categorical_accuracy: 0.4552 - lr: 0.0010\n",
            "Epoch 47/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:22:09.289843: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18843\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 147s 374ms/step - loss: 3.2069 - categorical_accuracy: 0.5843 - val_loss: 7.6008 - val_categorical_accuracy: 0.5203 - lr: 0.0010\n",
            "Epoch 48/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:25:39.356010: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18881\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 123s 313ms/step - loss: 3.2186 - categorical_accuracy: 0.5778 - val_loss: 7.4366 - val_categorical_accuracy: 0.4933 - lr: 0.0010\n",
            "Epoch 49/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:28:08.041682: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18919\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 112s 286ms/step - loss: 3.2115 - categorical_accuracy: 0.5796 - val_loss: 7.2821 - val_categorical_accuracy: 0.4601 - lr: 0.0010\n",
            "Epoch 50/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:30:37.288318: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18957\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 118s 301ms/step - loss: 3.2032 - categorical_accuracy: 0.5829 - val_loss: 7.3729 - val_categorical_accuracy: 0.4827 - lr: 0.0010\n",
            "Epoch 51/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:33:06.005934: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:18995\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 123s 314ms/step - loss: 3.2238 - categorical_accuracy: 0.5750 - val_loss: 7.4033 - val_categorical_accuracy: 0.4957 - lr: 0.0010\n",
            "Epoch 52/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:35:36.377118: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19033\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 130s 330ms/step - loss: 3.1886 - categorical_accuracy: 0.5897 - val_loss: 7.2252 - val_categorical_accuracy: 0.4738 - lr: 0.0010\n",
            "Epoch 53/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:37:53.756646: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19071\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 119s 302ms/step - loss: 3.2064 - categorical_accuracy: 0.5800 - val_loss: 7.4870 - val_categorical_accuracy: 0.4806 - lr: 0.0010\n",
            "Epoch 54/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:40:23.542929: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19109\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 124s 316ms/step - loss: 3.1894 - categorical_accuracy: 0.5904 - val_loss: 7.2428 - val_categorical_accuracy: 0.4883 - lr: 0.0010\n",
            "Epoch 55/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:42:34.756939: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19147\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 119s 303ms/step - loss: 3.2036 - categorical_accuracy: 0.5851 - val_loss: 7.3457 - val_categorical_accuracy: 0.4870 - lr: 0.0010\n",
            "Epoch 56/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:44:40.808465: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19185\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 113s 288ms/step - loss: 3.1847 - categorical_accuracy: 0.5893 - val_loss: 7.4053 - val_categorical_accuracy: 0.4768 - lr: 0.0010\n",
            "Epoch 57/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:47:09.774577: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19223\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 120s 306ms/step - loss: 3.2035 - categorical_accuracy: 0.5795 - val_loss: 7.7557 - val_categorical_accuracy: 0.5043 - lr: 0.0010\n",
            "Epoch 58/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:49:37.238793: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19261\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 124s 316ms/step - loss: 3.1847 - categorical_accuracy: 0.5873 - val_loss: 7.4764 - val_categorical_accuracy: 0.4867 - lr: 0.0010\n",
            "Epoch 59/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:52:06.433525: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19299\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 117s 297ms/step - loss: 3.1651 - categorical_accuracy: 0.5981 - val_loss: 7.4085 - val_categorical_accuracy: 0.4663 - lr: 0.0010\n",
            "Epoch 60/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:54:34.487187: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19337\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 115s 292ms/step - loss: 3.1677 - categorical_accuracy: 0.5929 - val_loss: 7.6165 - val_categorical_accuracy: 0.4940 - lr: 0.0010\n",
            "Epoch 61/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:57:04.206514: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19375\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 114s 288ms/step - loss: 3.1581 - categorical_accuracy: 0.6000 - val_loss: 7.4672 - val_categorical_accuracy: 0.4788 - lr: 0.0010\n",
            "Epoch 62/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 11:59:33.551838: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19413\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 126s 321ms/step - loss: 3.2167 - categorical_accuracy: 0.5733 - val_loss: 7.6600 - val_categorical_accuracy: 0.4865 - lr: 0.0010\n",
            "Epoch 63/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:01:45.765076: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19451\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 130s 332ms/step - loss: 3.1654 - categorical_accuracy: 0.5969 - val_loss: 7.3890 - val_categorical_accuracy: 0.4748 - lr: 0.0010\n",
            "Epoch 64/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:04:14.717002: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19489\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 116s 296ms/step - loss: 3.1840 - categorical_accuracy: 0.5880 - val_loss: 7.6072 - val_categorical_accuracy: 0.4937 - lr: 0.0010\n",
            "Epoch 65/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:06:43.307712: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19527\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 119s 303ms/step - loss: 3.1717 - categorical_accuracy: 0.5914 - val_loss: 7.5683 - val_categorical_accuracy: 0.4860 - lr: 0.0010\n",
            "Epoch 66/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:09:12.157752: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19565\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 122s 310ms/step - loss: 3.1589 - categorical_accuracy: 0.5975 - val_loss: 7.5964 - val_categorical_accuracy: 0.5077 - lr: 0.0010\n",
            "Epoch 67/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:11:19.667399: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19603\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 124s 316ms/step - loss: 3.1537 - categorical_accuracy: 0.6003 - val_loss: 7.3772 - val_categorical_accuracy: 0.4819 - lr: 0.0010\n",
            "Epoch 68/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:13:48.960054: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19641\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 119s 303ms/step - loss: 3.1971 - categorical_accuracy: 0.5807 - val_loss: 7.6117 - val_categorical_accuracy: 0.4977 - lr: 0.0010\n",
            "Epoch 69/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:16:18.085622: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19679\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 120s 305ms/step - loss: 3.1553 - categorical_accuracy: 0.5989 - val_loss: 7.5152 - val_categorical_accuracy: 0.4921 - lr: 0.0010\n",
            "Epoch 70/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:18:25.455585: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19717\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 118s 300ms/step - loss: 3.1413 - categorical_accuracy: 0.6054 - val_loss: 7.6448 - val_categorical_accuracy: 0.4739 - lr: 0.0010\n",
            "Epoch 71/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:20:53.933982: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19755\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 117s 298ms/step - loss: 3.1419 - categorical_accuracy: 0.6029 - val_loss: 7.4615 - val_categorical_accuracy: 0.4937 - lr: 0.0010\n",
            "Epoch 72/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:22:57.292304: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19793\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 128s 325ms/step - loss: 3.1424 - categorical_accuracy: 0.6022 - val_loss: 7.7098 - val_categorical_accuracy: 0.4828 - lr: 0.0010\n",
            "Epoch 73/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:25:10.294578: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19831\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 74s 186ms/step - loss: 3.1390 - categorical_accuracy: 0.6060 - val_loss: 7.5227 - val_categorical_accuracy: 0.4928 - lr: 0.0010\n",
            "Epoch 74/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:26:28.491190: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19869\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 95ms/step - loss: 3.2032 - categorical_accuracy: 0.5772 - val_loss: 7.6864 - val_categorical_accuracy: 0.5104 - lr: 0.0010\n",
            "Epoch 75/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:27:07.039281: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19907\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 3.1390 - categorical_accuracy: 0.6083 - val_loss: 7.7494 - val_categorical_accuracy: 0.5252 - lr: 0.0010\n",
            "Epoch 76/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:27:43.648846: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19945\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 3.1262 - categorical_accuracy: 0.6097 - val_loss: 7.7964 - val_categorical_accuracy: 0.5059 - lr: 0.0010\n",
            "Epoch 77/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:28:21.604609: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:19983\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 3.1271 - categorical_accuracy: 0.6083 - val_loss: 7.4693 - val_categorical_accuracy: 0.4624 - lr: 0.0010\n",
            "Epoch 78/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:28:58.707892: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20021\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 93ms/step - loss: 3.1981 - categorical_accuracy: 0.5766 - val_loss: 7.3260 - val_categorical_accuracy: 0.4629 - lr: 0.0010\n",
            "Epoch 79/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:29:36.570930: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20059\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 3.1485 - categorical_accuracy: 0.5986 - val_loss: 7.5927 - val_categorical_accuracy: 0.5045 - lr: 0.0010\n",
            "Epoch 80/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:30:14.053757: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20097\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 3.1331 - categorical_accuracy: 0.6060 - val_loss: 7.7390 - val_categorical_accuracy: 0.5253 - lr: 0.0010\n",
            "Epoch 81/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:30:51.156970: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20135\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 3.0498 - categorical_accuracy: 0.6560 - val_loss: 8.3996 - val_categorical_accuracy: 0.5796 - lr: 1.0000e-04\n",
            "Epoch 82/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:31:28.682207: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20173\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 3.0179 - categorical_accuracy: 0.6806 - val_loss: 8.4709 - val_categorical_accuracy: 0.5799 - lr: 1.0000e-04\n",
            "Epoch 83/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:32:06.082875: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20211\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 3.0062 - categorical_accuracy: 0.6877 - val_loss: 8.5385 - val_categorical_accuracy: 0.5801 - lr: 1.0000e-04\n",
            "Epoch 84/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:32:44.378292: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20249\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 93ms/step - loss: 2.9961 - categorical_accuracy: 0.6944 - val_loss: 8.5923 - val_categorical_accuracy: 0.5816 - lr: 1.0000e-04\n",
            "Epoch 85/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:33:22.361103: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20287\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 2.9990 - categorical_accuracy: 0.6847 - val_loss: 8.6328 - val_categorical_accuracy: 0.5873 - lr: 1.0000e-04\n",
            "Epoch 86/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:33:59.616492: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20325\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 93ms/step - loss: 2.9880 - categorical_accuracy: 0.6917 - val_loss: 8.6433 - val_categorical_accuracy: 0.5830 - lr: 1.0000e-04\n",
            "Epoch 87/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:34:37.688828: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20363\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 2.9741 - categorical_accuracy: 0.7017 - val_loss: 8.7229 - val_categorical_accuracy: 0.5885 - lr: 1.0000e-04\n",
            "Epoch 88/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:35:15.413847: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20401\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 2.9656 - categorical_accuracy: 0.7062 - val_loss: 8.6837 - val_categorical_accuracy: 0.5847 - lr: 1.0000e-04\n",
            "Epoch 89/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:35:52.664614: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20439\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 2.9659 - categorical_accuracy: 0.7003 - val_loss: 8.6790 - val_categorical_accuracy: 0.5841 - lr: 1.0000e-04\n",
            "Epoch 90/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:36:30.381007: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20477\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 2.9523 - categorical_accuracy: 0.7103 - val_loss: 8.7317 - val_categorical_accuracy: 0.5829 - lr: 1.0000e-04\n",
            "Epoch 91/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:37:08.044450: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20515\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 2.9528 - categorical_accuracy: 0.7059 - val_loss: 8.7149 - val_categorical_accuracy: 0.5810 - lr: 1.0000e-04\n",
            "Epoch 92/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:37:45.256110: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20553\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 93ms/step - loss: 2.9397 - categorical_accuracy: 0.7152 - val_loss: 8.7726 - val_categorical_accuracy: 0.5873 - lr: 1.0000e-04\n",
            "Epoch 93/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:38:23.216912: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20591\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 2.9328 - categorical_accuracy: 0.7186 - val_loss: 8.7911 - val_categorical_accuracy: 0.5802 - lr: 1.0000e-04\n",
            "Epoch 94/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:39:00.079108: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20629\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 2.9260 - categorical_accuracy: 0.7231 - val_loss: 8.8089 - val_categorical_accuracy: 0.5843 - lr: 1.0000e-04\n",
            "Epoch 95/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:39:38.199515: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20667\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 2.9284 - categorical_accuracy: 0.7141 - val_loss: 8.8298 - val_categorical_accuracy: 0.5777 - lr: 1.0000e-04\n",
            "Epoch 96/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:40:16.266745: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20705\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 2.9174 - categorical_accuracy: 0.7241 - val_loss: 8.8156 - val_categorical_accuracy: 0.5841 - lr: 1.0000e-04\n",
            "Epoch 97/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:40:53.212691: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20743\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 38s 97ms/step - loss: 2.9162 - categorical_accuracy: 0.7203 - val_loss: 8.8415 - val_categorical_accuracy: 0.5818 - lr: 1.0000e-04\n",
            "Epoch 98/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:41:32.616962: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20781\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 2.9075 - categorical_accuracy: 0.7285 - val_loss: 8.8582 - val_categorical_accuracy: 0.5777 - lr: 1.0000e-04\n",
            "Epoch 99/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:42:10.515149: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20819\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 2.9019 - categorical_accuracy: 0.7333 - val_loss: 8.8094 - val_categorical_accuracy: 0.5770 - lr: 1.0000e-04\n",
            "Epoch 100/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:42:47.794760: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20857\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 101\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 93ms/step - loss: 2.9029 - categorical_accuracy: 0.7253 - val_loss: 8.8216 - val_categorical_accuracy: 0.5738 - lr: 1.0000e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(58.85000228881836,\n",
              " array([51.99999809, 41.24000072, 37.09999919, 41.10000134, 41.02999866,\n",
              "        43.07000041, 42.05000103, 44.08000112, 46.23999894, 45.62999904,\n",
              "        46.2199986 , 46.30999863, 43.88999939, 40.84999859, 44.08999979,\n",
              "        41.87000096, 46.09000087, 45.44999897, 43.05000007, 45.15999854,\n",
              "        45.10999918, 49.68000054, 45.60000002, 47.13000059, 48.03000093,\n",
              "        46.68000042, 49.14999902, 43.84999871, 47.15999961, 45.19000053,\n",
              "        47.88999856, 45.62000036, 49.16000068, 46.63000107, 50.11000037,\n",
              "        50.19000173, 47.81999886, 47.69000113, 48.46000075, 47.02000022,\n",
              "        47.0600009 , 47.78000116, 46.00999951, 46.6899991 , 48.33000004,\n",
              "        48.39000106, 45.51999867, 52.02999711, 49.32999909, 46.00999951,\n",
              "        48.26999903, 49.57000017, 47.38000035, 48.05999994, 48.82999957,\n",
              "        48.69999886, 47.67999947, 50.42999983, 48.66999984, 46.63000107,\n",
              "        49.39999878, 47.87999988, 48.6499995 , 47.47999907, 49.36999977,\n",
              "        48.60000014, 50.7700026 , 48.19000065, 49.77000058, 49.21000004,\n",
              "        47.38999903, 49.36999977, 48.28000069, 49.27999973, 51.03999972,\n",
              "        52.52000093, 50.59000254, 46.23999894, 46.29000127, 50.44999719,\n",
              "        52.53000259, 57.95999765, 57.99000263, 58.00999999, 58.16000104,\n",
              "        58.73000026, 58.30000043, 58.85000229, 58.46999884, 58.4100008 ,\n",
              "        58.28999877, 58.09999704, 58.73000026, 58.02000165, 58.42999816,\n",
              "        57.77000189, 58.4100008 , 58.1799984 , 57.77000189, 57.70000219,\n",
              "        57.38000274]))"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the student model using distillation.\n",
        "distill(model=student,\n",
        "        teacher_predictions=teacher_predictions,\n",
        "        data_split=data_split,\n",
        "        advice_data=advice_data,\n",
        "        params=training_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt4LsGyCTFjB"
      },
      "source": [
        "# Vanilla Distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "bqjYRwwVfwV8"
      },
      "outputs": [],
      "source": [
        "# Load a fresh student model with the standard cross-entropy loss.\n",
        "with strategy.scope():\n",
        "  vanilla_student = load_model(\n",
        "      _STUDENT_MODEL,\n",
        "      num_classes=num_classes,\n",
        "      optimizer_name=_STUDENT_OPTIMIZER,\n",
        "      width_multiplier=1,\n",
        "      depth_multiplier=_STUDENT_MOBILENET_DEPTH_MULTIPLIER,\n",
        "      resnet_depth=_STUDENT_RESNET_DEPTH)\n",
        "\n",
        "  vanilla_student.load_weights('pretrained_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "qjmn101if7k3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 8s 18ms/step - loss: 3.3389 - categorical_accuracy: 0.5200\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:43:36.768699: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20916\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 31/390 [=>............................] - ETA: 28s - loss: 2.6725 - categorical_accuracy: 0.5736"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 73s 90ms/step - loss: 2.0769 - categorical_accuracy: 0.6028 - val_loss: 2.9804 - val_categorical_accuracy: 0.4463 - lr: 0.0010\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:44:51.284775: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20954\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 1.8797 - categorical_accuracy: 0.6246 - val_loss: 2.9256 - val_categorical_accuracy: 0.4478 - lr: 0.0010\n",
            "Epoch 3/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:45:28.250863: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:20992\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 1.7807 - categorical_accuracy: 0.6512 - val_loss: 2.8876 - val_categorical_accuracy: 0.4449 - lr: 0.0010\n",
            "Epoch 4/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:46:06.472559: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21030\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 89ms/step - loss: 1.7690 - categorical_accuracy: 0.6543 - val_loss: 2.7122 - val_categorical_accuracy: 0.4746 - lr: 0.0010\n",
            "Epoch 5/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:46:43.240074: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21068\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 1.7034 - categorical_accuracy: 0.6686 - val_loss: 3.0132 - val_categorical_accuracy: 0.4416 - lr: 0.0010\n",
            "Epoch 6/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:47:20.926399: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21106\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 1.7234 - categorical_accuracy: 0.6646 - val_loss: 2.4905 - val_categorical_accuracy: 0.5048 - lr: 0.0010\n",
            "Epoch 7/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:47:57.379795: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21144\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.6691 - categorical_accuracy: 0.6782 - val_loss: 2.7276 - val_categorical_accuracy: 0.4707 - lr: 0.0010\n",
            "Epoch 8/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:48:34.816854: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21182\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 1.6219 - categorical_accuracy: 0.6954 - val_loss: 2.7195 - val_categorical_accuracy: 0.4829 - lr: 0.0010\n",
            "Epoch 9/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:49:12.052101: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21220\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 1.6628 - categorical_accuracy: 0.6801 - val_loss: 2.6504 - val_categorical_accuracy: 0.4839 - lr: 0.0010\n",
            "Epoch 10/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:49:48.613077: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21258\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 1.5960 - categorical_accuracy: 0.7021 - val_loss: 2.5455 - val_categorical_accuracy: 0.5080 - lr: 0.0010\n",
            "Epoch 11/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:50:26.318104: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21296\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 1.6160 - categorical_accuracy: 0.6922 - val_loss: 2.9939 - val_categorical_accuracy: 0.4560 - lr: 0.0010\n",
            "Epoch 12/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:51:03.029611: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21334\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.5726 - categorical_accuracy: 0.7073 - val_loss: 2.5957 - val_categorical_accuracy: 0.4987 - lr: 0.0010\n",
            "Epoch 13/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:51:40.830045: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21372\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.5845 - categorical_accuracy: 0.7033 - val_loss: 2.7077 - val_categorical_accuracy: 0.4928 - lr: 0.0010\n",
            "Epoch 14/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:52:18.228268: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21410\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 1.5417 - categorical_accuracy: 0.7193 - val_loss: 2.8279 - val_categorical_accuracy: 0.4699 - lr: 0.0010\n",
            "Epoch 15/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:52:54.793924: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21448\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 1.5124 - categorical_accuracy: 0.7298 - val_loss: 2.8279 - val_categorical_accuracy: 0.4661 - lr: 0.0010\n",
            "Epoch 16/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:53:32.851186: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21486\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 1.5542 - categorical_accuracy: 0.7131 - val_loss: 3.0384 - val_categorical_accuracy: 0.4517 - lr: 0.0010\n",
            "Epoch 17/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:54:10.001391: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21524\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 1.5027 - categorical_accuracy: 0.7286 - val_loss: 2.8417 - val_categorical_accuracy: 0.4847 - lr: 0.0010\n",
            "Epoch 18/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:54:46.679322: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21562\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 96ms/step - loss: 1.5127 - categorical_accuracy: 0.7274 - val_loss: 2.9394 - val_categorical_accuracy: 0.4739 - lr: 0.0010\n",
            "Epoch 19/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:55:25.488665: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21600\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 89ms/step - loss: 1.4827 - categorical_accuracy: 0.7341 - val_loss: 2.7591 - val_categorical_accuracy: 0.4842 - lr: 0.0010\n",
            "Epoch 20/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:56:01.620046: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21638\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 1.4831 - categorical_accuracy: 0.7353 - val_loss: 2.7764 - val_categorical_accuracy: 0.4812 - lr: 0.0010\n",
            "Epoch 21/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:56:38.820748: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21676\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 1.4512 - categorical_accuracy: 0.7453 - val_loss: 2.5386 - val_categorical_accuracy: 0.4989 - lr: 0.0010\n",
            "Epoch 22/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:57:16.554442: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21714\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 89ms/step - loss: 1.4779 - categorical_accuracy: 0.7337 - val_loss: 2.6090 - val_categorical_accuracy: 0.4962 - lr: 0.0010\n",
            "Epoch 23/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:57:52.784984: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21752\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.4280 - categorical_accuracy: 0.7532 - val_loss: 2.8203 - val_categorical_accuracy: 0.4859 - lr: 0.0010\n",
            "Epoch 24/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:58:30.575056: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21790\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.4550 - categorical_accuracy: 0.7440 - val_loss: 2.5979 - val_categorical_accuracy: 0.5007 - lr: 0.0010\n",
            "Epoch 25/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:59:08.631338: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21828\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 1.4167 - categorical_accuracy: 0.7536 - val_loss: 2.6779 - val_categorical_accuracy: 0.5024 - lr: 0.0010\n",
            "Epoch 26/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 12:59:45.205343: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21866\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 93ms/step - loss: 1.3939 - categorical_accuracy: 0.7652 - val_loss: 2.8032 - val_categorical_accuracy: 0.4867 - lr: 0.0010\n",
            "Epoch 27/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:00:23.348394: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21904\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 89ms/step - loss: 1.4495 - categorical_accuracy: 0.7415 - val_loss: 2.7113 - val_categorical_accuracy: 0.4917 - lr: 0.0010\n",
            "Epoch 28/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:00:59.753561: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21942\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.4003 - categorical_accuracy: 0.7603 - val_loss: 2.6337 - val_categorical_accuracy: 0.4910 - lr: 0.0010\n",
            "Epoch 29/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:01:37.269625: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:21980\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.4036 - categorical_accuracy: 0.7585 - val_loss: 2.6139 - val_categorical_accuracy: 0.5068 - lr: 0.0010\n",
            "Epoch 30/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:02:14.674196: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22018\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 1.3910 - categorical_accuracy: 0.7643 - val_loss: 2.6459 - val_categorical_accuracy: 0.5048 - lr: 0.0010\n",
            "Epoch 31/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:02:51.223576: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22056\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 1.3584 - categorical_accuracy: 0.7747 - val_loss: 2.7659 - val_categorical_accuracy: 0.4721 - lr: 0.0010\n",
            "Epoch 32/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:03:28.975039: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22094\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 1.4053 - categorical_accuracy: 0.7563 - val_loss: 2.4307 - val_categorical_accuracy: 0.5257 - lr: 0.0010\n",
            "Epoch 33/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:04:06.707374: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22132\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 89ms/step - loss: 1.3675 - categorical_accuracy: 0.7697 - val_loss: 2.6375 - val_categorical_accuracy: 0.5080 - lr: 0.0010\n",
            "Epoch 34/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:04:42.961904: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22170\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.3816 - categorical_accuracy: 0.7649 - val_loss: 2.7885 - val_categorical_accuracy: 0.4747 - lr: 0.0010\n",
            "Epoch 35/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:05:20.221798: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22208\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 1.3581 - categorical_accuracy: 0.7731 - val_loss: 2.5239 - val_categorical_accuracy: 0.5125 - lr: 0.0010\n",
            "Epoch 36/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:05:57.035689: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22246\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.3676 - categorical_accuracy: 0.7683 - val_loss: 2.5255 - val_categorical_accuracy: 0.5090 - lr: 0.0010\n",
            "Epoch 37/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:06:34.570441: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22284\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 1.3301 - categorical_accuracy: 0.7849 - val_loss: 2.5446 - val_categorical_accuracy: 0.5182 - lr: 0.0010\n",
            "Epoch 38/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:07:12.254414: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22322\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 1.3639 - categorical_accuracy: 0.7688 - val_loss: 2.6194 - val_categorical_accuracy: 0.5004 - lr: 0.0010\n",
            "Epoch 39/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:07:49.006668: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22360\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.3357 - categorical_accuracy: 0.7803 - val_loss: 2.6412 - val_categorical_accuracy: 0.5054 - lr: 0.0010\n",
            "Epoch 40/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:08:26.478054: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22398\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 1.3073 - categorical_accuracy: 0.7931 - val_loss: 2.5132 - val_categorical_accuracy: 0.5128 - lr: 0.0010\n",
            "Epoch 41/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:09:03.144679: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22436\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 1.3017 - categorical_accuracy: 0.7927 - val_loss: 2.6155 - val_categorical_accuracy: 0.5062 - lr: 0.0010\n",
            "Epoch 42/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:09:40.634527: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22474\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.3669 - categorical_accuracy: 0.7652 - val_loss: 2.5240 - val_categorical_accuracy: 0.5211 - lr: 0.0010\n",
            "Epoch 43/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:10:17.954511: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22512\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 89ms/step - loss: 1.3072 - categorical_accuracy: 0.7897 - val_loss: 2.4921 - val_categorical_accuracy: 0.5153 - lr: 0.0010\n",
            "Epoch 44/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:10:54.355629: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22550\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 38s 96ms/step - loss: 1.3393 - categorical_accuracy: 0.7759 - val_loss: 2.6087 - val_categorical_accuracy: 0.5150 - lr: 0.0010\n",
            "Epoch 45/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:11:33.345304: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22588\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 1.2993 - categorical_accuracy: 0.7916 - val_loss: 2.5672 - val_categorical_accuracy: 0.5127 - lr: 0.0010\n",
            "Epoch 46/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:12:10.445844: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22626\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 89ms/step - loss: 1.3187 - categorical_accuracy: 0.7821 - val_loss: 2.6990 - val_categorical_accuracy: 0.4957 - lr: 0.0010\n",
            "Epoch 47/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:12:47.154863: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22664\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 1.3003 - categorical_accuracy: 0.7877 - val_loss: 2.6314 - val_categorical_accuracy: 0.5072 - lr: 0.0010\n",
            "Epoch 48/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:13:25.249284: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22702\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 89ms/step - loss: 1.3101 - categorical_accuracy: 0.7844 - val_loss: 2.9985 - val_categorical_accuracy: 0.4726 - lr: 0.0010\n",
            "Epoch 49/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:14:01.449658: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22740\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.2902 - categorical_accuracy: 0.7927 - val_loss: 2.8655 - val_categorical_accuracy: 0.4880 - lr: 0.0010\n",
            "Epoch 50/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:14:39.105492: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22778\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 1.2676 - categorical_accuracy: 0.8024 - val_loss: 2.5772 - val_categorical_accuracy: 0.5064 - lr: 0.0010\n",
            "Epoch 51/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:15:16.677734: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22816\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 1.2532 - categorical_accuracy: 0.8092 - val_loss: 2.7023 - val_categorical_accuracy: 0.4919 - lr: 0.0010\n",
            "Epoch 52/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:15:53.232561: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22854\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.3232 - categorical_accuracy: 0.7796 - val_loss: 2.6630 - val_categorical_accuracy: 0.5030 - lr: 0.0010\n",
            "Epoch 53/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:16:30.395950: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22892\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.2646 - categorical_accuracy: 0.8011 - val_loss: 2.7524 - val_categorical_accuracy: 0.4847 - lr: 0.0010\n",
            "Epoch 54/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:17:07.922015: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22930\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 89ms/step - loss: 1.2478 - categorical_accuracy: 0.8087 - val_loss: 2.5239 - val_categorical_accuracy: 0.5107 - lr: 0.0010\n",
            "Epoch 55/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:17:44.178117: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:22968\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 1.2347 - categorical_accuracy: 0.8138 - val_loss: 2.6576 - val_categorical_accuracy: 0.5092 - lr: 0.0010\n",
            "Epoch 56/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:18:22.373303: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23006\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 89ms/step - loss: 1.2345 - categorical_accuracy: 0.8121 - val_loss: 2.6820 - val_categorical_accuracy: 0.4984 - lr: 0.0010\n",
            "Epoch 57/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:18:58.640968: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23044\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.2299 - categorical_accuracy: 0.8151 - val_loss: 2.6325 - val_categorical_accuracy: 0.5126 - lr: 0.0010\n",
            "Epoch 58/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:19:36.013255: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23082\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 93ms/step - loss: 1.3392 - categorical_accuracy: 0.7691 - val_loss: 2.7786 - val_categorical_accuracy: 0.4902 - lr: 0.0010\n",
            "Epoch 59/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:20:13.973075: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23120\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 1.2838 - categorical_accuracy: 0.7939 - val_loss: 2.8080 - val_categorical_accuracy: 0.4956 - lr: 0.0010\n",
            "Epoch 60/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:20:50.381858: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23158\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.2469 - categorical_accuracy: 0.8088 - val_loss: 2.6901 - val_categorical_accuracy: 0.5066 - lr: 0.0010\n",
            "Epoch 61/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:21:27.655546: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23196\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 1.2640 - categorical_accuracy: 0.7983 - val_loss: 2.6224 - val_categorical_accuracy: 0.5116 - lr: 0.0010\n",
            "Epoch 62/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:22:05.302278: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23234\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 89ms/step - loss: 1.2649 - categorical_accuracy: 0.7978 - val_loss: 2.5393 - val_categorical_accuracy: 0.5138 - lr: 0.0010\n",
            "Epoch 63/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:22:41.686815: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23272\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.2500 - categorical_accuracy: 0.8024 - val_loss: 2.5806 - val_categorical_accuracy: 0.5122 - lr: 0.0010\n",
            "Epoch 64/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:23:19.208098: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23310\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 1.2574 - categorical_accuracy: 0.8014 - val_loss: 2.8913 - val_categorical_accuracy: 0.4720 - lr: 0.0010\n",
            "Epoch 65/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:23:55.949987: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23348\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 1.2275 - categorical_accuracy: 0.8115 - val_loss: 2.8175 - val_categorical_accuracy: 0.4940 - lr: 0.0010\n",
            "Epoch 66/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:24:33.766040: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23386\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.2207 - categorical_accuracy: 0.8138 - val_loss: 2.5149 - val_categorical_accuracy: 0.5205 - lr: 0.0010\n",
            "Epoch 67/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:25:11.490458: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23424\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 1.2156 - categorical_accuracy: 0.8172 - val_loss: 2.6822 - val_categorical_accuracy: 0.5076 - lr: 0.0010\n",
            "Epoch 68/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:25:48.811663: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23462\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.2846 - categorical_accuracy: 0.7889 - val_loss: 2.5854 - val_categorical_accuracy: 0.5147 - lr: 0.0010\n",
            "Epoch 69/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:26:26.126755: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23500\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 40s 103ms/step - loss: 1.2178 - categorical_accuracy: 0.8182 - val_loss: 2.6196 - val_categorical_accuracy: 0.5046 - lr: 0.0010\n",
            "Epoch 70/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:27:07.973282: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23538\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 1.2066 - categorical_accuracy: 0.8180 - val_loss: 2.6581 - val_categorical_accuracy: 0.5175 - lr: 0.0010\n",
            "Epoch 71/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:27:44.480324: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23576\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.1949 - categorical_accuracy: 0.8215 - val_loss: 2.5875 - val_categorical_accuracy: 0.5140 - lr: 0.0010\n",
            "Epoch 72/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:28:21.735940: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23614\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 91ms/step - loss: 1.2753 - categorical_accuracy: 0.7908 - val_loss: 2.5738 - val_categorical_accuracy: 0.5161 - lr: 0.0010\n",
            "Epoch 73/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:28:58.601590: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23652\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 1.2246 - categorical_accuracy: 0.8102 - val_loss: 2.7112 - val_categorical_accuracy: 0.5050 - lr: 0.0010\n",
            "Epoch 74/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:29:36.381574: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23690\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.2127 - categorical_accuracy: 0.8165 - val_loss: 2.6020 - val_categorical_accuracy: 0.5072 - lr: 0.0010\n",
            "Epoch 75/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:30:13.738672: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23728\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 1.2326 - categorical_accuracy: 0.8070 - val_loss: 2.5695 - val_categorical_accuracy: 0.5189 - lr: 0.0010\n",
            "Epoch 76/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:30:51.447893: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23766\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.2014 - categorical_accuracy: 0.8212 - val_loss: 2.6128 - val_categorical_accuracy: 0.5099 - lr: 0.0010\n",
            "Epoch 77/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:31:28.704359: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23804\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 1.1899 - categorical_accuracy: 0.8236 - val_loss: 2.6085 - val_categorical_accuracy: 0.5125 - lr: 0.0010\n",
            "Epoch 78/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:32:06.225003: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23842\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 1.1782 - categorical_accuracy: 0.8260 - val_loss: 2.5731 - val_categorical_accuracy: 0.5171 - lr: 0.0010\n",
            "Epoch 79/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:32:42.951643: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23880\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 1.2543 - categorical_accuracy: 0.7974 - val_loss: 2.6778 - val_categorical_accuracy: 0.5122 - lr: 0.0010\n",
            "Epoch 80/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:33:20.892745: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23918\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 89ms/step - loss: 1.2068 - categorical_accuracy: 0.8143 - val_loss: 2.5755 - val_categorical_accuracy: 0.5140 - lr: 0.0010\n",
            "Epoch 81/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:33:56.938264: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23956\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 38s 96ms/step - loss: 1.0462 - categorical_accuracy: 0.8835 - val_loss: 2.3041 - val_categorical_accuracy: 0.5611 - lr: 1.0000e-04\n",
            "Epoch 82/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:34:35.788837: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:23994\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.0061 - categorical_accuracy: 0.8942 - val_loss: 2.2825 - val_categorical_accuracy: 0.5672 - lr: 1.0000e-04\n",
            "Epoch 83/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:35:13.255277: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24032\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 0.9680 - categorical_accuracy: 0.9106 - val_loss: 2.2876 - val_categorical_accuracy: 0.5670 - lr: 1.0000e-04\n",
            "Epoch 84/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:35:50.106516: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24070\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 0.9518 - categorical_accuracy: 0.9146 - val_loss: 2.3277 - val_categorical_accuracy: 0.5613 - lr: 1.0000e-04\n",
            "Epoch 85/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:36:28.207113: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24108\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 0.9334 - categorical_accuracy: 0.9187 - val_loss: 2.3149 - val_categorical_accuracy: 0.5643 - lr: 1.0000e-04\n",
            "Epoch 86/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:37:05.744053: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24146\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 0.9210 - categorical_accuracy: 0.9205 - val_loss: 2.3085 - val_categorical_accuracy: 0.5608 - lr: 1.0000e-04\n",
            "Epoch 87/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:37:43.082963: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24184\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 0.9297 - categorical_accuracy: 0.9155 - val_loss: 2.2968 - val_categorical_accuracy: 0.5630 - lr: 1.0000e-04\n",
            "Epoch 88/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:38:20.675568: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24222\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 0.9016 - categorical_accuracy: 0.9237 - val_loss: 2.2963 - val_categorical_accuracy: 0.5644 - lr: 1.0000e-04\n",
            "Epoch 89/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:38:57.048534: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24260\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 0.9060 - categorical_accuracy: 0.9201 - val_loss: 2.3024 - val_categorical_accuracy: 0.5626 - lr: 1.0000e-04\n",
            "Epoch 90/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:39:34.793672: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24298\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 0.8851 - categorical_accuracy: 0.9259 - val_loss: 2.3092 - val_categorical_accuracy: 0.5640 - lr: 1.0000e-04\n",
            "Epoch 91/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:40:12.066980: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24336\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 0.8856 - categorical_accuracy: 0.9228 - val_loss: 2.2875 - val_categorical_accuracy: 0.5641 - lr: 1.0000e-04\n",
            "Epoch 92/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:40:48.600906: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24374\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 93ms/step - loss: 0.8680 - categorical_accuracy: 0.9266 - val_loss: 2.2516 - val_categorical_accuracy: 0.5700 - lr: 1.0000e-04\n",
            "Epoch 93/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:41:26.376153: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24412\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 0.8588 - categorical_accuracy: 0.9295 - val_loss: 2.2622 - val_categorical_accuracy: 0.5642 - lr: 1.0000e-04\n",
            "Epoch 94/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:42:03.483137: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24450\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 0.8620 - categorical_accuracy: 0.9238 - val_loss: 2.2481 - val_categorical_accuracy: 0.5651 - lr: 1.0000e-04\n",
            "Epoch 95/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:42:40.209920: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24488\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 38s 97ms/step - loss: 0.8450 - categorical_accuracy: 0.9295 - val_loss: 2.2598 - val_categorical_accuracy: 0.5668 - lr: 1.0000e-04\n",
            "Epoch 96/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:43:19.441679: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24526\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 90ms/step - loss: 0.8472 - categorical_accuracy: 0.9266 - val_loss: 2.2731 - val_categorical_accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 97/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:43:55.883613: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24564\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 0.8308 - categorical_accuracy: 0.9298 - val_loss: 2.2736 - val_categorical_accuracy: 0.5630 - lr: 1.0000e-04\n",
            "Epoch 98/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:44:33.478603: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24602\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 0.8246 - categorical_accuracy: 0.9306 - val_loss: 2.2747 - val_categorical_accuracy: 0.5623 - lr: 1.0000e-04\n",
            "Epoch 99/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:45:11.340733: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24640\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 35s 89ms/step - loss: 0.8291 - categorical_accuracy: 0.9269 - val_loss: 2.2668 - val_categorical_accuracy: 0.5654 - lr: 1.0000e-04\n",
            "Epoch 100/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:45:47.760044: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24678\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 0.8143 - categorical_accuracy: 0.9296 - val_loss: 2.2536 - val_categorical_accuracy: 0.5639 - lr: 1.0000e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(56.99999928474426,\n",
              " array([51.99999809, 44.63      , 44.78000104, 44.49000061, 47.45999873,\n",
              "        44.15999949, 50.48000216, 47.06999958, 48.28999937, 48.39000106,\n",
              "        50.80000162, 45.60000002, 49.86999929, 49.27999973, 46.9900012 ,\n",
              "        46.61000073, 45.1700002 , 48.46999943, 47.38999903, 48.42000008,\n",
              "        48.12000096, 49.88999963, 49.61999953, 48.59000146, 50.06999969,\n",
              "        50.2399981 , 48.66999984, 49.16999936, 49.09999967, 50.67999959,\n",
              "        50.48000216, 47.20999897, 52.56999731, 50.80000162, 47.47000039,\n",
              "        51.24999881, 50.90000033, 51.81999803, 50.04000068, 50.5400002 ,\n",
              "        51.27999783, 50.62000155, 52.10999846, 51.52999759, 51.49999857,\n",
              "        51.27000213, 49.57000017, 50.72000027, 47.2600013 , 48.80000055,\n",
              "        50.63999891, 49.1899997 , 50.3000021 , 48.46999943, 51.06999874,\n",
              "        50.91999769, 49.84000027, 51.26000047, 49.02000129, 49.55999851,\n",
              "        50.66000223, 51.16000175, 51.3800025 , 51.21999979, 47.20000029,\n",
              "        49.39999878, 52.05000043, 50.76000094, 51.46999955, 50.45999885,\n",
              "        51.74999833, 51.39999986, 51.60999894, 50.49999952, 50.72000027,\n",
              "        51.88999772, 50.98999739, 51.24999881, 51.70999765, 51.21999979,\n",
              "        51.39999986, 56.11000061, 56.72000051, 56.69999719, 56.12999797,\n",
              "        56.43000007, 56.08000159, 56.30000234, 56.44000173, 56.26000166,\n",
              "        56.40000105, 56.41000271, 56.99999928, 56.41999841, 56.51000142,\n",
              "        56.67999983, 56.25      , 56.30000234, 56.23000264, 56.54000044,\n",
              "        56.38999939]))"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the student model using distillation.\n",
        "distill(model=vanilla_student,\n",
        "        teacher_predictions=teacher_predictions,\n",
        "        data_split=data_split,\n",
        "        advice_data=None,\n",
        "        params=training_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49tgtpQHTJ-1"
      },
      "source": [
        "# Weighted Distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Ab1U4iPYgBLF"
      },
      "outputs": [],
      "source": [
        "def accuracy_distortion_weights(teacher: tf.keras.Model,\n",
        "                                student: tf.keras.Model,\n",
        "                                uncertainty: Callable[[tf.Tensor], tf.Tensor],\n",
        "                                n_neighbors: int,\n",
        "                                data_split: DataSplit) -> Advice:\n",
        "  \"\"\"Args: Maps (teacher, model)-confidence to (accuracy, distortion) pairs.\n",
        "\n",
        "  Args:\n",
        "    teacher: Instance of tf.keras.Model.\n",
        "    student: Instance of tf.keras.Model.\n",
        "    uncertainty: A function that maps probability distributions to uncertainty.\n",
        "    n_neighbors: The number of neighbors to average over when using 'Nearest\n",
        "      Neighbors' to learn the weights.\n",
        "    data_split: Instance of DataSplit containing the data.\n",
        "\n",
        "  Returns:\n",
        "    An instance of Advice containing advice for the examples.\n",
        "  \"\"\"\n",
        "  clip_max = 100000\n",
        "  clip_min = .00001\n",
        "\n",
        "  train = data_split.dataset_b\n",
        "  validation = data_split.validation\n",
        "\n",
        "  student_predictions_validation = student.predict(validation.examples)\n",
        "  teacher_predictions_validation = teacher.predict(validation.examples)\n",
        "\n",
        "  teacher_uncertainty_validation = tf.reshape(\n",
        "      uncertainty(teacher_predictions_validation), (-1, 1))\n",
        "\n",
        "  student_uncertainty_validation = tf.reshape(\n",
        "      uncertainty(student_predictions_validation), (-1, 1))\n",
        "\n",
        "  cce = tf.keras.losses.CategoricalCrossentropy(\n",
        "      reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "  noisy_loss = cce(teacher_predictions_validation,\n",
        "                   student_predictions_validation)\n",
        "\n",
        "  clean_loss = cce(validation.labels, student_predictions_validation)\n",
        "\n",
        "  distortion_validation = noisy_loss / (clean_loss + clip_min)\n",
        "\n",
        "  accuracy_validation = tf.cast(\n",
        "      tf.math.equal(\n",
        "          tf.argmax(teacher_predictions_validation, 1),\n",
        "          tf.argmax(validation.labels, 1)), tf.float32)\n",
        "\n",
        "  accuracy_validation = tf.reshape(accuracy_validation, shape=(-1, 1))\n",
        "  distortion_validation = tf.reshape(distortion_validation, shape=(-1, 1))\n",
        "\n",
        "  # If accuracy is 1 we want to set distortion to be 1 too.\n",
        "  # To do this we first multiply distortion by (1.- accuracy_validation)\n",
        "  # in order to zero-out all elements whose corresponding teacher predictions\n",
        "  # are correct.\n",
        "  distortion_validation_masked = distortion_validation * (\n",
        "      1. - accuracy_validation)\n",
        "\n",
        "  # Replace the distortion of the masked elements with their accuracy\n",
        "  # (which is equal to 1).\n",
        "  distortion_validation = distortion_validation_masked + accuracy_validation\n",
        "\n",
        "  # Clip distortion values for numerical stability.\n",
        "  distortion_validation_clipped = tf.clip_by_value(\n",
        "      distortion_validation, clip_value_min=0., clip_value_max=clip_max)\n",
        "\n",
        "  # We create the features and responses of the 2-dimension regression problem.\n",
        "  # The features are pairs (teacher_uncertainty, student_uncertainty) and the\n",
        "  # responses are pairs (accuracy, distortion).\n",
        "  space = tf.concat(\n",
        "      (teacher_uncertainty_validation, student_uncertainty_validation), axis=1)\n",
        "  y = tf.concat((accuracy_validation, distortion_validation_clipped), axis=1)\n",
        "\n",
        "  # Use knn to solve the regression problem.\n",
        "  neigh = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
        "  neigh.fit(space, y)\n",
        "\n",
        "  # Compute the predictions of the teacher model on the training examples.\n",
        "  teacher_predictions_train = teacher.predict(train.examples)\n",
        "  # Compute the uncertainty of teacher's predictions.\n",
        "  teacher_uncertainty_train = tf.reshape(\n",
        "      uncertainty(teacher_predictions_train), shape=(-1, 1))\n",
        "\n",
        "  # Compute the predictions of the student model on the training examples.\n",
        "  student_train_predictions = student.predict(train.examples)\n",
        "  # Compute the uncertainty of student's predictions.\n",
        "  student_uncertainty_train = tf.reshape(\n",
        "      uncertainty(student_train_predictions), shape=(-1, 1))\n",
        "\n",
        "  # Create the uncertainty features over the training data.\n",
        "  uncertainty_train = tf.concat(\n",
        "      (teacher_uncertainty_train, student_uncertainty_train), axis=1)\n",
        "\n",
        "  # Use the knn to obtain (accuracy, distortion) predictions over the training\n",
        "  # examples.\n",
        "  accuracy_distortion = neigh.predict(uncertainty_train)\n",
        "\n",
        "  accuracy_predicted = accuracy_distortion[:, :1]\n",
        "  distortion_predicted = accuracy_distortion[:, 1:]\n",
        "\n",
        "  # Compute the debiasing weights as described in the paper\n",
        "  # https://drive.google.com/file/d/1ye5PbhDHbu4Pr8jFskGVt_XzyPB9DYez/view?resourcekey=0-TPAMM5WVZ2IdrmyIBitctw.\n",
        "  weight = 1. / (1. + (1. - accuracy_predicted) * (distortion_predicted - 1))\n",
        "  weight = tf.clip_by_value(weight, clip_value_min=0., clip_value_max=1.)\n",
        "  weight = tf.reshape(weight, shape=[-1])\n",
        "\n",
        "  return _add_default_advice(data_split, weight)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9-s4GfqpT2F2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 2s 14ms/step\n",
            "16/16 [==============================] - 0s 20ms/step\n",
            "1156/1156 [==============================] - 25s 22ms/step\n",
            "1156/1156 [==============================] - 17s 13ms/step\n",
            " 63/313 [=====>........................] - ETA: 4s - loss: 3.3301 - categorical_accuracy: 0.5154"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 8s 18ms/step - loss: 3.3389 - categorical_accuracy: 0.5200\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:47:23.636720: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24817\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 73s 96ms/step - loss: 1.5520 - categorical_accuracy: 0.5893 - val_loss: 3.0628 - val_categorical_accuracy: 0.4404 - lr: 0.0010\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:48:37.641173: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24855\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 1.3580 - categorical_accuracy: 0.6296 - val_loss: 2.9786 - val_categorical_accuracy: 0.4621 - lr: 0.0010\n",
            "Epoch 3/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:49:15.787937: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24893\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.3477 - categorical_accuracy: 0.6288 - val_loss: 3.0039 - val_categorical_accuracy: 0.4571 - lr: 0.0010\n",
            "Epoch 4/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:49:53.107929: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24931\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 95ms/step - loss: 1.2903 - categorical_accuracy: 0.6468 - val_loss: 2.8426 - val_categorical_accuracy: 0.4711 - lr: 0.0010\n",
            "Epoch 5/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:50:31.516681: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:24969\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 1.2500 - categorical_accuracy: 0.6576 - val_loss: 2.6669 - val_categorical_accuracy: 0.4780 - lr: 0.0010\n",
            "Epoch 6/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:51:09.761104: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25007\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 1.2280 - categorical_accuracy: 0.6657 - val_loss: 2.9090 - val_categorical_accuracy: 0.4543 - lr: 0.0010\n",
            "Epoch 7/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:51:47.545037: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25045\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 1.2982 - categorical_accuracy: 0.6404 - val_loss: 2.7200 - val_categorical_accuracy: 0.4802 - lr: 0.0010\n",
            "Epoch 8/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:52:25.711703: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25083\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 1.2074 - categorical_accuracy: 0.6680 - val_loss: 2.9342 - val_categorical_accuracy: 0.4643 - lr: 0.0010\n",
            "Epoch 9/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:53:03.632332: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25121\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 93ms/step - loss: 1.2454 - categorical_accuracy: 0.6588 - val_loss: 2.7402 - val_categorical_accuracy: 0.4772 - lr: 0.0010\n",
            "Epoch 10/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:53:41.900666: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25159\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 95ms/step - loss: 1.1992 - categorical_accuracy: 0.6713 - val_loss: 2.7413 - val_categorical_accuracy: 0.4681 - lr: 0.0010\n",
            "Epoch 11/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:54:20.388990: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25197\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.1705 - categorical_accuracy: 0.6800 - val_loss: 2.7783 - val_categorical_accuracy: 0.4769 - lr: 0.0010\n",
            "Epoch 12/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:54:57.699011: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25235\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 38s 98ms/step - loss: 1.1424 - categorical_accuracy: 0.6932 - val_loss: 2.7744 - val_categorical_accuracy: 0.4823 - lr: 0.0010\n",
            "Epoch 13/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:55:37.740822: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25273\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 95ms/step - loss: 1.2003 - categorical_accuracy: 0.6684 - val_loss: 2.7980 - val_categorical_accuracy: 0.4809 - lr: 0.0010\n",
            "Epoch 14/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:56:16.460894: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25311\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.1342 - categorical_accuracy: 0.6914 - val_loss: 2.5694 - val_categorical_accuracy: 0.5082 - lr: 0.0010\n",
            "Epoch 15/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:56:54.111803: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25349\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 95ms/step - loss: 1.1078 - categorical_accuracy: 0.7005 - val_loss: 2.6582 - val_categorical_accuracy: 0.4866 - lr: 0.0010\n",
            "Epoch 16/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:57:32.607762: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25387\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 1.1635 - categorical_accuracy: 0.6781 - val_loss: 2.8722 - val_categorical_accuracy: 0.4673 - lr: 0.0010\n",
            "Epoch 17/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:58:10.804361: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25425\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 1.1124 - categorical_accuracy: 0.6960 - val_loss: 2.7304 - val_categorical_accuracy: 0.4881 - lr: 0.0010\n",
            "Epoch 18/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:58:48.592220: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25463\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 95ms/step - loss: 1.0845 - categorical_accuracy: 0.7055 - val_loss: 2.8284 - val_categorical_accuracy: 0.4750 - lr: 0.0010\n",
            "Epoch 19/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 13:59:26.985074: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25501\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 1.0681 - categorical_accuracy: 0.7120 - val_loss: 2.6891 - val_categorical_accuracy: 0.5011 - lr: 0.0010\n",
            "Epoch 20/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:00:05.110456: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25539\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 1.1191 - categorical_accuracy: 0.6867 - val_loss: 2.8174 - val_categorical_accuracy: 0.4787 - lr: 0.0010\n",
            "Epoch 21/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:00:43.091684: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25577\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 95ms/step - loss: 1.0719 - categorical_accuracy: 0.7070 - val_loss: 2.9319 - val_categorical_accuracy: 0.4586 - lr: 0.0010\n",
            "Epoch 22/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:01:21.608772: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25615\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 1.0708 - categorical_accuracy: 0.7068 - val_loss: 2.7492 - val_categorical_accuracy: 0.4941 - lr: 0.0010\n",
            "Epoch 23/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:01:59.113445: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25653\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 38s 97ms/step - loss: 1.0389 - categorical_accuracy: 0.7189 - val_loss: 2.8590 - val_categorical_accuracy: 0.4785 - lr: 0.0010\n",
            "Epoch 24/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:02:38.537586: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25691\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 95ms/step - loss: 1.0210 - categorical_accuracy: 0.7268 - val_loss: 2.6602 - val_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 25/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:03:16.981804: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25729\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 95ms/step - loss: 1.0120 - categorical_accuracy: 0.7303 - val_loss: 2.5551 - val_categorical_accuracy: 0.5119 - lr: 0.0010\n",
            "Epoch 26/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:03:55.559557: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25767\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 1.0898 - categorical_accuracy: 0.6963 - val_loss: 2.8644 - val_categorical_accuracy: 0.4703 - lr: 0.0010\n",
            "Epoch 27/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:04:33.978669: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25805\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 1.0053 - categorical_accuracy: 0.7305 - val_loss: 2.7284 - val_categorical_accuracy: 0.4918 - lr: 0.0010\n",
            "Epoch 28/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:05:12.469059: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25843\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 1.0531 - categorical_accuracy: 0.7128 - val_loss: 2.7908 - val_categorical_accuracy: 0.4771 - lr: 0.0010\n",
            "Epoch 29/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:05:50.614810: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25881\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 1.0077 - categorical_accuracy: 0.7284 - val_loss: 2.9500 - val_categorical_accuracy: 0.4677 - lr: 0.0010\n",
            "Epoch 30/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:06:28.871360: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25919\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 1.0251 - categorical_accuracy: 0.7212 - val_loss: 2.7628 - val_categorical_accuracy: 0.4863 - lr: 0.0010\n",
            "Epoch 31/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:07:07.237269: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25957\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 0.9929 - categorical_accuracy: 0.7346 - val_loss: 2.7052 - val_categorical_accuracy: 0.4815 - lr: 0.0010\n",
            "Epoch 32/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:07:45.123517: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:25995\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 0.9745 - categorical_accuracy: 0.7355 - val_loss: 2.8281 - val_categorical_accuracy: 0.4849 - lr: 0.0010\n",
            "Epoch 33/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:08:23.250286: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26033\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 92ms/step - loss: 0.9716 - categorical_accuracy: 0.7387 - val_loss: 2.9955 - val_categorical_accuracy: 0.4824 - lr: 0.0010\n",
            "Epoch 34/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:09:00.783977: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26071\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 95ms/step - loss: 1.0245 - categorical_accuracy: 0.7179 - val_loss: 2.7643 - val_categorical_accuracy: 0.4967 - lr: 0.0010\n",
            "Epoch 35/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:09:39.786983: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26109\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 0.9809 - categorical_accuracy: 0.7335 - val_loss: 2.6716 - val_categorical_accuracy: 0.5003 - lr: 0.0010\n",
            "Epoch 36/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:10:18.092485: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26147\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 0.9595 - categorical_accuracy: 0.7441 - val_loss: 2.9292 - val_categorical_accuracy: 0.4760 - lr: 0.0010\n",
            "Epoch 37/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:10:56.084676: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26185\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 95ms/step - loss: 0.9457 - categorical_accuracy: 0.7495 - val_loss: 2.6067 - val_categorical_accuracy: 0.5082 - lr: 0.0010\n",
            "Epoch 38/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:11:34.945603: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26223\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 1.0017 - categorical_accuracy: 0.7246 - val_loss: 2.8790 - val_categorical_accuracy: 0.4777 - lr: 0.0010\n",
            "Epoch 39/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:12:13.323302: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26261\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 93ms/step - loss: 0.9584 - categorical_accuracy: 0.7434 - val_loss: 2.5701 - val_categorical_accuracy: 0.5175 - lr: 0.0010\n",
            "Epoch 40/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:12:51.384600: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26299\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 0.9395 - categorical_accuracy: 0.7480 - val_loss: 2.7861 - val_categorical_accuracy: 0.4892 - lr: 0.0010\n",
            "Epoch 41/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:13:29.775940: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26337\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 0.9357 - categorical_accuracy: 0.7509 - val_loss: 2.7903 - val_categorical_accuracy: 0.4785 - lr: 0.0010\n",
            "Epoch 42/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:14:08.230955: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26375\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 0.9213 - categorical_accuracy: 0.7535 - val_loss: 2.8009 - val_categorical_accuracy: 0.4949 - lr: 0.0010\n",
            "Epoch 43/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:14:46.120792: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26413\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 95ms/step - loss: 0.9889 - categorical_accuracy: 0.7258 - val_loss: 2.8501 - val_categorical_accuracy: 0.4709 - lr: 0.0010\n",
            "Epoch 44/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:15:24.555999: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26451\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 91ms/step - loss: 0.9416 - categorical_accuracy: 0.7472 - val_loss: 2.6660 - val_categorical_accuracy: 0.5040 - lr: 0.0010\n",
            "Epoch 45/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:16:01.687693: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26489\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 93ms/step - loss: 0.9189 - categorical_accuracy: 0.7559 - val_loss: 2.7996 - val_categorical_accuracy: 0.4910 - lr: 0.0010\n",
            "Epoch 46/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:16:40.051597: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26527\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 0.9509 - categorical_accuracy: 0.7390 - val_loss: 3.1275 - val_categorical_accuracy: 0.4549 - lr: 0.0010\n",
            "Epoch 47/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:17:18.317802: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26565\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 0.9223 - categorical_accuracy: 0.7536 - val_loss: 2.7580 - val_categorical_accuracy: 0.5013 - lr: 0.0010\n",
            "Epoch 48/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:17:56.207091: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26603\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 38s 96ms/step - loss: 0.9059 - categorical_accuracy: 0.7596 - val_loss: 2.6891 - val_categorical_accuracy: 0.4876 - lr: 0.0010\n",
            "Epoch 49/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:18:35.631861: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26641\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 0.8927 - categorical_accuracy: 0.7629 - val_loss: 2.9706 - val_categorical_accuracy: 0.4753 - lr: 0.0010\n",
            "Epoch 50/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:19:13.812874: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26679\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 36s 93ms/step - loss: 0.9621 - categorical_accuracy: 0.7328 - val_loss: 2.6128 - val_categorical_accuracy: 0.5047 - lr: 0.0010\n",
            "Epoch 51/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:19:51.641261: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26717\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 95ms/step - loss: 0.9097 - categorical_accuracy: 0.7559 - val_loss: 2.8738 - val_categorical_accuracy: 0.4918 - lr: 0.0010\n",
            "Epoch 52/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:20:30.246997: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26755\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 37s 94ms/step - loss: 0.9272 - categorical_accuracy: 0.7468 - val_loss: 2.6371 - val_categorical_accuracy: 0.5123 - lr: 0.0010\n",
            "Epoch 53/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-04 14:21:08.478600: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "input: \"Placeholder/_2\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26793\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 100\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - ETA: 0s - loss: 0.9007 - categorical_accuracy: 0.7612"
          ]
        }
      ],
      "source": [
        "# Load a fresh student model with the standard cross-entropy loss.\n",
        "with strategy.scope():\n",
        "  acc_dist_student = load_model(\n",
        "      _STUDENT_MODEL,\n",
        "      num_classes=num_classes,\n",
        "      optimizer_name=_STUDENT_OPTIMIZER,\n",
        "      width_multiplier=1,\n",
        "      depth_multiplier=_STUDENT_MOBILENET_DEPTH_MULTIPLIER,\n",
        "      resnet_depth=_STUDENT_RESNET_DEPTH)\n",
        "\n",
        "  acc_dist_student.load_weights('pretrained_weights.h5')\n",
        "\n",
        "validation_size = data_split.validation.size\n",
        "# The dimension of the covariate space of the KNN is d = 2.\n",
        "d = 2\n",
        "# We use the asymptotic formula to compute the number of neighbors.\n",
        "n_neigh = round(0.5 * (validation_size)**(2 / (2 + d)))\n",
        "\n",
        "def _margin(x):\n",
        "  return margin(x, with_logits=False, normalize=False)\n",
        "\n",
        "weight_data = accuracy_distortion_weights(\n",
        "    teacher=teacher_model,\n",
        "    student=acc_dist_student,\n",
        "    uncertainty=_margin,\n",
        "    n_neighbors=n_neigh,\n",
        "    data_split=data_split)\n",
        "\n",
        "# Perform weighted distillation.\n",
        "distill(\n",
        "    model=acc_dist_student,\n",
        "    teacher_predictions=teacher_predictions,\n",
        "    data_split=data_split,\n",
        "    weight_data=weight_data,\n",
        "    params=training_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4os1XlFbTAoq"
      },
      "source": [
        "# SLaM (Data dependent top-k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fV8jRh_cHaV1"
      },
      "outputs": [],
      "source": [
        "def top_k_disagreement(q: tf.Tensor, p: tf.Tensor, k: int) -> tf.Tensor:\n",
        "  num_classes = tf.shape(p)[-1]\n",
        "  _, top_k_pos = tf.math.top_k(p, k=k)\n",
        "  one_hot_top_k = tf.reduce_sum(tf.one_hot(top_k_pos,  num_classes), axis=1)\n",
        "  true_top_1 = tf.one_hot(tf.argmax(q, 1), num_classes)\n",
        "\n",
        "  return tf.reduce_sum(one_hot_top_k * true_top_1, axis=1)\n",
        "\n",
        "\n",
        "def top_k_margin(x: tf.Tensor,\n",
        "                k: int,\n",
        "                with_logits: Optional[bool] = False,\n",
        "                normalize: Optional[bool] = False) -> tf.Tensor:\n",
        "  \"\"\"Computes the margin of a probability/logit tensor.\"\"\"\n",
        "\n",
        "  if with_logits:\n",
        "    class_probabilities = tf.nn.softmax(x, axis=None, name=None)\n",
        "  else:\n",
        "    class_probabilities = x\n",
        "  a, _ = tf.math.top_k(class_probabilities, k=k+1, sorted=True)\n",
        "\n",
        "  # Compute total probability of top-k elements\n",
        "  top_k_prob = tf.reduce_sum(a[:, :k], axis=1)\n",
        "  next_best_prob =  tf.reduce_sum(a[:, k:], axis=1)\n",
        "  marg = top_k_prob - next_best_prob\n",
        "\n",
        "  if normalize:\n",
        "    marg = marg/tf.math.reduce_mean(marg)\n",
        "\n",
        "  return marg\n",
        "\n",
        "\n",
        "def teacher_top_k_accuracy_predictions(\n",
        "    teacher_predictions_training: tf.keras.Model,\n",
        "    teacher_predictions_validation: tf.keras.Model,\n",
        "    k: int,\n",
        "    confidence: Callable[[tf.Tensor], tf.Tensor],\n",
        "    data_split: DataSplit) -> tf.Tensor:\n",
        "  \"\"\"Creates teacher-accuracy advice for the training dataset (dataset_b).\n",
        "\n",
        "  It uses a confidence measure (e.g., margin, entropy) for the teacher\n",
        "  prediction over a validation dataset and isotonic regression to learn\n",
        "  the mapping from confidence to accuracy.\n",
        "\n",
        "  Args:\n",
        "    teacher: Instance of tf.keras.Model: the teacher model.\n",
        "    confidence: A function that maps soft labels to confidence.\n",
        "    k: Compute the top-k accuracy of teacher.\n",
        "    data_split: Instance of DataSplit containing the\n",
        "      training, validation, and test data.\n",
        "\n",
        "  Returns:\n",
        "    Instance of Advice containing advice vectors.\n",
        "  \"\"\"\n",
        "\n",
        "  train = data_split.dataset_b\n",
        "  validation = data_split.validation\n",
        "\n",
        "  # These are the lower bound/upper bounds used in isotonic regression.\n",
        "  # All values predicted should be in the range [min_threshold, max_threshold].\n",
        "  # Since the outputs correspond to the probability that the teacher model is\n",
        "  # correct the range [0.5, 1.] is reasonable.\n",
        "  min_threshold = 0.5\n",
        "  max_threshold = 1.\n",
        "\n",
        "  # Compute the teacher margins on the validation examples.\n",
        "  covariate = tf.reshape(confidence(teacher_predictions_validation), (-1, 1))\n",
        "\n",
        "  # Compute the (pointwise) top-k accuracy of the teacher on the validation data.\n",
        "  response = top_k_disagreement(validation.labels, teacher_predictions_validation, k)\n",
        "\n",
        "  # Create a isotonic regressor that maps teacher_margins to teacher_accuracies.\n",
        "  covariate = tf.reshape(covariate, -1)\n",
        "  response = tf.reshape(response, -1)\n",
        "  iso = IsotonicRegression(\n",
        "      y_min=min_threshold, y_max=max_threshold, out_of_bounds='clip')\n",
        "  iso.fit(covariate, response)\n",
        "\n",
        "\n",
        "  # Compute the teacher confidence on the training dataset.\n",
        "  teacher_confidence = tf.reshape(confidence(teacher_predictions_training), -1)\n",
        "\n",
        "  # Use the knn to predict the accuracy of the teacher on the training examples.\n",
        "  main_advice = iso.predict(teacher_confidence)\n",
        "\n",
        "  return main_advice\n",
        "\n",
        "def teacher_top_k_accuracy_advice(\n",
        "    teacher: tf.keras.Model,\n",
        "    num_classes,\n",
        "    data_split: DataSplit) -> Advice:\n",
        "\n",
        "  pretraining = data_split.dataset_a\n",
        "  validation = data_split.validation\n",
        "  test = data_split.test\n",
        "\n",
        "  s = []\n",
        "\n",
        "  teacher_predictions_training = teacher.predict(train.examples)\n",
        "  teacher_predictions_validation = teacher.predict(validation.examples)\n",
        "\n",
        "  for k in range(1, num_classes):\n",
        "\n",
        "    def _top_k_confidence(x):\n",
        "      return top_k_margin(x, k, with_logits=False, normalize=False)\n",
        "\n",
        "    s.append(teacher_top_k_accuracy_predictions(\n",
        "        teacher_predictions_training,\n",
        "        teacher_predictions_validation,\n",
        "        k, _top_k_confidence, data_split))\n",
        "\n",
        "  s.append(tf.ones(data_split.dataset_b.size))\n",
        "\n",
        "  train_advice = tf.stack(s, axis=1)\n",
        "\n",
        "  validation_advice = None\n",
        "  pretraining_advice = None\n",
        "\n",
        "  if validation is not None:\n",
        "    validation_advice = tf.stack([tf.one_hot(0, num_classes) for i in range(validation.size)], axis=0)\n",
        "\n",
        "  if pretraining is not None:\n",
        "    pretraining_advice =  tf.stack([tf.one_hot(0, num_classes) for i in range(pretraining.size)], axis=0)\n",
        "\n",
        "  test_advice =  tf.stack([tf.zeros(num_classes) for i in range(test.size)], axis=0)\n",
        "\n",
        "  advice_data = Advice(\n",
        "      train=train_advice,\n",
        "      validation=validation_advice,\n",
        "      pretraining=pretraining_advice,\n",
        "      test=test_advice)\n",
        "\n",
        "  return advice_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ-qCtDcTkW_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1234/1234 [==============================] - 20s 16ms/step\n",
            "16/16 [==============================] - 0s 16ms/step\n"
          ]
        }
      ],
      "source": [
        "full_top_k_advice = teacher_top_k_accuracy_advice(teacher_model, 100, data_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSzSDWLvHb8o"
      },
      "outputs": [],
      "source": [
        "import tensorflow_probability as tfp\n",
        "\n",
        "def soft_top_k_mask(x, k_mask, temp):\n",
        "  perm_matrices =  tfp.math.soft_sorting_matrix(x, temp)\n",
        "  return tf.einsum('ijk, ij -> ik', perm_matrices, k_mask)\n",
        "\n",
        "\n",
        "def advice_mix_soft_top_full(num_classes, temperature, threshold):\n",
        "  \"\"\"A decorator that returns a top_k student label mixing loss decorator.\n",
        "\n",
        "  Args:\n",
        "      k: the top_k elements of the student to be used.\n",
        "\n",
        "  Returns:\n",
        "    A top_k student label mixing loss decorator.\n",
        "    loss.\n",
        "  \"\"\"\n",
        "\n",
        "  def _advice_mix_soft_top_k(loss):\n",
        "\n",
        "    def _loss(y_true, y_pred):\n",
        "\n",
        "      # Split y_true into the advice (last column of y_true) and labels.\n",
        "      advice = tf.stop_gradient(y_true[:, -num_classes:])\n",
        "      label = tf.stop_gradient(y_true[:, :-num_classes])\n",
        "      k_mask = tf.cast(advice<threshold, tf.float32)\n",
        "      boost = soft_top_k_mask(y_pred, k_mask, temperature) * (1-y_pred)\n",
        "\n",
        "      top_1_acc = advice[:, 0]\n",
        "      top_1_err = 1.-top_1_acc\n",
        "\n",
        "      y_1 = tf.einsum('ij, i -> ij', y_pred, top_1_acc)\n",
        "      y_2  = tf.einsum('ij, i -> ij', boost, top_1_err)\n",
        "      y_mixed = y_1 + y_2\n",
        "\n",
        "      # Return the loss of the teacher label and the mixed student label.\n",
        "      return loss(label, y_mixed)\n",
        "\n",
        "    return _loss\n",
        "\n",
        "  return _advice_mix_soft_top_k\n",
        "\n",
        "\n",
        "def mixed_cce_soft_top_full(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
        "  \"\"\"Computes the cross entropy loss using the advice to perform student mixing.\n",
        "\n",
        "  Args:\n",
        "    y_true: tf.Tensor with num_classes + 1 columns where the first num_classes\n",
        "      columns contain the true label and the last column corresponds to the\n",
        "      advice.\n",
        "    y_pred: tf.Tensor with num_classes columns that contains the predicted\n",
        "      probabilities for each class.\n",
        "\n",
        "  Returns:\n",
        "    The student mixed cross entropy between y_true[:,:-1] and y_pred defined as:\n",
        "    ce(teacher_pred, advice student_pred + (1-advice) (1-student_pred))\n",
        "  \"\"\"\n",
        "\n",
        "  # We have to use tf.keras.losses.Reduction.NONE when we are using\n",
        "  # tf.distribute.Strategy.\n",
        "  # (see https://www.tensorflow.org/tutorials/distribute/custom_training).\n",
        "  mixing_operator = advice_mix_soft_top_full(100, 100.0, 0.9)\n",
        "  loss = mixing_operator(tf.keras.losses.CategoricalCrossentropy(\n",
        "    reduction=tf.keras.losses.Reduction.NONE))\n",
        "\n",
        "  return tf.math.reduce_mean(loss(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8ZjtS89StWS"
      },
      "outputs": [],
      "source": [
        "# Load a fresh student model with the studentl-label-mixing cross-entropy loss.\n",
        "with strategy.scope():\n",
        "  student_soft_full = load_model(\n",
        "      _STUDENT_MODEL,\n",
        "      num_classes=num_classes,\n",
        "      optimizer_name=_STUDENT_OPTIMIZER,\n",
        "      loss_function=mixed_cce_soft_top_full,\n",
        "      width_multiplier=1,\n",
        "      depth_multiplier=_STUDENT_MOBILENET_DEPTH_MULTIPLIER,\n",
        "      resnet_depth=_STUDENT_RESNET_DEPTH)\n",
        "\n",
        "  student_soft_full.load_weights('pretrained_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbT_U0M4VKv-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 6s 11ms/step - loss: 7.7357 - categorical_accuracy: 0.4761\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:49:00.470331: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26938\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 64s 74ms/step - loss: 3.1287 - categorical_accuracy: 0.1615 - val_loss: 6.8793 - val_categorical_accuracy: 0.3732 - lr: 0.0010\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:50:05.845758: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:26976\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 3.0694 - categorical_accuracy: 0.1564 - val_loss: 7.0704 - val_categorical_accuracy: 0.4004 - lr: 0.0010\n",
            "Epoch 3/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:50:35.178354: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27014\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 74ms/step - loss: 3.0196 - categorical_accuracy: 0.1600 - val_loss: 6.7585 - val_categorical_accuracy: 0.3882 - lr: 0.0010\n",
            "Epoch 4/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:51:05.537696: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27052\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 3.0062 - categorical_accuracy: 0.1564 - val_loss: 6.8224 - val_categorical_accuracy: 0.3933 - lr: 0.0010\n",
            "Epoch 5/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:51:34.852328: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27090\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.9843 - categorical_accuracy: 0.1575 - val_loss: 6.8830 - val_categorical_accuracy: 0.4327 - lr: 0.0010\n",
            "Epoch 6/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:52:04.903340: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27128\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.9505 - categorical_accuracy: 0.1580 - val_loss: 6.8586 - val_categorical_accuracy: 0.4057 - lr: 0.0010\n",
            "Epoch 7/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:52:34.104480: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27166\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 72ms/step - loss: 2.9647 - categorical_accuracy: 0.1535 - val_loss: 6.8485 - val_categorical_accuracy: 0.4221 - lr: 0.0010\n",
            "Epoch 8/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:53:04.009966: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27204\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.9207 - categorical_accuracy: 0.1577 - val_loss: 6.9726 - val_categorical_accuracy: 0.4361 - lr: 0.0010\n",
            "Epoch 9/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:53:33.267320: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27242\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.8908 - categorical_accuracy: 0.1600 - val_loss: 6.9539 - val_categorical_accuracy: 0.4071 - lr: 0.0010\n",
            "Epoch 10/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:54:02.742973: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27280\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.8751 - categorical_accuracy: 0.1609 - val_loss: 7.0815 - val_categorical_accuracy: 0.4271 - lr: 0.0010\n",
            "Epoch 11/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:54:32.392464: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27318\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.8587 - categorical_accuracy: 0.1621 - val_loss: 6.6604 - val_categorical_accuracy: 0.4025 - lr: 0.0010\n",
            "Epoch 12/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:55:01.518121: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27356\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.9267 - categorical_accuracy: 0.1501 - val_loss: 6.9511 - val_categorical_accuracy: 0.4287 - lr: 0.0010\n",
            "Epoch 13/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:55:31.531461: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27394\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 72ms/step - loss: 2.8648 - categorical_accuracy: 0.1583 - val_loss: 7.0230 - val_categorical_accuracy: 0.4389 - lr: 0.0010\n",
            "Epoch 14/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:56:01.044452: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27432\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.8426 - categorical_accuracy: 0.1604 - val_loss: 7.0320 - val_categorical_accuracy: 0.4433 - lr: 0.0010\n",
            "Epoch 15/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:56:31.379305: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27470\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.8484 - categorical_accuracy: 0.1583 - val_loss: 7.0458 - val_categorical_accuracy: 0.4314 - lr: 0.0010\n",
            "Epoch 16/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:57:00.536751: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27508\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.8196 - categorical_accuracy: 0.1623 - val_loss: 7.0187 - val_categorical_accuracy: 0.4223 - lr: 0.0010\n",
            "Epoch 17/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:57:30.586071: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27546\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.7949 - categorical_accuracy: 0.1641 - val_loss: 6.9632 - val_categorical_accuracy: 0.4578 - lr: 0.0010\n",
            "Epoch 18/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:57:59.807790: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27584\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.7770 - categorical_accuracy: 0.1667 - val_loss: 7.1380 - val_categorical_accuracy: 0.4571 - lr: 0.0010\n",
            "Epoch 19/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:58:29.828922: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27622\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.8459 - categorical_accuracy: 0.1561 - val_loss: 6.9635 - val_categorical_accuracy: 0.4323 - lr: 0.0010\n",
            "Epoch 20/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:58:59.015599: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27660\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 74ms/step - loss: 2.7989 - categorical_accuracy: 0.1627 - val_loss: 7.0107 - val_categorical_accuracy: 0.4477 - lr: 0.0010\n",
            "Epoch 21/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:59:29.210842: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27698\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.7788 - categorical_accuracy: 0.1637 - val_loss: 7.0190 - val_categorical_accuracy: 0.4092 - lr: 0.0010\n",
            "Epoch 22/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 12:59:58.315296: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27736\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.7790 - categorical_accuracy: 0.1632 - val_loss: 6.9865 - val_categorical_accuracy: 0.4295 - lr: 0.0010\n",
            "Epoch 23/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:00:28.444269: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27774\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.7621 - categorical_accuracy: 0.1657 - val_loss: 7.1560 - val_categorical_accuracy: 0.4512 - lr: 0.0010\n",
            "Epoch 24/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:00:57.621913: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27812\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 74ms/step - loss: 2.7350 - categorical_accuracy: 0.1685 - val_loss: 7.2800 - val_categorical_accuracy: 0.4609 - lr: 0.0010\n",
            "Epoch 25/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:01:28.011991: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27850\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.7758 - categorical_accuracy: 0.1627 - val_loss: 7.2846 - val_categorical_accuracy: 0.4761 - lr: 0.0010\n",
            "Epoch 26/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:01:57.209648: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27888\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.7320 - categorical_accuracy: 0.1689 - val_loss: 7.2403 - val_categorical_accuracy: 0.4593 - lr: 0.0010\n",
            "Epoch 27/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:02:27.340810: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27926\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.7332 - categorical_accuracy: 0.1684 - val_loss: 7.2669 - val_categorical_accuracy: 0.4769 - lr: 0.0010\n",
            "Epoch 28/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:02:56.444082: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:27964\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.7267 - categorical_accuracy: 0.1687 - val_loss: 7.0457 - val_categorical_accuracy: 0.4493 - lr: 0.0010\n",
            "Epoch 29/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:03:26.545530: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28002\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.7092 - categorical_accuracy: 0.1721 - val_loss: 7.1840 - val_categorical_accuracy: 0.4550 - lr: 0.0010\n",
            "Epoch 30/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:03:55.848877: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28040\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.7336 - categorical_accuracy: 0.1659 - val_loss: 7.2926 - val_categorical_accuracy: 0.4498 - lr: 0.0010\n",
            "Epoch 31/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:04:25.984754: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28078\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.7025 - categorical_accuracy: 0.1707 - val_loss: 7.0730 - val_categorical_accuracy: 0.4135 - lr: 0.0010\n",
            "Epoch 32/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:04:55.207259: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28116\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.7070 - categorical_accuracy: 0.1699 - val_loss: 7.1511 - val_categorical_accuracy: 0.4451 - lr: 0.0010\n",
            "Epoch 33/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:05:25.126018: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28154\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.6852 - categorical_accuracy: 0.1736 - val_loss: 7.1489 - val_categorical_accuracy: 0.4063 - lr: 0.0010\n",
            "Epoch 34/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:05:54.405241: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28192\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 74ms/step - loss: 2.6727 - categorical_accuracy: 0.1756 - val_loss: 7.2467 - val_categorical_accuracy: 0.4557 - lr: 0.0010\n",
            "Epoch 35/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:06:24.639605: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28230\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.7107 - categorical_accuracy: 0.1689 - val_loss: 7.0716 - val_categorical_accuracy: 0.4398 - lr: 0.0010\n",
            "Epoch 36/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:06:53.862454: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28268\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.6794 - categorical_accuracy: 0.1739 - val_loss: 7.3263 - val_categorical_accuracy: 0.4668 - lr: 0.0010\n",
            "Epoch 37/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:07:24.004558: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28306\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.6516 - categorical_accuracy: 0.1779 - val_loss: 7.2645 - val_categorical_accuracy: 0.4425 - lr: 0.0010\n",
            "Epoch 38/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:07:53.082035: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28344\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.7013 - categorical_accuracy: 0.1691 - val_loss: 7.3342 - val_categorical_accuracy: 0.4484 - lr: 0.0010\n",
            "Epoch 39/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:08:23.133671: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28382\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.6536 - categorical_accuracy: 0.1758 - val_loss: 7.3572 - val_categorical_accuracy: 0.4640 - lr: 0.0010\n",
            "Epoch 40/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:08:52.265777: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28420\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.6411 - categorical_accuracy: 0.1790 - val_loss: 7.2987 - val_categorical_accuracy: 0.4463 - lr: 0.0010\n",
            "Epoch 41/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:09:22.392910: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28458\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.6275 - categorical_accuracy: 0.1814 - val_loss: 7.2897 - val_categorical_accuracy: 0.4645 - lr: 0.0010\n",
            "Epoch 42/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:09:51.534170: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28496\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.6299 - categorical_accuracy: 0.1787 - val_loss: 7.3903 - val_categorical_accuracy: 0.4672 - lr: 0.0010\n",
            "Epoch 43/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:10:21.705915: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28534\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.6130 - categorical_accuracy: 0.1819 - val_loss: 7.3802 - val_categorical_accuracy: 0.4737 - lr: 0.0010\n",
            "Epoch 44/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:10:50.907920: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28572\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.6165 - categorical_accuracy: 0.1809 - val_loss: 7.4440 - val_categorical_accuracy: 0.4723 - lr: 0.0010\n",
            "Epoch 45/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:11:20.896392: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28610\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 72ms/step - loss: 2.7118 - categorical_accuracy: 0.1656 - val_loss: 7.3752 - val_categorical_accuracy: 0.4512 - lr: 0.0010\n",
            "Epoch 46/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:11:50.324499: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28648\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.6537 - categorical_accuracy: 0.1756 - val_loss: 7.2954 - val_categorical_accuracy: 0.4709 - lr: 0.0010\n",
            "Epoch 47/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:12:20.320966: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28686\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.6324 - categorical_accuracy: 0.1783 - val_loss: 7.2645 - val_categorical_accuracy: 0.4528 - lr: 0.0010\n",
            "Epoch 48/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:12:49.419614: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28724\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.6235 - categorical_accuracy: 0.1800 - val_loss: 7.4867 - val_categorical_accuracy: 0.4789 - lr: 0.0010\n",
            "Epoch 49/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:13:19.463366: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28762\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.6487 - categorical_accuracy: 0.1746 - val_loss: 7.2012 - val_categorical_accuracy: 0.4596 - lr: 0.0010\n",
            "Epoch 50/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:13:48.658108: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28800\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.6236 - categorical_accuracy: 0.1786 - val_loss: 7.3558 - val_categorical_accuracy: 0.4681 - lr: 0.0010\n",
            "Epoch 51/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:14:18.723088: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28838\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.6108 - categorical_accuracy: 0.1804 - val_loss: 7.2755 - val_categorical_accuracy: 0.4495 - lr: 0.0010\n",
            "Epoch 52/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:14:47.929877: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28876\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.6344 - categorical_accuracy: 0.1768 - val_loss: 7.4812 - val_categorical_accuracy: 0.4736 - lr: 0.0010\n",
            "Epoch 53/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:15:17.913903: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28914\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.6033 - categorical_accuracy: 0.1823 - val_loss: 7.4000 - val_categorical_accuracy: 0.4755 - lr: 0.0010\n",
            "Epoch 54/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:15:47.185918: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28952\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.5993 - categorical_accuracy: 0.1822 - val_loss: 7.5198 - val_categorical_accuracy: 0.4625 - lr: 0.0010\n",
            "Epoch 55/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:16:18.358232: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:28990\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 72ms/step - loss: 2.5872 - categorical_accuracy: 0.1841 - val_loss: 7.4845 - val_categorical_accuracy: 0.4624 - lr: 0.0010\n",
            "Epoch 56/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:16:47.964608: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29028\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.6477 - categorical_accuracy: 0.1739 - val_loss: 7.3626 - val_categorical_accuracy: 0.4526 - lr: 0.0010\n",
            "Epoch 57/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:17:18.118512: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29066\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.5978 - categorical_accuracy: 0.1820 - val_loss: 7.3305 - val_categorical_accuracy: 0.4607 - lr: 0.0010\n",
            "Epoch 58/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:17:47.643621: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29104\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.5896 - categorical_accuracy: 0.1828 - val_loss: 7.5296 - val_categorical_accuracy: 0.4804 - lr: 0.0010\n",
            "Epoch 59/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:18:17.886422: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29142\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.5732 - categorical_accuracy: 0.1852 - val_loss: 7.3067 - val_categorical_accuracy: 0.4606 - lr: 0.0010\n",
            "Epoch 60/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:18:47.208469: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29180\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.5673 - categorical_accuracy: 0.1859 - val_loss: 7.4096 - val_categorical_accuracy: 0.4360 - lr: 0.0010\n",
            "Epoch 61/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:19:17.386567: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29218\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 72ms/step - loss: 2.6233 - categorical_accuracy: 0.1759 - val_loss: 7.2399 - val_categorical_accuracy: 0.4530 - lr: 0.0010\n",
            "Epoch 62/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:19:46.968092: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29256\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.5797 - categorical_accuracy: 0.1837 - val_loss: 7.1442 - val_categorical_accuracy: 0.4352 - lr: 0.0010\n",
            "Epoch 63/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:20:17.096888: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29294\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.5981 - categorical_accuracy: 0.1801 - val_loss: 7.5655 - val_categorical_accuracy: 0.4712 - lr: 0.0010\n",
            "Epoch 64/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:20:46.399364: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29332\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.5690 - categorical_accuracy: 0.1854 - val_loss: 7.5237 - val_categorical_accuracy: 0.4849 - lr: 0.0010\n",
            "Epoch 65/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:21:16.565518: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29370\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.5585 - categorical_accuracy: 0.1854 - val_loss: 7.5329 - val_categorical_accuracy: 0.4540 - lr: 0.0010\n",
            "Epoch 66/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:21:45.906575: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29408\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.6017 - categorical_accuracy: 0.1789 - val_loss: 7.4758 - val_categorical_accuracy: 0.4618 - lr: 0.0010\n",
            "Epoch 67/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:22:16.054446: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29446\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.5658 - categorical_accuracy: 0.1848 - val_loss: 7.5621 - val_categorical_accuracy: 0.4746 - lr: 0.0010\n",
            "Epoch 68/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:22:45.351648: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29484\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.5439 - categorical_accuracy: 0.1883 - val_loss: 7.4004 - val_categorical_accuracy: 0.4545 - lr: 0.0010\n",
            "Epoch 69/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:23:15.321102: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29522\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.5947 - categorical_accuracy: 0.1796 - val_loss: 7.3272 - val_categorical_accuracy: 0.4438 - lr: 0.0010\n",
            "Epoch 70/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:23:44.735855: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29560\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.5723 - categorical_accuracy: 0.1828 - val_loss: 7.3570 - val_categorical_accuracy: 0.4431 - lr: 0.0010\n",
            "Epoch 71/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:24:14.701700: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29598\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.5524 - categorical_accuracy: 0.1870 - val_loss: 7.4581 - val_categorical_accuracy: 0.4490 - lr: 0.0010\n",
            "Epoch 72/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:24:44.086860: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29636\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.5512 - categorical_accuracy: 0.1868 - val_loss: 7.6313 - val_categorical_accuracy: 0.4803 - lr: 0.0010\n",
            "Epoch 73/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:25:14.214700: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29674\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.5861 - categorical_accuracy: 0.1806 - val_loss: 7.3549 - val_categorical_accuracy: 0.4656 - lr: 0.0010\n",
            "Epoch 74/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:25:43.615601: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29712\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.5528 - categorical_accuracy: 0.1863 - val_loss: 7.5081 - val_categorical_accuracy: 0.4749 - lr: 0.0010\n",
            "Epoch 75/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:26:13.668374: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29750\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.5343 - categorical_accuracy: 0.1889 - val_loss: 7.4458 - val_categorical_accuracy: 0.4575 - lr: 0.0010\n",
            "Epoch 76/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:26:43.099062: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29788\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.5796 - categorical_accuracy: 0.1807 - val_loss: 7.6481 - val_categorical_accuracy: 0.4749 - lr: 0.0010\n",
            "Epoch 77/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:27:13.211071: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29826\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.5451 - categorical_accuracy: 0.1882 - val_loss: 7.4679 - val_categorical_accuracy: 0.4452 - lr: 0.0010\n",
            "Epoch 78/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:27:42.567002: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29864\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.5595 - categorical_accuracy: 0.1834 - val_loss: 7.5479 - val_categorical_accuracy: 0.4670 - lr: 0.0010\n",
            "Epoch 79/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:28:12.534646: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29902\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.5296 - categorical_accuracy: 0.1888 - val_loss: 7.4892 - val_categorical_accuracy: 0.4525 - lr: 0.0010\n",
            "Epoch 80/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:28:41.827895: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29940\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.5333 - categorical_accuracy: 0.1885 - val_loss: 7.6018 - val_categorical_accuracy: 0.4760 - lr: 0.0010\n",
            "Epoch 81/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:29:11.777452: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:29978\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 72ms/step - loss: 2.4489 - categorical_accuracy: 0.1998 - val_loss: 8.1004 - val_categorical_accuracy: 0.5360 - lr: 1.0000e-04\n",
            "Epoch 82/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:29:41.317379: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30016\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 74ms/step - loss: 2.3949 - categorical_accuracy: 0.2082 - val_loss: 8.1625 - val_categorical_accuracy: 0.5396 - lr: 1.0000e-04\n",
            "Epoch 83/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:30:11.986737: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30054\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 72ms/step - loss: 2.3725 - categorical_accuracy: 0.2106 - val_loss: 8.2248 - val_categorical_accuracy: 0.5357 - lr: 1.0000e-04\n",
            "Epoch 84/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:30:41.440910: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30092\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.3505 - categorical_accuracy: 0.2121 - val_loss: 8.2209 - val_categorical_accuracy: 0.5372 - lr: 1.0000e-04\n",
            "Epoch 85/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:31:11.474692: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30130\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 72ms/step - loss: 2.3506 - categorical_accuracy: 0.2114 - val_loss: 8.2301 - val_categorical_accuracy: 0.5340 - lr: 1.0000e-04\n",
            "Epoch 86/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:31:40.875350: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30168\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.3352 - categorical_accuracy: 0.2124 - val_loss: 8.2328 - val_categorical_accuracy: 0.5303 - lr: 1.0000e-04\n",
            "Epoch 87/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:32:11.069750: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30206\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 72ms/step - loss: 2.3219 - categorical_accuracy: 0.2128 - val_loss: 8.2411 - val_categorical_accuracy: 0.5316 - lr: 1.0000e-04\n",
            "Epoch 88/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:32:40.575540: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30244\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.3097 - categorical_accuracy: 0.2133 - val_loss: 8.2053 - val_categorical_accuracy: 0.5309 - lr: 1.0000e-04\n",
            "Epoch 89/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:33:10.596250: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30282\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 72ms/step - loss: 2.3112 - categorical_accuracy: 0.2130 - val_loss: 8.2408 - val_categorical_accuracy: 0.5304 - lr: 1.0000e-04\n",
            "Epoch 90/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:33:40.010240: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30320\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.2955 - categorical_accuracy: 0.2137 - val_loss: 8.2529 - val_categorical_accuracy: 0.5297 - lr: 1.0000e-04\n",
            "Epoch 91/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:34:10.169032: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30358\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.2846 - categorical_accuracy: 0.2140 - val_loss: 8.2343 - val_categorical_accuracy: 0.5311 - lr: 1.0000e-04\n",
            "Epoch 92/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:34:39.537847: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30396\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.2750 - categorical_accuracy: 0.2141 - val_loss: 8.2609 - val_categorical_accuracy: 0.5330 - lr: 1.0000e-04\n",
            "Epoch 93/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:35:09.613944: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30434\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.2831 - categorical_accuracy: 0.2129 - val_loss: 8.2281 - val_categorical_accuracy: 0.5256 - lr: 1.0000e-04\n",
            "Epoch 94/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:35:38.863468: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30472\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.2705 - categorical_accuracy: 0.2135 - val_loss: 8.2160 - val_categorical_accuracy: 0.5252 - lr: 1.0000e-04\n",
            "Epoch 95/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:36:08.808648: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30510\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.2632 - categorical_accuracy: 0.2132 - val_loss: 8.2865 - val_categorical_accuracy: 0.5301 - lr: 1.0000e-04\n",
            "Epoch 96/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:36:38.148431: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30548\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.2541 - categorical_accuracy: 0.2140 - val_loss: 8.2740 - val_categorical_accuracy: 0.5279 - lr: 1.0000e-04\n",
            "Epoch 97/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:37:08.187758: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30586\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 72ms/step - loss: 2.2456 - categorical_accuracy: 0.2140 - val_loss: 8.2757 - val_categorical_accuracy: 0.5270 - lr: 1.0000e-04\n",
            "Epoch 98/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:37:37.733537: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30624\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 73ms/step - loss: 2.2383 - categorical_accuracy: 0.2142 - val_loss: 8.2111 - val_categorical_accuracy: 0.5245 - lr: 1.0000e-04\n",
            "Epoch 99/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:38:07.541114: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30662\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 28s 71ms/step - loss: 2.2438 - categorical_accuracy: 0.2132 - val_loss: 8.2659 - val_categorical_accuracy: 0.5247 - lr: 1.0000e-04\n",
            "Epoch 100/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-03 13:38:36.904868: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
            "op: \"TensorSliceDataset\"\n",
            "input: \"Placeholder/_0\"\n",
            "input: \"Placeholder/_1\"\n",
            "attr {\n",
            "  key: \"Toutput_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_FLOAT\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"_cardinality\"\n",
            "  value {\n",
            "    i: 50000\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"is_files\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"metadata\"\n",
            "  value {\n",
            "    s: \"\\n\\030TensorSliceDataset:30700\"\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 32\n",
            "        }\n",
            "        dim {\n",
            "          size: 3\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: 200\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"replicate_on_split\"\n",
            "  value {\n",
            "    b: false\n",
            "  }\n",
            "}\n",
            "experimental_type {\n",
            "  type_id: TFT_PRODUCT\n",
            "  args {\n",
            "    type_id: TFT_DATASET\n",
            "    args {\n",
            "      type_id: TFT_PRODUCT\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "      args {\n",
            "        type_id: TFT_TENSOR\n",
            "        args {\n",
            "          type_id: TFT_FLOAT\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "390/390 [==============================] - 29s 73ms/step - loss: 2.2359 - categorical_accuracy: 0.2136 - val_loss: 8.2760 - val_categorical_accuracy: 0.5267 - lr: 1.0000e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(53.96000146865845,\n",
              " array([47.60999978, 37.31999993, 40.04000127, 38.82000148, 39.32999969,\n",
              "        43.27000082, 40.56999981, 42.21000075, 43.61000061, 40.7099992 ,\n",
              "        42.71000028, 40.25000036, 42.87      , 43.88999939, 44.33000088,\n",
              "        43.1400001 , 42.23000109, 45.78000009, 45.7100004 , 43.23000014,\n",
              "        44.76999938, 40.92000127, 42.95000136, 45.12000084, 46.09000087,\n",
              "        47.60999978, 45.93000114, 47.69000113, 44.92999911, 45.50000131,\n",
              "        44.98000145, 41.3500011 , 44.51000094, 40.63000083, 45.57000101,\n",
              "        43.97999942, 46.68000042, 44.24999952, 44.83999908, 46.39999866,\n",
              "        44.63      , 46.450001  , 46.7200011 , 47.36999869, 47.2299993 ,\n",
              "        45.12000084, 47.08999991, 45.28000057, 47.88999856, 45.96000016,\n",
              "        46.81000113, 44.94999945, 47.36000001, 47.54999876, 46.2500006 ,\n",
              "        46.23999894, 45.26000023, 46.07000053, 48.0399996 , 46.05999887,\n",
              "        43.59999895, 45.30000091, 43.52000058, 47.11999893, 48.48999977,\n",
              "        45.39999962, 46.1800009 , 47.45999873, 45.44999897, 44.38000023,\n",
              "        44.31000054, 44.9000001 , 48.03000093, 46.56000137, 47.49000072,\n",
              "        45.75000107, 47.49000072, 44.51999962, 46.70000076, 45.24999857,\n",
              "        47.6000011 , 53.60000134, 53.96000147, 53.57000232, 53.71999741,\n",
              "        53.39999795, 53.03000212, 53.15999985, 53.09000015, 53.03999782,\n",
              "        52.96999812, 53.10999751, 53.29999924, 52.56000161, 52.52000093,\n",
              "        53.0099988 , 52.78999805, 52.700001  , 52.45000124, 52.4699986 ,\n",
              "        52.67000198]))"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the student model using distillation.\n",
        "distill(model=student_soft_full,\n",
        "        teacher_predictions=teacher_predictions,\n",
        "        data_split=data_split,\n",
        "        advice_data=full_top_k_advice,\n",
        "        params=training_params)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "BwiCChDUzGrS",
        "dMwnTVBV7uGY"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01509b6f21de43f48343d2df137fa434": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01fdb47da20048959040309cb36dd181": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "02e462c5e91e469a8146c500989c19df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c58d1e6316a24750bdf4ba51098f7280",
            "placeholder": "​",
            "style": "IPY_MODEL_e747346d06d449aaadfefb36d902a576",
            "value": "Dl Size...: 100%"
          }
        },
        "06e56a5f67004e76bb5bf78086aa7003": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0b3b5c2ae94f4a819f88e1cee9f5a33c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "101c50425c25436ea142886a0bdfbb9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90412bde42e5466881d26982937b17e8",
              "IPY_MODEL_c40d07cf2d074291a42b4cc176f89cce",
              "IPY_MODEL_2661835ce6334e6c9fd3e1426d37700e"
            ],
            "layout": "IPY_MODEL_dbf29b11c23e4610a6e340636d90f159"
          }
        },
        "10eff5b4c3964489af536c7d634fe9fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ade307cbc41c4d25abf1f154d4658cb9",
              "IPY_MODEL_d23796d20af0492f81105ab8a358117c",
              "IPY_MODEL_ee3b23415db646ae92917cd03344b01f"
            ],
            "layout": "IPY_MODEL_01fdb47da20048959040309cb36dd181"
          }
        },
        "132d9720f49246eca68a2c2d0e722b58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1428d7468b8b460597e89f415a3c5dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4448ea8d263746ce8db8e3d66bfad446",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c87185ea3abb41689d6b23c50d57eed2",
            "value": 1
          }
        },
        "14f2501b6a764a34ab0be67d832bc304": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "166dc17a38e8447288cba6ce147c51e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_934e160518314e03b2d675618cb699cf",
            "placeholder": "​",
            "style": "IPY_MODEL_d9a4e5660b8c4a67ad50cbdbd0c419fc",
            "value": " 4/4 [00:07&lt;00:00,  7.85s/ file]"
          }
        },
        "1b6b6bd2bbc349578bc477be08e8dbfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b3b5c2ae94f4a819f88e1cee9f5a33c",
            "placeholder": "​",
            "style": "IPY_MODEL_1dcc162118e24304aec8d5bbda552b14",
            "value": "Dl Completed...: 100%"
          }
        },
        "1dcc162118e24304aec8d5bbda552b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ed735d10be546a3bc2cc66068ea999c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02e462c5e91e469a8146c500989c19df",
              "IPY_MODEL_1428d7468b8b460597e89f415a3c5dbd",
              "IPY_MODEL_b30f448657a04c7abaada388d3b656aa"
            ],
            "layout": "IPY_MODEL_82a347fbd16d4c32971306b8d6b2b57a"
          }
        },
        "1faee804aa4d4fad8c1d713fc2d1a882": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2661835ce6334e6c9fd3e1426d37700e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_132d9720f49246eca68a2c2d0e722b58",
            "placeholder": "​",
            "style": "IPY_MODEL_779ac98dd484436ea7b3825235ddf6e2",
            "value": " 42374/50000 [00:00&lt;00:00, 222880.70 examples/s]"
          }
        },
        "2758760fa84943d297ff75f2f4a1f11b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "29e4f83090ef471f849ae595f906f480": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "305dd26f0d5e429f9614c3fcb17d3002": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd825562f093402d95854387ec6b6063",
              "IPY_MODEL_48c4bdcae65a4f71979157529bf45a5c",
              "IPY_MODEL_53cf49b0f7cf4941a875a4966703c2c9"
            ],
            "layout": "IPY_MODEL_7303a767e82d498fb1da120e9f76d25f"
          }
        },
        "30f0c55344814ed08dcf841d39b42b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3139735376164a03b93833ed8f5345bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85a2069f167f498fb897a976246e9dcd",
            "placeholder": "​",
            "style": "IPY_MODEL_f139b7728dcc4696b1882b767fb6d0c1",
            "value": "Generating test examples...:  98%"
          }
        },
        "33fb288614544851a9bd1e586f07f1b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4aa9619da1284b6baeb704212c750aa1",
            "placeholder": "​",
            "style": "IPY_MODEL_d5a4f6e8f4284d26a949cb3fe19caf6b",
            "value": " 2/2 [00:28&lt;00:00, 12.57s/ splits]"
          }
        },
        "390d198cedcf4bc896f36f914679737a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39e3cd47bdb245a4a7bd94eb5ab0c4df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4448ea8d263746ce8db8e3d66bfad446": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "48c4bdcae65a4f71979157529bf45a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1faee804aa4d4fad8c1d713fc2d1a882",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecb53fbd438e4a4f9259b49f23ed493a",
            "value": 10000
          }
        },
        "4aa9619da1284b6baeb704212c750aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c97d001bebf432f975c3c64fc3a61c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f2b801a0594441fb1a4afadeefd719d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53cb7da6a615452c9ee6430842f97ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53cf49b0f7cf4941a875a4966703c2c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd23a566c5b84e8685c9a86431b2ed72",
            "placeholder": "​",
            "style": "IPY_MODEL_53cb7da6a615452c9ee6430842f97ce8",
            "value": " 0/10000 [00:00&lt;?, ? examples/s]"
          }
        },
        "5da76f426a98463da3ff4c80740647a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f2bf455d9e041cdac6b8519997c03fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06e56a5f67004e76bb5bf78086aa7003",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ae8b96e5082416c8b8f3613f80e80ff",
            "value": 1
          }
        },
        "63b11c2932b844b485071b76c548e9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "670822cafcf64dcebfb8ed5d0b5f6b80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2758760fa84943d297ff75f2f4a1f11b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14f2501b6a764a34ab0be67d832bc304",
            "value": 1
          }
        },
        "69a3ede4ec9a4f11b236033320ec13b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "6f35e7c451124d6285e5afdb21e26823": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f6e896a8d4441cf9dcd953ae60fca40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7303a767e82d498fb1da120e9f76d25f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "779ac98dd484436ea7b3825235ddf6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ae8b96e5082416c8b8f3613f80e80ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ec328eb316e460085b6c29897dbb1bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f35e7c451124d6285e5afdb21e26823",
            "placeholder": "​",
            "style": "IPY_MODEL_d2e97d0c4f184760b254bec2a97ed5f1",
            "value": " 9781/10000 [00:04&lt;00:00, 2226.81 examples/s]"
          }
        },
        "806932478b564e7f8c905c5600637815": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82a347fbd16d4c32971306b8d6b2b57a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83169747f618462a9bbd29138f50e38c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3139735376164a03b93833ed8f5345bd",
              "IPY_MODEL_88ae664f204f484bbab5e635fb2e5a85",
              "IPY_MODEL_7ec328eb316e460085b6c29897dbb1bc"
            ],
            "layout": "IPY_MODEL_69a3ede4ec9a4f11b236033320ec13b4"
          }
        },
        "85a2069f167f498fb897a976246e9dcd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88ae664f204f484bbab5e635fb2e5a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1b0bf12a7c6463698328f72755a3447",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aaf32eef522e44ccb35a804929bb2d2f",
            "value": 10000
          }
        },
        "90412bde42e5466881d26982937b17e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8f91dd0a4654b63849fe61c9e940d53",
            "placeholder": "​",
            "style": "IPY_MODEL_806932478b564e7f8c905c5600637815",
            "value": "Shuffling /root/tensorflow_datasets/cifar100/3.0.2.incomplete3UOGFH/cifar100-train.tfrecord*...:  85%"
          }
        },
        "90eee6032ea54cf189fa725751c4baa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29e4f83090ef471f849ae595f906f480",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1ec1877fd234ec3b85baad00987ed3c",
            "value": 2
          }
        },
        "90f2a31b38d347d185625063e1f7f933": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "934e160518314e03b2d675618cb699cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9468c4c8ec5647d991126ed5c227d355": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "983191d266f14c41b015890a9f53b903": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb473a9b00424987a4e36d9d044b0a96",
            "placeholder": "​",
            "style": "IPY_MODEL_39e3cd47bdb245a4a7bd94eb5ab0c4df",
            "value": "Extraction completed...: 100%"
          }
        },
        "aaf32eef522e44ccb35a804929bb2d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ade307cbc41c4d25abf1f154d4658cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b22299f613e34e328a47f968493235c9",
            "placeholder": "​",
            "style": "IPY_MODEL_5da76f426a98463da3ff4c80740647a7",
            "value": "Generating train examples...: 100%"
          }
        },
        "b22299f613e34e328a47f968493235c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2d1c265c0f340978e79a1e20e4ec4f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f6e896a8d4441cf9dcd953ae60fca40",
            "placeholder": "​",
            "style": "IPY_MODEL_c0545872c3de4561ac4bef7ed402f89d",
            "value": "Generating splits...: 100%"
          }
        },
        "b30f448657a04c7abaada388d3b656aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01509b6f21de43f48343d2df137fa434",
            "placeholder": "​",
            "style": "IPY_MODEL_30f0c55344814ed08dcf841d39b42b45",
            "value": " 160/160 [00:07&lt;00:00, 49.79 MiB/s]"
          }
        },
        "b37ee5210bc9441fbb9617dff6889b1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8f91dd0a4654b63849fe61c9e940d53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbba9b14a5e3419f93ec24b63ae83ac3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0545872c3de4561ac4bef7ed402f89d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1b0bf12a7c6463698328f72755a3447": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c40d07cf2d074291a42b4cc176f89cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b37ee5210bc9441fbb9617dff6889b1f",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_390d198cedcf4bc896f36f914679737a",
            "value": 50000
          }
        },
        "c58d1e6316a24750bdf4ba51098f7280": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c87185ea3abb41689d6b23c50d57eed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb473a9b00424987a4e36d9d044b0a96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd23a566c5b84e8685c9a86431b2ed72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd825562f093402d95854387ec6b6063": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f2b801a0594441fb1a4afadeefd719d",
            "placeholder": "​",
            "style": "IPY_MODEL_63b11c2932b844b485071b76c548e9d2",
            "value": "Shuffling /root/tensorflow_datasets/cifar100/3.0.2.incomplete3UOGFH/cifar100-test.tfrecord*...:   0%"
          }
        },
        "cf3cd11bdbef467593013786ae70a08a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_983191d266f14c41b015890a9f53b903",
              "IPY_MODEL_5f2bf455d9e041cdac6b8519997c03fb",
              "IPY_MODEL_166dc17a38e8447288cba6ce147c51e0"
            ],
            "layout": "IPY_MODEL_d8ebb04555ce40728eeecd4951a798bf"
          }
        },
        "d23796d20af0492f81105ab8a358117c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc4db6cb065347769502ce5180001db3",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90f2a31b38d347d185625063e1f7f933",
            "value": 50000
          }
        },
        "d2e97d0c4f184760b254bec2a97ed5f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5a4f6e8f4284d26a949cb3fe19caf6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d730206c2ec248c7b9dd24a591e1e578": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8ebb04555ce40728eeecd4951a798bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9a4e5660b8c4a67ad50cbdbd0c419fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dad908eb1a5e453886aae4072421cef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c97d001bebf432f975c3c64fc3a61c5",
            "placeholder": "​",
            "style": "IPY_MODEL_ee90192a07a84b61a2702054138189c2",
            "value": " 1/1 [00:07&lt;00:00,  3.85s/ url]"
          }
        },
        "dbf29b11c23e4610a6e340636d90f159": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "e019cf23b028471ba4bbdd7562059fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b6b6bd2bbc349578bc477be08e8dbfd",
              "IPY_MODEL_670822cafcf64dcebfb8ed5d0b5f6b80",
              "IPY_MODEL_dad908eb1a5e453886aae4072421cef7"
            ],
            "layout": "IPY_MODEL_bbba9b14a5e3419f93ec24b63ae83ac3"
          }
        },
        "e747346d06d449aaadfefb36d902a576": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecb53fbd438e4a4f9259b49f23ed493a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee3b23415db646ae92917cd03344b01f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d730206c2ec248c7b9dd24a591e1e578",
            "placeholder": "​",
            "style": "IPY_MODEL_f239894a44c14a1abd0a21109167537d",
            "value": " 49926/50000 [00:23&lt;00:00, 2156.85 examples/s]"
          }
        },
        "ee90192a07a84b61a2702054138189c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef60724b291e4e81abfa35d5444d9ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2d1c265c0f340978e79a1e20e4ec4f1",
              "IPY_MODEL_90eee6032ea54cf189fa725751c4baa6",
              "IPY_MODEL_33fb288614544851a9bd1e586f07f1b5"
            ],
            "layout": "IPY_MODEL_9468c4c8ec5647d991126ed5c227d355"
          }
        },
        "f139b7728dcc4696b1882b767fb6d0c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1ec1877fd234ec3b85baad00987ed3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f239894a44c14a1abd0a21109167537d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc4db6cb065347769502ce5180001db3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
